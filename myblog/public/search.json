[{"title":"alertmanager","url":"/2025/04/27/alertmanager/","content":"安装curl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composeversion: &#x27;3&#x27;services:  alertmanager:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/alertmanager:v0.28.1    ports:      - &quot;9093:9093&quot;      - &quot;9094:9094&quot;    volumes:      - ./config:/etc/alertmanager      - alertmanager_data:/alertmanager    command:      - &#x27;--config.file=/etc/alertmanager/alertmanager.yml&#x27;      - &#x27;--storage.path=/alertmanager&#x27;      - &#x27;--cluster.advertise-address=alertmanager:9094&#x27;    networks:      - monitoring-netvolumes:  alertmanager_data:networks:  monitoring-net:    driver: bridge\n配置文件解读global: # 即为全局设置,在Alertmanager配置文件中,只要全局设置配置了的选项,全部为公共设置,可以让其他设置继承,作为默认值,可以子参数中覆盖其设置。  resolve_timeout: 1m # 用于设置处理超时时间,也是生命警报状态为解决的时间,这个时间会直接影响到警报恢复的通知时间,需要自行结合实际生产场景来设置主机的恢复时间,默认是5分钟。  # 整合邮件  smtp_smarthost: &#x27;smtp.qq.com:465&#x27; # 邮箱smtp服务器  smtp_from: &#x27;1451578387@qq.com&#x27; # 发件用的邮箱地址  smtp_auth_username: &#x27;1451578387@qq.com&#x27; # 发件人账号  smtp_auth_password: &#x27;dkuuifhdskaduasdsb&#x27; # 发件人邮箱密码  smtp_require_tls: false # 不进行tls验证route: # 路由分组  group_by: [&#x27;alertname&#x27;] # 报警分组  group_wait: 10s # 组内等待时间,同一分组内收到第一个告警等待多久开始发送,目标是为了同组消息同时发送,不占用告警信息,默认30s。  group_interval: 10s # 当组内已经发送过一个告警,组内若有新增告警需要等待的时间,默认为5m,这条要确定组内信息是影响同一业务才能设置,若分组不合理,可能导致告警延迟,造成影响。  repeat_interval: 1h # 告警已经发送,且无新增告警,若重复告警需要间隔多久,默认4h,属于重复告警,时间间隔应根据告警的严重程度来设置。  receiver: &#x27;webhook&#x27; # 告警的接收者,需要和 receivers[n].name 的值一致。  # 上面所有的属性都由所有子路由继承,并且可以在每个子路由上进行覆盖。  # 当报警信息中标签匹配到team:node时会使用email发送报警,否则使用webhook。 templates:- &#x27;/etc/alertmanager/config/*.tmpl&#x27;# route根路由,该模块用于该根路由下的节点及子路由routes的定义,子树节点如果不对相关配置进行配置,则默认会从父路由树继承该配置选项。每一条告警都要进入route,即要求配置选项group_by的值能够匹配到每一条告警的至少一个labelkey(即通过POST请求向altermanager服务接口所发送告警的labels项所携带的&lt;labelname&gt;),告警进入到route后,将会根据子路由routes节点中的配置项match_re或者match来确定能进入该子路由节点的告警(由在match_re或者match下配置的labelkey:labelvalue是否为告警labels的子集决定,是的话则会进入该子路由节点,否则不能接收进入该子路由节点)。route:  # 例如所有labelkey:labelvalue含cluster=A及altertname=LatencyHigh的labelkey的告警都会被归入单一组中  group_by: [&#x27;job&#x27;, &#x27;altername&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;,&#x27;severity&#x27;]  # 若一组新的告警产生,则会等group_wait后再发送通知,该功能主要用于当告警在很短时间内接连产生时,在group_wait内合并为单一的告警后再发送  group_wait: 30s  # 再次告警时间间隔  group_interval: 5m  # 如果一条告警通知已成功发送,且在间隔repeat_interval后,该告警仍然未被设置为resolved,则会再次发送该告警通知  repeat_interval: 12h  # 默认告警通知接收者,凡未被匹配进入各子路由节点的告警均被发送到此接收者  receiver: &#x27;wechat&#x27;  # 上述route的配置会被传递给子路由节点,子路由节点进行重新配置才会被覆盖  # 子路由树  routes:  # 该配置选项使用正则表达式来匹配告警的labels,以确定能否进入该子路由树  # match_re和match均用于匹配labelkey为service,labelvalue分别为指定值的告警,被匹配到的告警会将通知发送到对应的receiver  - match_re:      service: ^(foo1|foo2|baz)$    receiver: &#x27;wechat&#x27;    # 在带有service标签的告警同时有severity标签时,他可以有自己的子路由,同时具有severity != critical的告警则被发送给接收者team-ops-mails,对severity == critical的告警则被发送到对应的接收者即team-ops-pager    routes:    - match:        severity: critical      receiver: &#x27;wechat&#x27;  # 比如关于数据库服务的告警,如果子路由没有匹配到相应的owner标签,则都默认由team-DB-pager接收  - match:      service: database    receiver: &#x27;wechat&#x27;  # 我们也可以先根据标签service:database将数据库服务告警过滤出来,然后进一步将所有同时带labelkey为database  - match:      severity: critical    receiver: &#x27;wechat&#x27;# 抑制规则,当出现critical(关键的)告警时忽略warning。# 下面的这段配置是指如果出现标签为severity=critical的告警,则抑制severity=warning的告警inhibit_rules:- source_match:    severity: &#x27;critical&#x27;  target_match:    severity: &#x27;warning&#x27;  # 如果警报名称相同,则应用抑制。  # alertname、cluster和service对应的标签值需要相等  equal: [&#x27;alertname&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;]# 收件人配置receivers:- name: &#x27;team-ops-mails&#x27;  email_configs:  - to: &#x27;dukuan@xxx.com&#x27;- name: &#x27;team-X-pager&#x27;  email_configs:  - to: &#x27;team-X+alerts-critical@example.org&#x27;  pagerduty_configs:  - service_key: &lt;team-X-key&gt;- name: &#x27;team-Y-mails&#x27;  email_configs:  - to: &#x27;team-Y+alerts@example.org&#x27;- name: &#x27;webhook&#x27;  webhook_configs:  - url: http://127.0.0.1:8060/dingtalk/webhook1/send    send_resolved: true\n分组和路由\n\n路由match（精确匹配）match_re（正则表达式匹配）每一个告警都会从配置文件中顶级的route进入路由树，需要注意的是顶级的route必须匹配所有告警(即不能有任何的匹配设置match和match_re)，每一个路由都可以定义自己的接受人以及匹配规则。默认情况下，告警进入到顶级route后会遍历所有的子节点，直到找到最深的匹配route，并将告警发送到该route定义的receiver中。但如果route中设置continue的值为false，那么告警在匹配到第一个子节点之后就直接停止。如果continue为true，报警则会继续进行后续子节点的匹配。如果当前告警匹配不到任何的子节点，那该告警将会基于当前路由节点的接收器配置方式进行处理\n分组告警通知进行分组，将多条告警合合并为一个通知。这里我们可以使用group_by来定义分组规则。基于告警中包含的标签，如果满足group_by中定义标签名称，那么这些告警将会合并为一个通知发送给接收器。有的时候为了能够一次性收集和发送更多的相关信息时，可以通过group_wait参数设置等待时间，如果在等待时间内当前group接收到了新的告警，这些告警将会合并为一个通知向receiver发送\n\n\nroute:  group_by: [&#x27;alertname&#x27;,&#x27;team&#x27;]   #在这里添加team匹配的标签  group_wait: 5s  group_interval: 5s  repeat_interval: 5m  # 默认发给&quot;sre_system&quot;组用户  receiver: &#x27;sre_system&#x27;  continue: false  # 配置子路由  routes:    - receiver: &#x27;sre_dba&#x27;      match_re:        job: test      # 建议将continue的值设置为true，表示当前的条件是否匹配，都将继续向下匹配规则      # 这样做的目的是将消息发给最后的系统组(sre_system)      continue: true==================================================================#rule.yml- name: grafana  rules:  - alert: node           #这个相当于alertname的值,与之前匹配的相同    expr: up&#123;job=&quot;grafana&quot;&#125; == 0    for: 10s                      labels:                         severity: 1       job: test  # 对应上面的 match_re      team: grafana        #这里标签设置不同的一会用    annotations:                    summary: &quot;&#123;&#123; \\$labels.instance &#125;&#125; 已停止运行超过 15s&quot;      description: hello world alertname 等于 node 如果相同报警会一起发送team 等于 grafana \n抑制规则inhibit_rules:  - source_match:      severity: &#x27;告警&#x27;    target_match:      severity: &#x27;提示&#x27;    #equal: [&#x27;type&#x27;,&#x27;test&#x27;] 要求 type 和 test签均相同     equal: [&#x27;type&#x27;]type的值必须一样当匹配到 告警 时就会抑制提示的告警通知并检查他们是否来自于同个ssl（即ssl标签的值相同抑制才会生效）当子路由匹配到不同的 severity 时就会将消息发往不同的 receiver，当子路由无法匹配到时，消息会默认发往根路由的 receiver，因此，无论是否匹配到子路由规则，消息都会发往根路由的 receiver对应报警规则配置为groups:- name: node-alerts  rules:  - alert: HighNodeCPU    expr: (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) * 100 &gt; 80    for: 5m    labels:      severity: &quot;告警&quot;      type: ssl    annotations:      summary: &quot;高节点CPU使用率 (&#123;&#123; $labels.instance &#125;&#125;)&quot;      description: &quot;节点 &#123;&#123; $labels.instance &#125;&#125; CPU 使用率超过 80% 已持续 5 分钟&quot;- name: cluster-alerts  rules:  - alert: ClusterWideCPUProblem    expr: |      sum( (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) * 100 &gt; 80 )      /      count( (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) )      * 100 &gt; 50    for: 10m    labels:      severity: &quot;提示&quot;      type: ssl    annotations:      summary: &quot;集群级CPU问题&quot;      description: &quot;超过 50% 的节点持续高CPU使用率达 10 分钟&quot;\n\nalertmanager集成三方告警\n原生alertmanager只有邮件和webhook告警；Alertmanager 的原生 Webhook 告警是一种通过 HTTP POST 请求将告警信息发送到自定义接口（Webhook 接收端）的机制；所以要对接需要开发者自行开发，这里推荐两个现成的工具来对接\n\nPrometheusAlert使用\nPrometheus Alert 是开源的运维告警中心消息转发系统，支持主流的监控系统 Prometheus，日志系统 Graylog 和数据可视化系统 Grafana 发出的预警消息。通知渠道支持钉钉、微信、华为云短信、腾讯云短信、腾讯云电话、阿里云短信、阿里云电话等等\n\nwget https://github.com/feiyu563/PrometheusAlert/releases/download/v4.8.1/linux.zipchmod +x PrometheusAlert启动 nohup ./PrometheusAlert &amp; 后台运行#alertmanager.yml配置集成PrometheusAlert；格式可以登录PrometheusAlert查看receivers:- name: &#x27;web.hook.prometheusalert&#x27;  webhook_configs:  - url: &#x27;http://192.168.197.142:8080/prometheusalert?type=wx&amp;tpl=prometheus-wx&amp;wxurl=https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=53fdb356-4446-42e5-b8bd-f7da63bcfe76&#x27;\n\nprometheus-webhook-dingtalk使用\nPrometheus 的Alertmanager自身不支持钉钉报警，需要通过插件的方式来达到报警条件\n\n安装wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v2.1.0/prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gztar zxf prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gz mv prometheus-webhook-dingtalk-2.1.0.linux-amd64 /usr/local/prometheus-webhook-dingtalkcat &gt; /usr/lib/systemd/system/webhook-dingtalk.service &lt;&lt; EOF[Unit]Description=prometheus-webhook-dingtalkDocumentation=https://github.com/timonwong/prometheus-webhook-dingtalkAfter=network.target[Service]User=rootGroup=rootExecStart=/usr/local/prometheus-webhook-dingtalk/prometheus-webhook-dingtalk  --config.file=/usr/local/prometheus-webhook-dingtalk/config.ymlExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failure[Install]WantedBy=multi-user.targetEOF#集成模版/usr/local/prometheus-webhook-dingtalk/config.ymltemplates:    - /usr/local/prometheus/webhook-dingtalk/template.tmpltargets:  webhook1:    url: https://oapi.dingtalk.com/robot/send?access_token=9ac4354ab7c8#alertmanager配置发送给dingtalk插件receivers:  - name: &#x27;email&#x27;    email_configs:      - to: &#x27;xxxxx@163.com&#x27; #指定发送给谁  - name: &#x27;webhook1&#x27;    webhook_configs:      - send_resolved: false        url: http://localhost:8060/dingtalk/webhook1/send\n\n报警内容模版vim /usr/local/prometheus/webhook-dingtalk/template.tmpl&#123;&#123; define &quot;__subject&quot; &#125;&#125;[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;]&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;__alert_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;---&#123;&#123; if .Labels.owner &#125;&#125;@&#123;&#123; .Labels.owner &#125;&#125;&#123;&#123; end &#125;&#125; **告警主题**: &#123;&#123; .Annotations.summary &#125;&#125;**告警类型**: &#123;&#123; .Labels.alertname &#125;&#125; **告警级别**: &#123;&#123; .Labels.severity &#125;&#125;  **告警主机**: &#123;&#123; .Labels.instance &#125;&#125;  **告警信息**: &#123;&#123; index .Annotations &quot;description&quot; &#125;&#125; **告警时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; &#123;&#123; define &quot;__resolved_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;---&#123;&#123; if .Labels.owner &#125;&#125;@&#123;&#123; .Labels.owner &#125;&#125;&#123;&#123; end &#125;&#125;**告警主题**: &#123;&#123; .Annotations.summary &#125;&#125;**告警类型**: &#123;&#123; .Labels.alertname &#125;&#125;  **告警级别**: &#123;&#123; .Labels.severity &#125;&#125; **告警主机**: &#123;&#123; .Labels.instance &#125;&#125; **告警信息**: &#123;&#123; index .Annotations &quot;description&quot; &#125;&#125; **告警时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125; **恢复时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.EndsAt) &quot;Asia/Shanghai&quot; &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;default.title&quot; &#125;&#125;&#123;&#123; template &quot;__subject&quot; . &#125;&#125;&#123;&#123; end &#125;&#125; &#123;&#123; define &quot;default.content&quot; &#125;&#125;&#123;&#123; if gt (len .Alerts.Firing) 0 &#125;&#125;**====侦测到&#123;&#123; .Alerts.Firing | len  &#125;&#125;个故障====**&#123;&#123; template &quot;__alert_list&quot; .Alerts.Firing &#125;&#125;---&#123;&#123; end &#125;&#125; &#123;&#123; if gt (len .Alerts.Resolved) 0 &#125;&#125;**====恢复&#123;&#123; .Alerts.Resolved | len  &#125;&#125;个故障====**&#123;&#123; template &quot;__resolved_list&quot; .Alerts.Resolved &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;ding.link.title&quot; &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; define &quot;ding.link.content&quot; &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;\n报警规则示例mkdir /usr/local/prometheus/prometheus/rulevim /usr/local/prometheus/prometheus/rule/node_exporter.ymlgroups:- name: 服务器资源监控  rules:  - alert: 内存使用率过高    expr: 100 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 &gt; 80    for: 3m     labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123; $labels.instance &#125;&#125; 内存使用率过高, 请尽快处理！&quot;      description: &quot;&#123;&#123; $labels.instance &#125;&#125;内存使用率超过80%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;            - alert: 服务器宕机    expr: up == 0    for: 1s    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 服务器宕机, 请尽快处理!&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 服务器延时超过3分钟,当前状态&#123;&#123; $value &#125;&#125;. &quot;   - alert: CPU高负荷    expr: 100 - (avg by (instance,job)(irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) * 100) &gt; 90    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; CPU使用率过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; CPU使用大于90%,当前使用率&#123;&#123; $value &#125;&#125;%. &quot;        - alert: 磁盘IO性能    expr: avg(irate(node_disk_io_time_seconds_total[1m])) by(instance,job)* 100 &gt; 90    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入磁盘IO使用率过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入磁盘IO大于90%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;    - alert: 网络流入    expr: ((sum(rate (node_network_receive_bytes_total&#123;device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*&#x27;&#125;[5m])) by (instance,job)) / 100) &gt; 102400    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入网络带宽过高，请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入网络带宽持续5分钟高于100M. RX带宽使用量&#123;&#123;$value&#125;&#125;.&quot;   - alert: 网络流出    expr: ((sum(rate (node_network_transmit_bytes_total&#123;device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*&#x27;&#125;[5m])) by (instance,job)) / 100) &gt; 102400    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流出网络带宽过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流出网络带宽持续5分钟高于100M. RX带宽使用量&#123;$value&#125;&#125;.&quot;    - alert: TCP连接数    expr: node_netstat_Tcp_CurrEstab &gt; 10000    for: 2m    labels:      severity: 严重告警    annotations:      summary: &quot; TCP_ESTABLISHED过高！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; TCP_ESTABLISHED大于100%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;   - alert: 磁盘容量    expr: 100-(node_filesystem_free_bytes&#123;fstype=~&quot;ext4|xfs&quot;&#125;/node_filesystem_size_bytes &#123;fstype=~&quot;ext4|xfs&quot;&#125;*100) &gt; 90    for: 1m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.mountpoint&#125;&#125; 磁盘分区使用率过高，请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 磁盘分区使用大于90%，当前使用率&#123;&#123; $value &#125;&#125;%.&quot;\n","categories":["prometheus"]},{"title":"elastcisearch_dump","url":"/2025/08/12/elastcisearch-dump/","content":"esdumphttps://github.com/elasticsearch-dump/elasticsearch-dump\ndocker pull elasticdump/elasticsearch-dumporwget https://nodejs.org/dist/v16.18.0/node-v16.18.0-linux-x64.tar.xzexport PATH=$PATH:/root/node-v16.18.0-linux-x64/bin/npm install elasticdump -g#bashPREFIX=&quot;y-logs-&quot;curl -s &quot;http://localhost:9200/_cat/indices?h=index&quot; | grep &quot;^$&#123;PREFIX&#125;&quot; | while read -r INDEX_NAME; do#INDEX_NAME=&quot;y-logs-2025&quot;    for TYPE in &#123;settings,mapping,data&#125;;do        echo &quot;start $TYPE of index  [$INDEX_NAME]...&quot;        elasticdump  --input=http://localhost:9200/$INDEX_NAME     --output=http://username:passwd@dest_addr.com:9200/$INDEX_NAME     --type=$TYPE --limit 10000    done    echo &#x27;==============================================&#x27;    sleep 3done# --limit 并发数# --output=/data/es/$&#123;INDEX_NAME&#125;.json 备份可以保存到文件 # --httpAuthFile指定HTTP认证文件# --searchBody=&quot;&#123;\\&quot;query\\&quot;:&#123;\\&quot;term\\&quot;:&#123;\\&quot;username\\&quot;: \\&quot;admin\\&quot;&#125;&#125;&#125;&quot; 过滤\n\n\nsnapshot#设置fs类型仓库存储路径；然后重启esexport path.repo=/usr/share/elasticsearch/data/es_snapshot#创建仓库curl -XPUT &#x27;http://localhost:9200/_snapshot/y_repo&#x27; \\  -H &#x27;Content-Type: application/json&#x27; \\  -d &#x27;&#123;    &quot;type&quot;: &quot;fs&quot;,    &quot;settings&quot;: &#123;      &quot;location&quot;: &quot;/usr/share/elasticsearch/data/es_snapshot&quot;,      &quot;compress&quot;: true    &#125;  &#125;&#x27;#location必须和path.repo一致#查看curl  -s localhost:9200/_snapshot/y_repo|jq#删除curl -XDELETE localhost:9200/_snapshot/y_repo=======================================================#创建快照#不指定索引就是快照所有curl -XPUT   localhost:9200/_snapshot/y_repo/snapshot_all  #?wait_for_completion=true #指定索引快照curl -H &quot;Content-Type: application/json&quot; -XPUT localhost:9200/_snapshot/y_repo/snapshot_202508_01-02?pretty -d&#x27;&#123;&quot;indices&quot;: &quot;y-logs-2025.08.01,y-logs-2025.08.02&quot;&#125;&#x27;#查看快照信息curl localhost:9200/_cat/snapshots/y_repo?vcurl localhost:9200/_cat/snapshots/_all?v#查看快照包含的索引信息curl   -Ss localhost:9200/_snapshot/y_repo/_all|jqcurl   -Ss localhost:9200/_snapshot/y_repo/snapshot_202508_01-02|jqcurl   -Ss localhost:9200/_snapshot/y_repo/snapshot_202508_01-02/_status|jq=======================================================#恢复快照;目标索引名称尽量不要存在同名curl -X POST &quot;http://localhost:9200/_snapshot/y_repo/snapshot_all/_restore&quot; \\  -H &quot;Content-Type: application/json&quot; \\  -d &#x27;&#123;    &quot;indices&quot;: &quot;y-logs-2025.08.*&quot;,    &quot;rename_pattern&quot;: &quot;y-logs-2025.08.01&quot;,    &quot;rename_replacement&quot;: &quot;y_new_repo&quot;  &#125;&#x27;#indices指定恢复的索引名称;需要精确匹配如果范围较大，rename_pattern匹配不上的会直接名称不变恢复#rename_pattern\t正则表达式，匹配原始索引名称中的模式（用于捕获需要替换的部分）#rename_replacement\t替换后的新索引名称模板（使用 $1、$2 等引用正则表达式中的捕获组）#示例json参数&#x27;&#123;  &quot;indices&quot;: &quot;y-logs-2025.08.01&quot;  // 仅恢复该索引，名称不变&#125;&#x27;&#x27;&#123;  &quot;indices&quot;: &quot;y-logs-2025.08.01&quot;,  &quot;rename_pattern&quot;: &quot;(.+)&quot;,          // 匹配整个原始名称  &quot;rename_replacement&quot;: &quot;restored_$1&quot; // 新名称：restored_y-logs-2025.08.01&#125;&#x27;&#x27;&#123;  &quot;indices&quot;: &quot;y-logs*&quot;,  &quot;rename_pattern&quot;: &quot;y-logs-(\\\\d&#123;4&#125;)\\\\.(\\\\d&#123;2&#125;)\\\\.(\\\\d&#123;2&#125;)&quot;,  // 捕获年、月、日  &quot;rename_replacement&quot;: &quot;archive_$1-$2-$3&quot;  // 新名称：archive_2025-08-01&#125;&#x27;&#x27;&#123;    &quot;indices&quot;: &quot;*,-.security*,-.kibana*&quot;, //使用- 过滤不迁移的索引    &quot;ignore_unavailable&quot;: &quot;true&quot;&#125;&#x27;=========================================================================#查看快照恢复情况curl -s -X GET &quot;http://localhost:9200/_recovery/&quot;|jqcurl -X GET &quot;http://localhost:9200/_cat/recovery/?v&quot;curl -s -X GET &quot;http://localhost:9200/archive_2025-08-08/_recovery/&quot;|jqcurl -s -X GET &quot;http://localhost:9200/_cat/recovery/archive_2025-08-08?format=json&quot;|jq&#123;    &quot;index&quot;: &quot;archive_2025-08-08&quot;,    &quot;shard&quot;: &quot;0&quot;,    &quot;time&quot;: &quot;441ms&quot;, 恢复总耗时（441 毫秒）    &quot;type&quot;: &quot;snapshot&quot;, 恢复类型为 快照恢复（从快照仓库恢复数据）。    &quot;stage&quot;: &quot;done&quot;, 当前恢复阶段：- init（初始化）- index（复制索引文件）- translog（传输事务日志）- finalize（完成恢复）- done（已完成）    &quot;source_host&quot;: &quot;n/a&quot;, 源数据节点的主机名或 IP（仅在跨节点恢复时出现，如分片迁移）    &quot;source_node&quot;: &quot;n/a&quot;, 源节点的名称（Elasticsearch 集群内唯一标识）。    &quot;target_host&quot;: &quot;172.26.0.2&quot;, 目标    &quot;target_node&quot;: &quot;be439083dc6b&quot;,    &quot;repository&quot;: &quot;y_repo&quot;,    &quot;snapshot&quot;: &quot;snapshot_all&quot;,    &quot;files&quot;: &quot;35&quot;, 需要恢复文件数    &quot;files_recovered&quot;: &quot;35&quot;, 已经恢复    &quot;files_percent&quot;: &quot;100.0%&quot;, 进度    &quot;files_total&quot;: &quot;35&quot;, 总文件数    &quot;bytes&quot;: &quot;3429792&quot;, 字节    &quot;bytes_recovered&quot;: &quot;3429792&quot;, 已恢复字节数    &quot;bytes_percent&quot;: &quot;100.0%&quot;, 进度    &quot;bytes_total&quot;: &quot;3429792&quot;,    &quot;translog_ops&quot;: &quot;0&quot;, 需要恢复的事务日志操作总数    &quot;translog_ops_recovered&quot;: &quot;0&quot;,     &quot;translog_ops_percent&quot;: &quot;100.0%&quot;  &#125;#查看仓库级别的进度;只显示正在执行的快照相关操作，已完成的不显示curl -s -X GET &quot;http://localhost:9200/_snapshot/y_repo/_current&quot;|jq#通过 stats.processed_files 和 processed_size_in_bytes 估算剩余时间&#123;  &quot;snapshots&quot;: [    &#123;      &quot;snapshot&quot;: &quot;snapshot_all&quot;,       // 快照名称      &quot;uuid&quot;: &quot;ABC123&quot;,                    // 快照唯一ID      &quot;state&quot;: &quot;IN_PROGRESS&quot;,              // 执行状态      &quot;include_global_state&quot;: true,        // 是否包含集群全局状态      &quot;shards_stats&quot;: &#123;        &quot;initializing&quot;: 0,                 // 初始化中的分片数        &quot;started&quot;: 5,                      // 进行中的分片数        &quot;finalizing&quot;: 0,                   // 最终化中的分片数        &quot;done&quot;: 10,                        // 已完成的分片数        &quot;failed&quot;: 0,                       // 失败的分片数        &quot;total&quot;: 15                        // 总分片数      &#125;,      &quot;stats&quot;: &#123;        &quot;number_of_files&quot;: 100,            // 总文件数        &quot;processed_files&quot;: 80,             // 已处理文件数        &quot;total_size_in_bytes&quot;: 1024000,    // 总字节数        &quot;processed_size_in_bytes&quot;: 819200  // 已处理字节数      &#125;,      &quot;indices&quot;: &#123;                         // 涉及的索引及各自分片状态        &quot;logs-2023&quot;: &#123;          &quot;shards_stats&quot;: &#123; ... &#125;,          &quot;stats&quot;: &#123; ... &#125;        &#125;      &#125;,      &quot;start_time&quot;: &quot;2023-10-05T14:00:00.000Z&quot;,  // 任务开始时间      &quot;end_time&quot;: null                     // 任务结束时间（未完成时为null）    &#125;  ]&#125;\n迁移恢复到其他集群\nesdump直接导出导入即可不多讲\nsnapshot方式需要将fs的物理存储路径拷贝到新节点，然后在新节点es重新注册同名仓库后快照可以直接来使用恢复；如果是nfs或者s3（自建minio这种）这种类型就不需要迁移文件直接注册同名仓库后恢复即可\n\n","categories":["中间件"],"tags":["es"]},{"title":"elfk部署使用","url":"/2025/04/18/elfk/","content":"\nfilebeat不建议容器启动，适合放到每个节点采集日志统一发给logstash；如果全部输出到elasticsearch会导致负载比较高；不建议每个节点用logstash采集因为比较重，filebeat比较轻量级\n\n安装elfkcurl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composeyum install -y https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpmcat &gt;&gt; ./elk.yml &lt;&lt; EOFversion: &#x27;3.8&#x27;services:  elasticsearch:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/elasticsearch:7.14.0    container_name: elasticsearch    environment:      - discovery.type=single-node  # 单节点模式      - ES_JAVA_OPTS=-Xms512m -Xmx512m  # JVM 堆内存限制      - ELASTIC_PASSWORD=Ytest@123  # 设置 Elasticsearch 密码    volumes:      - ./elasticsearch/data:/usr/share/elasticsearch/data  # 数据持久化#      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml  # 自定义配置（可选）    ports:      - &quot;9200:9200&quot;  # REST API      - &quot;9300:9300&quot;  # 集群通信    networks:      - elk  logstash:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/logstash:7.14.0    container_name: logstash    volumes:      - ./logstash/config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf  # 自定义 Logstash 管道配置      - ./logstash/logs:/usr/share/logstash/logs  # 日志持久化    environment:      - LS_JAVA_OPTS=-Xms512m -Xmx512m  # JVM 堆内存限制    ports:      - &quot;5044:5044&quot;  # Beats 输入端口（如 Filebeat）      - &quot;5000:5000/tcp&quot;  # TCP 输入      - &quot;5000:5000/udp&quot;  # UDP 输入    depends_on:      - elasticsearch    networks:      - elk  kibana:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/kibana:7.14.0    container_name: kibana    environment:      - I18N_LOCALE=zh-CN      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200  # 指向 Elasticsearch 服务      - ELASTICSEARCH_USERNAME=elastic  # 默认用户名      - ELASTICSEARCH_PASSWORD=Ytest@123  # 与 Elasticsearch 密码一致    ports:      - &quot;5601:5601&quot;  # Kibana Web 界面    depends_on:      - elasticsearch    networks:      - elknetworks:  elk:    driver: bridgeEOFmkdir ./logstash/config -pcat &gt;&gt; ./logstash/config/logstash.conf &lt;&lt; EOF# ./logstash/config/logstash.confinput &#123;  tcp &#123;    port =&gt; 5000  # 监听 TCP 日志  &#125;  beats &#123;    port =&gt; 5044  # 接收 Filebeat 输入  &#125;&#125;filter &#123;  grok &#123;    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;  # 解析 Apache 日志  &#125;  date &#123;    match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]  # 时间解析  &#125;&#125;output &#123;  elasticsearch &#123;    hosts =&gt; [&quot;elasticsearch:9200&quot;]    user =&gt; &quot;elastic&quot;    password =&gt; &quot;Ytest@123&quot;    index =&gt; &quot;logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引  &#125;&#125;EOFchmod 777 elasticsearch/data\nfilebeat根据不同tag写入不同的logstash后续分割和输出建立索引好区分\nfilebeat.inputs: # filebeat input输入- type: log    # 标准输入  enabled: true  # 启用标准输入  paths:    - /var/log/*  tags: [&quot;system&quot;]  #  fields:  #    type: &quot;system_log&quot;- type: filestream  paths:    - &quot;/var/log/nginx/*.log&quot;  tags: [&quot;nginx&quot;]   # 标记为 nginx 日志#output.console:# enabled: true               # 启用控制台输出  #  pretty: true                # 美化 JSON 格式  # codec.json:  #   pretty: true  # escape_html: false        # 不转义 HTML 符号（保持原始格式） # 输出到 Logstash - 用于生产数据处理output.logstash:  enabled: true               # 启用 Logstash 输出  #  when:  #    equals:  #      fields.type: &quot;system_log&quot;  hosts: [&quot;127.0.0.1:5044&quot;]  # Logstash 的地址和端口（支持多个主机负载均衡）  when.contains:      tags: &quot;system&quot;  # 匹配 tags 包含 &quot;system&quot;  hosts: [&quot;127.0.0.1:5045&quot;]  enabled: true  when.contains:    tags: &quot;nginx&quot;  # 匹配 tags 包含 &quot;nginx&quot;\nlogstash根据不同type进行过滤和输出索引\nLogstash Reference [7.10] | Elasticinput &#123;  tcp &#123;    port =&gt; 5000  # 监听 TCP 日志  &#125;  beats &#123;    port =&gt; 5044  # 接收 Filebeat 输入    type =&gt; &quot;system&quot;  &#125;  beats &#123;    port =&gt; 5045  # 接收 Filebeat 输入    type =&gt; &quot;nginx&quot;  &#125;&#125;   filter &#123;  date &#123;    match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]  # 时间解析  &#125;   if[type] == &quot;nginx&quot; &#123;    grok &#123;      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;HTTPD_COMMONLOG&#125;&quot; &#125;  # 解析 nginx 日志,如果不区分；system类型是解析不了的，会直接报错      remove_field =&gt; [&quot;@version&quot;]     &#125;  &#125;  #对于system类型可以再写个if来单独过滤  if[type] == &quot;system&quot; &#123;    grok &#123;      match =&gt;  &#123;&quot;message&quot; =&gt; &quot;%&#123;IPV4:ip&#125;&quot;&#125;        remove_field =&gt; [&quot;@version&quot;]     &#125;    mutate &#123;  #这里过滤器乱写的，需要根据自身的业务配置        remove_field =&gt; [&quot;timestamp&quot;]        gsub =&gt; [&quot;message&quot;,&quot;\\s&quot;,&quot;| &quot;]        split =&gt; [&quot;message&quot;,&quot;|&quot;]        replace =&gt; &#123; &quot;timenew&quot; =&gt;  &quot;%&#123;+yyyy-MM-dd&#125;&quot; &#125;        add_field =&gt; &#123;         &quot;year&quot; =&gt; &quot;%&#123;+yyyy&#125;&quot;         &quot;month&quot; =&gt; &quot;%&#123;+MM&#125;&quot;         &quot;day&quot; =&gt; &quot;%&#123;+dd&#125;&quot;         &quot;status&quot; =&gt; &quot;%&#123;[message][1]&#125;&quot;         &quot;code&quot; =&gt; &quot;%&#123;[message][2]&#125;&quot;        &#125;    &#125;  &#125;   &#125;#必须通过type指定不同输出创建不同的index =&gt;,否则index的字段不一样，当第一个index结构确定后，第二个输入无法输出到第一个index，因为字段不一样output &#123;  if &quot;system&quot; in [tags] &#123;    elasticsearch &#123;      hosts =&gt; [&quot;elasticsearch:9200&quot;]      user =&gt; &quot;elastic&quot;      password =&gt; &quot;Ytest@123&quot;      index =&gt; &quot;filebeat-system-logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引    &#125;  &#125;    if &quot;nginx&quot; in [tags] &#123;    elasticsearch &#123;      hosts =&gt; [&quot;elasticsearch:9200&quot;]      user =&gt; &quot;elastic&quot;      password =&gt; &quot;Ytest@123&quot;      index =&gt; &quot;filebeat-nginx-logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引    &#125;  &#125;  &#125;\nelasticsearch\n常用语法\n\n&#x2F;_cat &#x2F;_cat&#x2F;master?help&#x2F;_cat&#x2F;indices?v  显示title&#x2F;_cat&#x2F;indiceslogs-2025.03.24 为索引名称&#x2F;logs-2025.03.24&#x2F;_search 查看文档&#x2F;logs-2025.03.24&#x2F; 查看索引结构&#x2F;logs-2025.03.24&#x2F;_doc&#x2F;_search?q&#x3D;message:test\n\n\n","categories":["中间件"]},{"title":"ftp","url":"/2025/07/25/ftp/","content":"主动模式PORT中文称为主动模式，工作的原理： FTP客户端连接到FTP服务器的21端口，发送用户名和密码登录，登录成功后要list列表或者读取数据时，客户端随机开放一个端口（1024以上），发送 PORT命令到FTP服务器，告诉服务器客户端采用主动模式并开放端口；FTP服务器收到PORT主动模式命令和端口号后，通过服务器的20端口和客户端开放的端口连接，发送数据，原理如下图\n被动模式PASV是Passive的缩写，中文成为被动模式，工作原理：FTP客户端连接到FTP服务器的21端口，发送用户名和密码登录，登录成功后要list列表或者读取数据时，发送PASV命令到FTP服务器， 服务器在本地随机开放一个端口（1024以上），然后把开放的端口告诉客户端， 客户端再连接到服务器开放的端口进行数据传输，原理如下图\n从上面的运行原来看到，主动模式和被动模式的不同简单概述为： 主动模式传送数据时是“服务器”连接到“客户端”的端口；被动模式传送数据是“客户端”连接到“服务器”的端口。主动模式需要客户端必须开放端口给服务器，很多客户端都是在防火墙内，开放端口给FTP服务器访问比较困难。被动模式只需要服务器端开放端口给客户端连接就行了,所以推荐被动模式，主动模式可能会被客户端拦截\n","categories":["linux"]},{"title":"iptables防止ddos(cc)","url":"/2025/04/21/iptables%E9%98%B2%E6%AD%A2ddos-cc/","content":"\n基本上发行版都是自带的，轻量级，不需要额外下载Fail2Ban也可以但是需要额外下载\n\n如何配置使用iptables -I INPUT -p tcp --dport 80 -m state --state NEW -m recent --set参数    作用-I INPUT    将规则插入到 INPUT 链的最前面-p tcp --dport 80    匹配目标端口为 80 的 TCP 流量-m state --state NEW    仅匹配 新建连接（如 TCP 的 SYN 包）-m recent --set    将来源 IP 记录到 recent 模块的默认列表（/proc/net/xt_recent/DEFAULT）iptables -I INPUT -p tcp --dport 80 -m state --state NEW -m recent --update --seconds 60 --hitcount 100 -j DROP参数    作用-m recent --update --seconds 60 --hitcount 100    检查 IP 在 60 秒内是否发起超过 100 次新连接-j DROP    若超限，直接丢弃数据包\n\n效果图，到指定次数自动丢弃数据包，端口不通，到达指定时间自动恢复\n经过测试 –hitcount 大于20 会报错\n解决办法echo options xt_recent ip_pkt_list_tot=200 &gt; /etc/modprobe.d/xt.confmodprobe -r xt_recent &amp;&amp; modprobe xt_recent 重新加载查看 lsmod |grep xt  ；cat /sys/module/xt_recent/parameters/ip_pkt_list_tot 对应 xt.conf\n额外补充若其他规则也使用 recent 默认列表，可能导致误判，可以通过–name 指定名称分类\niptables -I INPUT -p tcp –dport 80 -m state –state NEW -m recent –set –name HTTP_CC\niptables -I INPUT -p tcp –dport 80 -m state –state NEW -m recent –update –seconds 60 –hitcount 200 –name HTTP_CC -j DROP\n则 &#x2F;proc&#x2F;net&#x2F;xt_recent&#x2F;HTTP_CC 叫 HTTP_CC\n","categories":["linux"]},{"title":"kubeclt-neat","url":"/2025/07/24/kubeclt-neat/","content":"kubeclt-neat使用\n如果部署的yaml丢失，可以使用kubeclt-neat精简后直接使用导入新的环境，默认的文件有多余的信息是不能直接使用的yum -y install bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrcwget https://github.com/itaysk/kubectl-neat/releases/download/v2.0.3/kubectl-neat_linux_amd64.tar.gztar -zxvf kubectl-neat_linux_amd64.tar.gzmv kubectl-neat /usr/local/bin/kubectl get deploy my-deployment -o yaml | kubectl neat &gt; current-config.yamlkubectl apply -f current-config.yamldiff current-config.yaml new-config.yaml\n\n","categories":["k8s"]},{"title":"miniconda3","url":"/2025/04/21/miniconda3/","content":"\nconda是一个包和环境管理工具，用于创建、管理和切换Python的虚拟环境\n\n安装mkdir -p ~/miniconda3wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.shbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3rm ~/miniconda3/miniconda.shsource ~/miniconda3/bin/activate\n使用1. conda --version #查看conda版本，验证是否安装2. conda update conda #更新至最新版本，也会更新其它相关包3. conda update --all #更新所有包4. conda update package_name #更新指定的包5. conda create -n env_name package_name #创建名为env_name的新环境，并在该环境下安装名为package_name 的包，可以指定新环境的版本号，例如：conda create -n python2 python=python2.7 numpy pandas，创建了python2环境，python版本为2.7，同时还安装了numpy pandas包6. source activate env_name #切换至env_name环境7. source deactivate #退出环境8. conda info -e #显示所有已经创建的环境9. conda create --name new_env_name --clone old_env_name #复制old_env_name为new_env_name10. conda remove --name env_name –all #删除环境11. conda list #查看所有已经安装的包12. conda install package_name #在当前环境中安装包13. conda install --name env_name package_name #在指定环境中安装包14. conda remove -- name env_name package #删除指定环境中的包15. conda remove package #删除当前环境中的包16. conda env remove -n env_name #采用第10条的方法删除环境失败时，可采用这种方法\n\n\n\n两个环境，一个有request一个没有，隔离作用\n镜像源# 查看镜像源conda config --show-sources# 添加镜像源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main# 从镜像源中安装包时显示来源conda config --set show_channel_urls yes# 删除镜像源conda config --remove channels https://XXX# 删除配置的镜像源，使用默认镜像源conda config --remove-key channels\n\n打包运行环境pip install conda-packconda pack -n my_env_name -o out_name.tar.gztar -zxvf 2.7.tar.gz -C 2.7conda info -esource activate my_env_name\n\n","categories":["python"]},{"title":"mq","url":"/2025/08/22/mq/","content":"rabbitMQ\n生产者路由  vhost  &gt;  exchange  &gt;  queue每一个vhost本质上是一个mini版的RabbitMQ服务器，拥有自己的交换机、队列、绑定等，拥有自己的权限机制version: &#x27;3&#x27;services:  rabbitmq:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/mq:rabbit-3-management    container_name: rabbitmq    restart: always    ports:      - &quot;5672:5672&quot;      - &quot;15672:15672&quot;      - &quot;15692:15692&quot;  # Prometheus 监控指标端口（可选）    environment:      RABBITMQ_DEFAULT_USER: admin      RABBITMQ_DEFAULT_PASS: secret      RABBITMQ_DEFAULT_VHOST: /prod  # 指定默认虚拟主机      ABBITMQ_NODE_IP_ADDRESS: 0.0.0.0    volumes:      - rabbitmq_data:/var/lib/rabbitmq  # 持久化数据      - rabbitmq_logs:/var/log/rabbitmq  # 持久化日志    healthcheck:      test: [&quot;CMD&quot;, &quot;rabbitmq-diagnostics&quot;, &quot;status&quot;]      interval: 30s      timeout: 10s      retries: 3volumes:  rabbitmq_data:  rabbitmq_logs:\n简单使用demo#生产者import pikacredentials = pika.PlainCredentials(&#x27;admin&#x27;, &#x27;secret&#x27;)connection = pika.BlockingConnection(    pika.ConnectionParameters(host=&#x27;47.109.136.x&#x27;, port=5672, virtual_host=&#x27;/prod&#x27;, credentials=credentials))channel = connection.channel()channel.queue_declare(queue=&#x27;test_queue&#x27;)channel.basic_publish(exchange=&#x27;&#x27;, routing_key=&#x27;test_queue&#x27;, body=&#x27;Hello from Python!&#x27;)connection.close()#消费者import pikadef callback(ch, method, properties, body):    print(f&quot;Received: &#123;body.decode()&#125;&quot;)credentials = pika.PlainCredentials(&#x27;admin&#x27;, &#x27;secret&#x27;)connection = pika.BlockingConnection(    pika.ConnectionParameters(host=&#x27;47.109.136.x&#x27;, port=5672, virtual_host=&#x27;/prod&#x27;, credentials=credentials))channel = connection.channel()channel.queue_declare(queue=&#x27;test_queue&#x27;)channel.basic_consume(queue=&#x27;test_queue&#x27;, on_message_callback=callback, auto_ack=True)print(&#x27;Waiting for messages...&#x27;)channel.start_consuming()\n关于回调函数class Library:    def __init__(self):        self.callback = None    def register_callback(self, callback_func):        self.callback = callback_func  # 保存函数对象    def trigger_event(self):        if self.callback:            # 在事件发生时调用回调函数，并传入参数            self.callback(&quot;param1&quot;, &quot;param2&quot;)# 用户定义的函数def my_callback(a, b):    print(f&quot;回调触发: &#123;a&#125;, &#123;b&#125;&quot;)# 使用库lib = Library()lib.register_callback(my_callback)  # 传递函数对象lib.trigger_event()  # 输出: 回调触发: param1, param2\n\nkafka\n生产者路由  group  &gt;   topic   &gt;  tag,适合吞吐量很大的场景比如大数据version: &#x27;3&#x27;services:  zookeeper:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/mq:zk-3.8  # Zookeeper 镜像    container_name: zookeeper    ports:      - &quot;2181:2181&quot;    environment:      - ALLOW_ANONYMOUS_LOGIN=yes  # 允许匿名访问（测试用）    networks:      - kafka-net    volumes:      - zookeeper_data:/bitnami/zookeeper  kafka:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/mq:kafka-3.4   # Kafka 镜像    container_name: kafka    ports:      - &quot;9092:9092&quot;    environment:      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181      - ALLOW_PLAINTEXT_LISTENER=yes  # 允许明文监听      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092  # 客户端访问地址    depends_on:      - zookeeper    networks:      - kafka-net    volumes:      - kafka_data:/bitnami/kafkanetworks:  kafka-net:    driver: bridgevolumes:  zookeeper_data:  kafka_data:\n# 创建主题 &quot;test-topic&quot;kafka-topics.sh --create \\  --bootstrap-server localhost:9092 \\  --replication-factor 1 \\  --partitions 1 \\  --topic test-topickafka-topics.sh    --bootstrap-server localhost:9092   --list# 启动生产者，发送消息kafka-console-producer.sh \\  --bootstrap-server localhost:9092 \\  --topic test-topic# 启动消费者，接收消息kafka-console-consumer.sh \\  --bootstrap-server localhost:9092 \\  --topic test-topic \\  --from-beginning# 不同节点的配置差异（以 101 节点为例）broker.id=1  # 102 节点改为 2，103 节点改为 3listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://192.168.1.101:9092  # 修改为当前节点 IP# 所有节点相同配置zookeeper.connect=192.168.1.101:2181,192.168.1.102:2181,192.168.1.103:2181log.dirs=/data/kafka/logsnum.partitions=3  # 默认分区数（建议 &gt;= Broker 数量）default.replication.factor=3  # 默认副本数（建议 = Broker 数量）offsets.topic.replication.factor=3transaction.state.log.replication.factor=3delete.topic.enable=true\n\n","categories":["中间件"]},{"title":"nginx_todo","url":"/2025/07/21/nginx-todo/","content":"proxy_pass转发策略请求url和转发一致后端服务实际处理路径为 /api/upload，与客户端请求路径一致。Nginx配置：location /api/ &#123;         # 匹配客户端请求中的 /api/ 前缀    proxy_pass http://backend;  # 不改变路径，直接转发 /api/xxx 到后端&#125;转发效果：客户端请求 → /api/uploadNginx转发 → http://backend/api/upload\n\n后端服务需要基础路径（去掉&#x2F;api&#x2F;前缀）后端路由示例：后端服务处理根路径 /upload，不需要 /api/ 前缀。Nginx配置：nginxlocation /api/ &#123;    # 通过 rewrite 移除 /api/ 前缀    rewrite ^/api/(.*) /$1 break;      proxy_pass http://backend;  &#125;或location /api/ &#123;    # 直接在 proxy_pass 中追加路径    proxy_pass http://backend/;  # 注意结尾的斜杠&#125;● 转发效果：客户端请求 → /api/uploadNginx转发 → http://backend/upload\n\n转发加url注意点curl http://127.0.0.1/api/client-testlocation /api/ &#123;    proxy_pass http://backend/test/;  # 结尾必须加斜杠&#125;127.0.0.1- - [21/Jul/2025:14:32:45 +0800] &quot;GET /test/client-test HTTP/1.0&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://-127.0.0.1- - [21/Jul/2025:14:32:45 +0800] &quot;GET /api/client-test HTTP/1.1&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://127.0.0.1客户端请求 /api/client-test → 后端路径 /test/client-testcurl http://127.0.0.1/api-test/client-testlocation /api-test/ &#123;    proxy_pass http://backend/test;  # 无斜杠 → 路径合并&#125;127.0.0.1- - [21/Jul/2025:14:32:28 +0800] &quot;GET /testclient-test HTTP/1.0&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://-127.0.0.1- - [21/Jul/2025:14:32:28 +0800] &quot;GET /api-test/client-test HTTP/1.1&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://127.0.0.1客户端请求: http://example.com/api-test/client-test实际转发路径: http://backend/testclient-test\n\n日志记录常用内置变量$http_ 变量可以自定义比如$http_lky 请求头里面有lky:value则$http_lky等于value$args ： #这个变量等于请求行中的参数，同$query_string$content_length ： # 请求头中的Content-length字段。$content_type ： # 请求头中的Content-Type字段。$document_root ： # 当前请求在root指令中指定的值。$host ： # 请求主机头字段，否则为服务器名称。$http_user_agent ：#  客户端agent信息$http_cookie ： # 客户端cookie信息$limit_rate ： # 这个变量可以限制连接速率。$status  # 请求状态$body_bytes_sent # 发送字节$request_method ： # 客户端请求的动作，通常为GET或POST。$remote_addr ： # 客户端的IP地址。$remote_port ： # 客户端的端口。$remote_user ： # 已经经过Auth Basic Module验证的用户名。$request_filename ： # 当前请求的文件路径，由root或alias指令与URI请求生成。$scheme ： # HTTP方法（如http，https）。$server_protocol ： # 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$server_addr ： # 服务器地址，在完成一次系统调用后可以确定这个值。$server_name ： # 服务器名称。$server_port ： # 请求到达服务器的端口号。$request_uri ： # 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。$uri ： # 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。$document_uri ： # 与$uri相同。\n日志配置变量location / &#123;      proxy_pass [$Domain]; #必须      index index.html index.htm index.jsp index.shtml;      proxy_redirect off;      proxy_set_header Host $host;      proxy_set_header Lky $remote_addr;      proxy_set_header REMOTE-HOST $remote_addr;      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;      proxy_set_header X-My-Header &quot;My Value&quot;;      #在日志中使用$http_x_my_header就可以获取到值，可以写死也可以用内置变量比如set自定义      经测试 proxy_set_header 第一个字母必须大写，只能用-不能用_      log_format 日志格式必须是$http开头-需要换成_而且必须全部小写    &#125;log_format custom &#x27;$remote_addr [$time_local] &quot;$request&quot; &#x27;                  &#x27;Lky:$http_lky&#x27; ;access_log /var/log/nginx/access.log custom;#如果是  proxy_pass http://127.0.0.1:83 第一跳记录上游日志包含真实ip，第二条是客户端访问的不包含Lky，一个请求有两个日志输出#127.0.0.1 - - [23/May/2025:16:31:41 +0800] &quot;GET / HTTP/1.0&quot; 200 4833 &quot;-&quot; &quot;curl/7.60.0&quot; &quot;10.0.1.100&quot; 10.0.1.100Lky:&quot;10.0.1.100&quot;#这里的日志可以通过proxy_set_header自定义，比如获取客户端真实IP#10.0.1.100 - - [23/May/2025:16:31:41 +0800] &quot;GET / HTTP/1.1&quot; 200 4833 &quot;-&quot; &quot;curl/7.60.0&quot; &quot;-&quot; 10.0.1.100:83Lky:&quot;-&quot;#这个则是客户端直接请求的日志，因为$remote_addr为空#测试响应头add_header Lky $remote_addr always;GET / HTTP/1.1Host: example.comUser-Agent: Mozilla/5.0Lky: 192.168.1.100\n\n","categories":["中间件"]},{"title":"openvpn","url":"/2025/04/21/openvpn/","content":"安装git clone https://github.com/likaiyuan00/openvpn-install.gitcd openvpn-install &amp;&amp; bash openvpn-install.sh#systemctl start openvpn@client.service 启动的账号密码  auth-user-pass 控制客户端密码验证echo &quot;test test@123&quot; &gt;  /etc/openvpn/userfile.sh\n\n配置文件字段解读server端在#openvpn服务端的监听地址local 0.0.0.0#openvpn服务端的监听端口（默认1194）port 1115#使用的协议，tcp/udpproto tcp#使用三层路由ip隧道（tun），还是二层以太网隧道（tap），一般使用tundev tun#ca证书、服务端证书、服务端秘钥和秘钥交换文件ca /etc/openvpn/server/ca.crtcert /etc/openvpn/server/server.crtkey /etc/openvpn/server/server.keydh /etc/openvpn/server/dh.pem#vpn服务端为自己和客户端分配的ip地址池。#服务端自己获取网段的第一个地址（此处是10.8.0.1），后为客户端分配其他的可用地址。以后客户端就可以和10.8.0.1进行通信。注意：以下网段地址不要和已有网段冲突或重复server 10.8.0.0  255.255.255.0#使用一个文件记录已分配虚拟ip的客户端和虚拟ip的对应关系。以后openvpn重启时，将可以按照此文件继续为对应的客户端分配此前相同的ip（自动续借ip）ifconfig-pool-persist ipp.txt#使用tap模式的时候考虑此选项server-bridge XXXXXX#vpn服务端向客户端推送vpn服务端内网网段的路由配置，以便让客户端能够找到服务端的内网。多条路由写多个push指令push &quot;route 10.0.10.0  255.255.255.0&quot;push &quot;route 192.168.10.0 255.255.255.0&quot;  #允许客户端访问的内网网段#让vpn客户端之间可以通信。默认情况客户端只能服务端进行通信#默认此项是注释的，客户端之间不能相互通信client-to-client#允许多个客户端使用同一个vpn账号连接服务端#默认是注释的，不支持多个客户端登录一个账号duplicate-cn#每10秒ping一次，120秒后没收到ping就说明对方挂了keepalive 10 120#加强认证方式，防攻击。如果配置文件中启用此项（默认是启用的），需要执行openvpn --genkey --secret ta.key，并把ta.key放到/etc/openvpn/server/目录，服务端第二个参数为0；同时客户端也要有此文件，且client.conf中此指令的第二个参数需要为1tls-auth /etc/openvpn/server/ta.key 0#选择一个密码。如果在服务器上使用了cipher选项，那么也必须在这里指定它。注意，v2.4客户端/服务端将在tls模式下自动协商AES-256-GCMcipher AES-256-CBC#openvpn 2.4版本的vpn才能设置此选项。表示服务端启用lz4的压缩功能 ，传输数据给客户端时会压缩数据包。Push后在客户端也配置启用lz4的压缩功能，向服务端发数据时也会压缩。如果是2.4版本以下的老版本，则使用用comp-lzo指令compress lz4-v2push &quot;compress lz4-v2&quot;#启用lzo数据压缩格式，此指令用于低于2.4版本的老版本，且如果服务端配置了该指令，客户端也必须要配置comp-lzo#并发客户端的连接数max-clients 1000#通过ping得知超时时，当重启vpn后将使用同一个秘钥文件以及保持tun连接状态persist-keypersist-tun#在文件中输出当前的连接信息，每分钟截断并重写一次该文件status openvpn-status.log#log指令表示每次启动vpn时覆盖式记录到指定日志文件中#log-append则表示每次启动vpn时追加式的记录到指定日志中#但两者只能选其一，或者不选时记录到rsyslog中log  /var/log/openvpn.loglog-append  /var/log/openvpn.log#日志记录的详细级别verb 3#当服务器重新启动时，通知客户端，以便它可以自动重新连接。仅在UDP协议是可用explicit-exit-notify 1#沉默的重复信息。最多20条相同消息类别的连续消息将输出到日志mute 20\nclient#标识这是个客户端client#使用的协议，tcp/udp，服务端是什么客户端就是什么proto tcp#使用三层路由ip隧道（tun），还是二层以太网隧道（tap），服务端是什么客户端就是什么dev tun#服务端的地址和端口remote 10.0.0.190 1194#一直尝试解析OpenVPN服务器的主机名resolv-retry infinite#大多数客户机不需要绑定到特定的本地端口号nobind#初始化后的降级特权(仅非windows)user nobodygroup nobody#尝试在重新启动时保留某些状态persist-keypersist-tun#ca证书、客户端证书、客户端密钥#如果它们和client.conf或client.ovpn在同一个目录下则可以不写绝对路径，否则需要写绝对路径调用ca ca.crtcert client.crtkey client.key#通过检查certicate是否具有正确的密钥使用设置来验证服务器证书。remote-cert-tls server#加强认证方式，防攻击。服务端有配置，则客户端必须有tls-auth ta.key 1#选择一个密码。如果在服务器上使用了cipher选项，那么您也必须在这里指定它。注意，v2.4客户端/服务器将在TLS模式下自动协商AES-256-GCM。cipher AES-256-CBC# 服务端用的什么，客户端就用的什么#表示客户端启用lz4的压缩功能，传输数据给客户端时会压缩数据包comp-lzo# 日志级别verb 3#沉默的重复信息。最多20条相同消息类别的连续消息将输出到日志mute 20\n\n如何直连openvpn服务端其他局域网服务器\n客户端（10.8.0.10） ping (服务端)172.16.1.7 正常 ping (服务端其他内网机器)172.16.1.8失败\n\n\n第一种方法 配置路由route add -net 10.8.0.0 netmask 255.255.255.0 gw 172.16.1.710.8.0.0  客户端IP172.16.1.7 openvpn 服务端IP\n\n\n\n\n\n\n\n第二种方法使用snat转发 iptables -t nat -A POSTROUTING -d 10.8.0.0&#x2F;24 -o eth0 -j MASQUERADEiptables -A FORWARD -s 10.8.0.0 -j ACCEPT\n\n\n\n额外服务端route 192.168.0.0 255.255.0.0   指令作用是在服务端加一条路由，网关是客户端ip\n服务端只能ping通客户端的tun0的ip，内网ip不行，即使加了路由也不行\n客户端push “route 192.168.10.0 255.255.255.0”作用是在客户端多加一条路由。网关是服务端的tun0IP（也就是server 指令配置分配的地址池）\n","categories":["linux"]},{"title":"prometheus","url":"/2025/04/18/prometheus/","content":"https://github.com/likaiyuan00/k8s-prometheus.git\nk8s-prometheus部署kubernetes_sd_configs配置文件只采集了\n\n1 prometheus*  prometheus-server2 container*   kubelet 的10250端口  &#x2F;metrics&#x2F;cadvisor3 node*    node_exporter4 apiserver*  apiserver 6443 端口 &#x2F;metrics5 kube*  kube-state-metrics组件 8080端口 &#x2F;metrics6 coredns*  kubernetes-pods 自动发现 pod需要配置 prometheus.io&#x2F;scrape: “true” 不然抓取不到 默认flaseprometheus.io&#x2F;path: “&#x2F;metrics”   # 指标路径（默认 &#x2F;metrics 可不写）7 kubelet*  apiserver代理端点 &#x2F;api&#x2F;v1&#x2F;nodes&#x2F;&lt;node-name&gt;&#x2F;proxy&#x2F;metrics其他有需要的可以自行配置\n\n导入镜像，执行yml文件即可\nprometheus效果图\ngrafana效果图\nkubelet 组件 kubelet 三个指标 &#x2F;metrics&#x2F;probes（探针） &#x2F;metrics&#x2F;cadvisor（pod） &#x2F;metrics（node）\n对应apiserver的 &#x2F;api&#x2F;v1&#x2F;nodes&#x2F;${node-name}&#x2F;proxy&#x2F;${url};一般为了减少apiserver的负载不建议使用这种方式 **\n直接访问会报401没有权限\n需要先获取token，上面文件执行完会有一个prometheus用户\npod内token路径为 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token\n通过token再去访问发现就正常了\n/metricscurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metricscurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics\n\n对应kubelet*开头\n/metrics/probes（探针）curl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metrics/probescurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics/probes\n\n/metrics/cadvisor（pod）curl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metrics/cadvisorcurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics/cadvisor\n\n对应container*开头，容器指标\nnode_exporter端口暴露到节点了就不需要token了\nnode*开头，节点指标\nkube-state-metrics集群应用状态监控比较重要的一个需要单独安装使用containerPort: 8080 暴露到节点了不需要token\nkube*开头\napiserver主要是监控apiserver的qps,查询成功率失败率等信息\napiserver*开头\nkubernetes-pods 自动发现如果元数据内设置true，该pod才可以被抓取，默认false\n以coredns为例\n以coredns*开头\n这个自动发现还可以配置自身业务的监控，只有保证开启抓取，和符合prometheus抓取规范就可以，如果开启了prometheus.io&#x2F;scrape 但是pod并没有提供数据指标的能力就会直接报错，如图404\n比如现在我想加一个grafana的数据，只需要添加对应元数据就可以了\nprometheus就自动发现了pod的ip\ngrafana*开头\n","categories":["prometheus"],"tags":["prometheus"]},{"title":"prometheus进阶","url":"/2025/08/22/prometheus%E8%BF%9B%E9%98%B6/","content":"deploy#!/bin/bash# 创建目录结构mkdir -p monitoring/prometheuscd monitoring# 生成docker-compose.yml,node和process必须使用host宿主机网络，不然很多指标只能采集到容器里面的信息不准确cat &gt; docker-compose.yml &lt;&lt; EOFversion: &#x27;3.8&#x27;networks:  monitoring:    driver: bridgeservices:  prometheus:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/prometheus:v2.40.7    container_name: prometheus    restart: unless-stopped    ports:      - &quot;9090:9090&quot;    volumes:      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml      - prom_data:/prometheus    networks:      - monitoring    command:      - &#x27;--config.file=/etc/prometheus/prometheus.yml&#x27;      - &#x27;--storage.tsdb.retention.time=30d&#x27;      - &#x27;--web.enable-lifecycle&#x27; #curl -X POST http://localhost:9090/-/reload  node-exporter:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/nodeexporter:v1.9.1    container_name: node-exporter    restart: unless-stopped    command:      - &#x27;--path.rootfs=/host&#x27;      - &#x27;--web.listen-address=:9400&#x27;   # networks:  # 加入监控网络    #  - monitoring    network_mode: host  # 使用host网络    pid: host    volumes:      - /:/host:ro,rslave  blackbox-exporter:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/nodeexporter:blackbox-exporterv0.27.0    container_name: blackbox-exporter    restart: unless-stopped    ports:      - &quot;9115:9115&quot;    networks:      - monitoring    volumes:      - ./blackbox.yml:/etc/blackbox_exporter/config.yml    command:      - &#x27;--config.file=/etc/blackbox_exporter/config.yml&#x27;  process-exporter:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/nodeexporter:process-exporter-v0.8.7    container_name: process-exporter    restart: unless-stopped    network_mode: host  # 使用host网络   # networks:   #   - monitoring  # 使用统一网络    ports:      - &quot;9256:9256&quot;  # 添加端口映射    volumes:      - /proc:/host/proc:ro      - ./process-exporter.yml:/config.yml    command:      - &#x27;-config.path=/config.yml&#x27;      - &#x27;-procfs=/host/proc&#x27;volumes:  prom_data:EOF# 生成Prometheus配置cat &gt; prometheus/prometheus.yml &lt;&lt;EOFglobal:  scrape_interval: 15s  evaluation_interval: 15sscrape_configs:  - job_name: &#x27;prometheus&#x27;    static_configs:      - targets: [&#x27;localhost:9090&#x27;]  - job_name: &#x27;node&#x27;    static_configs:      - targets: [&#x27;node-exporter:9400&#x27;] #host模式需要换成宿主机ip  - job_name: &#x27;blackbox-http&#x27;    metrics_path: /probe    params:      module: [http_2xx]    static_configs:      - targets:        - https://qq.com        - https://google.com    relabel_configs:      - source_labels: [__address__]        target_label: __param_target      - source_labels: [__param_target]        target_label: instance      - target_label: __address__        replacement: blackbox-exporter:9115  - job_name: &#x27;process-exporter&#x27;    static_configs:      - targets: [&#x27;process-exporter:9256&#x27;] #host模式需要换成宿主机ipEOF# 生成Blackbox配置cat &gt; blackbox.yml &lt;&lt;EOFmodules:  http_2xx:    prober: http    timeout: 5s    http:      valid_http_versions: [&quot;HTTP/1.1&quot;, &quot;HTTP/2&quot;]      valid_status_codes: [200]      method: GET      preferred_ip_protocol: &quot;ip4&quot;EOF# 生成Process Exporter配置cat &gt; process-exporter.yml &lt;&lt;EOFprocess_names:  - name: &quot;&#123;&#123;.Comm&#125;&#125;&quot;    cmdline:    - &#x27;.+&#x27;  # 正则表达式（匹配任何非空内容）  #- name: &quot;&#123;&#123;.Matches&#125;&#125;&quot; #   cmdline: #     - &#x27;nginx&#x27;  # 只监控 nginx 进程 # - name: &quot;&#123;&#123;.Matches&#125;&#125;&quot;  #  cmdline:  #    - &#x27;docker&#x27;  # 只监控 docker 进程EOF# 启动服务docker compose up -decho -e &quot;\\n\\033[32m部署完成！以下是访问信息：\\033[0m&quot;echo &quot;Prometheus:     http://localhost:9090&quot;echo &quot;Node Exporter:  http://localhost:9100/metrics&quot;echo &quot;Blackbox:       http://localhost:9115/metrics&quot;echo &quot;Process-Exporter: http://localhost:9256/metrics&quot;echo -e &quot;\\n请修改以下配置文件后重启服务：&quot;echo &quot;- blackbox.yml 中的监控目标&quot;echo &quot;- process-exporter.yml 中的进程过滤规则&quot;\n\n\n如果节点较多prometheus对所有指标的采集会对负载和磁盘占用较多，可以通过relabel drop不需要的指标，减轻负担#relabel_configs\t抓取前，针对target#metric_relabel_configs 抓取后，针对指标名称scrape_configs:  - job_name: &#x27;node-drop&#x27;     static_configs:      - targets: [&#x27;localhost:9100&#x27;]    metric_relabel_configs:      - source_labels: [__name__]        regex: &#x27;^(node_cpu_seconds_total|node_memory_.*|node_disk_.*|node_network_.*)$&#x27;        action: keep  - job_name: &#x27;node&#x27;    static_configs:      - targets: [&#x27;node1:9100&#x27;, &#x27;node2:9100&#x27;,&#x27;master:9100&#x27;]    relabel_configs:      # 根据目标地址动态添加 environment 标签      - source_labels: [__address__]        regex: &#x27;node1:9100&#x27;        replacement: &#x27;prod&#x27;        target_label: environment      - source_labels: [__address__]        regex: &#x27;node2:9100&#x27;        replacement: &#x27;staging&#x27;        target_label: environment      # 只保留主机名包含 &quot;node&quot; 的目标      - source_labels: [__address__]        regex: &#x27;node[0-9]+:9100&#x27;  # 正则匹配 node1, node2 等        action: keep      - source_labels: [__meta_kubernetes_pod_label_app]        regex: &quot;nginx|api-server&quot;  # 只抓取带有 app=nginx 或 app=api-server 标签的 Pod        action: keep# 仅启用 cpu 和 meminfo 收集器;不好用node_exporter \\  --collector.cpu \\  --collector.meminfo \\  --no-collector.diskstats \\  --no-collector.netdev \\  --no-collector.filesystem \\  # 禁用其他所有收集器...\n\nfile_sd可以基于文件动态更新 prometheus 的监控节点\n#文件类型/etc/prometheus/targets/nodes.json[  &#123;    &quot;targets&quot;: [&quot;192.168.1.10:9100&quot;],  # 监控目标地址（IP:Port）    &quot;labels&quot;: &#123;                        # 自定义标签（可选）      &quot;env&quot;: &quot;prod&quot;,      &quot;role&quot;: &quot;web-server&quot;    &#125;  &#125;,  &#123;    &quot;targets&quot;: [&quot;192.168.1.11:9100&quot;,&quot;192.168.3.11:9100&quot;],    &quot;labels&quot;: &#123;      &quot;env&quot;: &quot;staging&quot;,      &quot;role&quot;: &quot;db-server&quot;    &#125;  &#125;]#prometheus配置scrape_configs:  - job_name: &quot;node-exporter&quot;            # 任务名称    file_sd_configs:                     # 启用 file_sd      - files:          - &quot;/etc/prometheus/targets/*.json&quot;  # 目标文件路径（支持通配符）          - &quot;/etc/prometheus/targets/mysql-exporters/*.json&quot; # MySQL 监控        refresh_interval: 5m             # 重新加载间隔（默认 5m）\nnode exporter textfile#!/bin/bashDURATION=15         # 默认抓包时长（建议比 cron 间隔稍短）INTERFACE=&quot;eth0&quot;OUTPUT_FILE=&quot;/tmp/traffic.pcap&quot;METRICS_FILE=&quot;/etc/node-exporter/textfile-collector/network_traffic.prom&quot;  # Node Exporter 收集目录# 安装依赖（如未安装）if ! command -v tcpdump &amp;&gt;/dev/null || ! command -v tshark &amp;&gt;/dev/null; then    echo &quot;安装依赖: tcpdump 和 tshark...&quot;    sudo apt-get update &amp;&amp; sudo apt-get install -y tcpdump tsharkfi# 捕获流量sudo timeout $DURATION tcpdump -i $INTERFACE -w $OUTPUT_FILE &gt;/dev/null 2&gt;&amp;1# 生成 Prometheus 格式的指标sudo tshark -r $OUTPUT_FILE -T fields -e ip.src -e ip.dst -e frame.len 2&gt;/dev/null \\  | awk &#x27;    BEGIN &#123;        total_bytes = 0        delete bytes  # 清空数组    &#125;    &#123;        bytes[$1] += $3;  # 源IP统计        bytes[$2] += $3;  # 目的IP统计        total_bytes += $3    &#125;    END &#123;        # 输出总流量指标        print &quot;network_traffic_total_bytes &quot; total_bytes        # 输出每个IP的流量指标        for (ip in bytes) &#123;            if (ip != &quot;&quot;) &#123;  # 过滤空值                printf &quot;network_traffic_bytes&#123;ip=\\&quot;%s\\&quot;&#125; %d\\n&quot;, ip, bytes[ip]            &#125;        &#125;    &#125;&#x27; &gt; &quot;$METRICS_FILE.$$&quot;  # 先写入临时文件# 原子操作替换文件（避免读取半成品）sudo mv &quot;$METRICS_FILE.$$&quot; &quot;$METRICS_FILE&quot;# 清理sudo rm -f &quot;$OUTPUT_FILE&quot;./node_exporter  --web.listen-address=&quot;:900&quot; --collector.textfile.directory=/etc/node-exporter/textfile-collector/\n\n\n\n\n\n\n\nblackbox_exporter#blackbox.yml配置，prober类型可以自定义http,tcp,icmp,dnsmodules:  http_2xx:    prober: http    timeout: 5s    http:      valid_http_versions: [&quot;HTTP/1.1&quot;, &quot;HTTP/2&quot;]      valid_status_codes: [200]      method: GET      preferred_ip_protocol: &quot;ip4&quot;  ssh_banner_check:  # 自定义模块名    prober: tcp    timeout: 10s    tcp:      query_response:        - expect: &quot;^SSH-2.0-OpenSSH&quot;          send: &quot;SSH-2.0-blackbox-ssh-check&quot;      preferred_ip_protocol: &quot;ip4&quot;# prometheus集成scrape_configs: - job_name: &#x27;blackbox-http&#x27;    metrics_path: /probe    params:      module: [http_2xx]    static_configs:      - targets:        - https://qq.com        - https://google.com    relabel_configs: &amp;common_relabel      - source_labels: [__address__]        target_label: __param_target      - source_labels: [__param_target]        target_label: instance      - target_label: __address__        replacement: blackbox-exporter:9115  - job_name: &#x27;blackbox-ssh&#x27;    metrics_path: /probe    params:      module: [ssh_banner_check]  # 对应TCP模块    static_configs:      - targets:        - &#x27;127.0.0.1:22&#x27;        - &#x27;10.0.1.122:22&#x27;    relabel_configs: *common_relabel#relabel_configs配置解析Prometheus 抓取任务生成│├─ 原始目标: example.com:80│  ││  ├─ relabel 规则1: 将地址赋值给 __param_target → ?target=example.com:80│  ├─ relabel 规则2: 用 __param_target 标记 instance → instance=&quot;example.com:80&quot;│  └─ relabel 规则3: 重写地址 → 实际请求发送到 Blackbox Exporter│     ││     └─ Blackbox Exporter 收到请求，解析参数后探测 example.com:80│└─ 原始目标: google.com:443   └─ 同理生成请求 http://192.168.100.100:9115/probe?target=google.com:443&amp;module=http_2xx#告警ingprobe_success&#123;job=&quot;blackbox-http&quot;&#125; == 0#状态码probe_http_status_code&#123;job=&quot;blackbox-http&quot;&#125; &lt; 200 or probe_http_status_code&#123;job=&quot;blackbox-http&quot;&#125; &gt;= 300#证书过期时间probe_ssl_earliest_cert_expiry&#123;job=&quot;blackbox-http&quot;&#125; - time() &lt; 86400 * 30  # 30天#tcp端口是否通probe_success&#123;job=&quot;blackbox-tcp&quot;&#125; == 0#响应时长probe_duration_seconds&#123;job=&quot;blackbox-http&quot;&#125; &gt; 1#解析时长probe_dns_lookup_time_seconds\n\n\n\n\n\nprocess-exporter&#123;&#123;.Comm&#125;&#125; 包含原始可执行文件的基本名称，即 /proc/&lt;pid&gt;/stat 中的第 2 个字段，并截取前15个字符&#123;&#123;.ExeBase&#125;&#125; 包含可执行文件的基本名称  &#123;&#123;.ExeFull&#125;&#125; 包含可执行文件的完全限定路径  &#123;&#123;.Username&#125;&#125; 包含有效用户的用户名  &#123;&#123;.Matches&#125;&#125; map 包含应用 cmdline 正则表达式产生的所有匹配项&#123;&#123;.PID&#125;&#125; 包含进程的 PID。请注意，使用 PID 意味着该组将仅包含一个进程&#123;&#123;.StartTime&#125;&#125; 包含进程的开始时间。这与 PID 结合使用时非常有用，因为 PID 会随着时间的推移而被重用。&#123;&#123;.Cgroups&#125;&#125; 包含（如果支持）进程的 cgroups （/proc/self/cgroup）。这对于识别进程属于哪个容器特别有用#process-exporter.yml#常用的就comm和exefull,matchesprocess_names:  #- name: &quot;&#123;&#123;.ExeFull&#125;&#125;&quot;   #  cmdline:  #  - &#x27;.+&#x27;  # 正则表达式（匹配任何非空内容）不常用太多了影响资源消耗  - name: &quot;&#123;&#123;.Comm&#125;&#125;&quot; #groupname=&quot;docker&quot;    cmdline:    - &#x27;docker*&#x27;   - name: &quot;&#123;&#123;.Matches&#125;&#125;&quot; #groupname=&quot;map[:nginx]&quot;    cmdline:    - &#x27;nginx*&#x27;   - name: &quot;&#123;&#123;.ExeFull&#125;&#125;&quot;  #groupname=&quot;/usr/sbin/mysqld    cmdline:    - &#x27;mysql*&#x27;                #告警...namedprocess_namegroup_num_procs&#123;groupname!~&quot;.*process-exporter.*&quot;&#125; == 0namedprocess_namegroup_states&#123;state=&quot;Z&quot;&#125; &gt; 0namedprocess_namegroup_num_procs&#123;groupname=&quot;nginx&quot;&#125; == 0#cpu百分比100 * rate(namedprocess_namegroup_cpu_seconds_total&#123;groupname=&quot;java&quot;&#125;[5m])100 * rate(namedprocess_namegroup_cpu_seconds_total&#123;&#125;[5m]) &gt; 50#内存 mbnamedprocess_namegroup_memory_bytes&#123;groupname=&quot;java&quot;&#125; / 1024^2除于#节点内存 就是占用内存百分比node_memory_MemTotal_bytes / 1024 / 1024 # 读速率 MB/Srate(namedprocess_namegroup_read_bytes_total&#123;groupname=&quot;mysql&quot;&#125;[5m]) / 1024^2# 写速率rate(namedprocess_namegroup_write_bytes_total&#123;groupname=&quot;mysql&quot;&#125;[5m]) / 1024^2\n\nprometheus联邦\n数量较多的情况下从多个下级 Prometheus 实例中提取特定指标，汇总到中心 Prometheus                Central Prometheus                        ↑        从多个下级拉取聚合后的指标                        |        +---------------+---------------+        |               |               |   Region A       Region B       Region C   Prometheus    Prometheus    Prometheusscrape_configs:  - job_name: &#x27;federate-regions&#x27;        # 任务名称    scrape_interval: 1m                # 建议比下级采集间隔长    honor_labels: true                 # 保留下级标签（避免覆盖）    metrics_path: &#x27;/federate&#x27;          # 联邦接口路径    params:      &#x27;match[]&#x27;:        - &#x27;&#123;job=&quot;api-server&quot;&#125;&#x27;         # 拉取下级的指定 job 指标        - &#x27;&#123;__name__=~&quot;job:.*&quot;&#125;&#x27;        - &#x27;up&#123;instance=~&quot;.+&quot;&#125;&#x27;         # 拉取所有下级实例的 up 状态    static_configs:      - targets:          - &#x27;prometheus-region-a:9090&#x27; # 下级 Prometheus 地址          - &#x27;prometheus-region-b:9090&#x27;          - &#x27;prometheus-region-c:9090&#x27;match[] 过滤条件精确匹配：&#x27;&#123;job=&quot;mysql&quot;&#125;&#x27; 拉取所有 job=mysql 的指标。正则匹配：&#x27;__name__=~&quot;http_request_.+&quot;&#x27; 拉取以 http_request_ 开头的指标。组合条件：&#x27;&#123;env=&quot;prod&quot;, app=~&quot;web|api&quot;&#125;&#x27; 拉取 prod 环境下 web 或 api 应用的指标。\n\n","categories":["prometheus"]},{"title":"proxysql","url":"/2025/08/19/proxysql/","content":"\nproxysql是一款代理数据库的开源软件，此外还有maxsaclehttps://github.com/sysown/proxysql\n\n搭建读写分离mkdir -p proxysql &amp;&amp; cd proxysqlmkdir -p mysql/&#123;master,proxysql,slave&#125;/conf#proxysql.cnf配置datadir=&quot;/var/lib/proxysql&quot;mysql_servers =(    &#123;        address = &quot;mysql-master&quot;        port = 3306        hostgroup = 10  # 写组        max_connections = 200    &#125;,    &#123;        address = &quot;mysql-slave&quot;        port = 3306        hostgroup = 20  # 读组      #  weight = 110        max_connections = 1000    &#125;,    #  &#123;  #      address = &quot;mysql-slave2&quot;   # 从库2  #      port = 3306  #      hostgroup_id = 20   #     weight = 100  #      max_connections = 500   # &#125;)#CREATE USER &#x27;appuser&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;AppUser123!&#x27;;#GRANT ALL PRIVILEGES ON *.* TO &#x27;appuser&#x27;@&#x27;%&#x27;;mysql_users =(    &#123;        username = &quot;appuser&quot; #后端mysql的用户        password = &quot;AppUser123!&quot;        default_hostgroup = 10    &#125;)mysql_query_rules =(    &#123;        rule_id = 100 #规则唯一标识符，数值越小优先级越高        active = 1  #规则是否启用：1 启用，0 禁用        match_pattern = &quot;^SELECT&quot; #匹配读请求        destination_hostgroup = 20 #匹配的 SQL 请求路由到的主机组        apply = 1 #是否在匹配后终止后续规则匹配：1 终止，0 继续    &#125;,    &#123;        rule_id = 200        active = 1        match_pattern = &quot;^((?!SELECT).)*$&quot;         destination_hostgroup = 10        apply = 1    &#125;)#docker exec -it proxysql-proxysql-1 mysql -uadmin -padmin -h127.0.0.1 -P6032#6032是管理端口，显示的是proxysql的元数据表，#可以通过环境变量修改默认密码admin#UPDATE global_variables SET variable_value=&#x27;admin:new_password&#x27; WHERE variable_name=&#x27;admin-admin_credentials&#x27;;#SELECT * FROM global_variables  WHERE variable_name LIKE &#x27;admin-admin_%&#x27;;#mysql -uappuser -pAppUser123! -h127.0.0.1 -P6033 #6033是服务端口，直接可以路由到后端mysql#master配置[mysqld]server_id = 1log_bin = mysql-binbinlog_format = ROW#slave配置[mysqld]server_id = 2relay_log = mysql-relay-binread_only = 1#======================================================================================cat &gt;&gt; docker-compose.yaml &lt;&lt; &#x27;EOF&#x27;version: &#x27;3.8&#x27;services:  mysql-master:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/mysql:8.0.43    networks:      - mysql-network    environment:      MYSQL_ROOT_PASSWORD: MasterRoot123!      MYSQL_REPLICATION_USER: repl      MYSQL_REPLICATION_PASSWORD: ReplPass123!    volumes:      - ./mysql/master/conf:/etc/mysql/conf.d      - ./mysql/master/data:/var/lib/mysql    command:      - --character-set-server=utf8mb4      - --collation-server=utf8mb4_unicode_ci  mysql-slave:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/mysql:8.0.43    networks:      - mysql-network    environment:      MYSQL_ROOT_PASSWORD: SlaveRoot123!    volumes:      - ./mysql/slave/conf:/etc/mysql/conf.d      - ./mysql/slave/data:/var/lib/mysql    command:      - --character-set-server=utf8mb4      - --collation-server=utf8mb4_unicode_ci  proxysql:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/mysql:proxysql    networks:      - mysql-network    ports:      - &quot;6033:6033&quot;      - &quot;6032:6032&quot;    volumes:      - ./mysql/proxysql/proxysql.cnf:/etc/proxysql.cnf    depends_on:      - mysql-master      - mysql-slavenetworks:  mysql-network:    driver: bridgeEOF#===================================================================================#配置主从复制#8.4版本以上语法 SHOW BINARY LOG STATUS;docker exec -it proxysql-mysql-master-1 mysql -uroot -p&quot;MasterRoot123!&quot; -e \\&quot;CREATE USER &#x27;repl&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;ReplPass123!&#x27;; \\GRANT REPLICATION SLAVE ON *.* TO &#x27;repl&#x27;@&#x27;%&#x27;; \\FLUSH PRIVILEGES; \\SHOW MASTER STATUS;&quot;#MASTER_LOG_POS可以通过 SHOW MASTER STATUS;在master节点执行查看docker exec -it proxysql-mysql-slave-1 mysql -uroot -pSlaveRoot123! -e \\&quot;CHANGE MASTER TO \\MASTER_HOST=&#x27;mysql-master&#x27;, \\MASTER_USER=&#x27;repl&#x27;, \\MASTER_PASSWORD=&#x27;ReplPass123!&#x27;, \\MASTER_LOG_FILE=&#x27;mysql-bin.000003&#x27;, \\MASTER_LOG_POS=827; \\START SLAVE; \\SHOW SLAVE STATUS\\G&quot;#SHOW MASTER STATUS;#SHOW SLAVE STATUS;#SHOW BINARY LOGS;#SHOW BINLOG EVENTS;#show binlog events in &#x27;mysql-bin.000002&#x27; from 219 limit 5;#reset master; #清空所有binlog#flush logs;  #刷新binlog，直接生成新的binlog文件#SHOW VARIABLES LIKE &quot;%expire_logs_days%&quot;;    #binlog保存多久 #SHOW VARIABLES LIKE &#x27;binlog_expire_logs_seconds&#x27;; 优先级比expire_logs_days高#SHOW VARIABLES LIKE &quot;%max_binlog%&quot;;  #单个binlog到多大开始生成新的#================================================================================#创建proxysql的监控后端mysql用户，注意只需要在master节点执行，因为已经主从同步了，不然主从会报错停止-- 创建监控用户CREATE USER &#x27;monitor&#x27;@&#x27;%&#x27; IDENTIFIED  BY &#x27;MonitorPass123!&#x27;;-- 授予必要权限（ProxySQL 健康检查需要）GRANT USAGE, REPLICATION CLIENT ON *.* TO &#x27;monitor&#x27;@&#x27;%&#x27;;-- grant all privileges on *.* to &#x27;monitor&#x27;@&#x27;%&#x27; with grant option;-- 刷新权限FLUSH PRIVILEGES;#登录proxysqldocker exec -it proxysql-proxysql-1 mysql -uadmin -padmin -h127.0.0.1 -P6032#proxysql监控用户名和密码默认都是monitor，可以通过以下语句查看SELECT * FROM global_variables WHERE variable_name IN (&#x27;mysql-monitor_username&#x27;, &#x27;mysql-monitor_password&#x27;);#修改密码UPDATE global_variables SET variable_value=&#x27;MonitorPass123!&#x27;WHERE variable_name=&#x27;mysql-monitor_password&#x27;;load mysql variables to runtime;save mysql variables to disk;#proxysql的相关元数据表SELECT hostgroup_id, hostname, status FROM main.mysql_servers;;hostgroup_id：服务器所属主机组（如读写分离的读组 20 和写组 10）。hostname：服务器地址（IP 或域名）。status：节点状态，如 ONLINE（正常）、OFFLINE_SOFT（软下线）、OFFLINE_HARD（硬下线）、SHUNNED（临时屏蔽）SELECT hostgroup, username, digest_text,count_star,sum_time FROM stats.stats_mysql_query_digest;digest_text：归一化后的 SQL 模板（如 SELECT * FROM users WHERE id=?）。count_star：该 SQL 模板的执行次数。sum_time：该 SQL 模板的总耗时（微秒）。hostgroup：请求路由到的主机组。username：执行 SQL 的客户端用户。SELECT * FROM global_variables WHERE variable_name LIKE &#x27;mysql-monitor%&#x27;;mysql-monitor_username：监控用户（需在后端 MySQL 存在并授权）。mysql-monitor_ping_interval：Ping 检查间隔（毫秒）。mysql-monitor_read_only_interval：检查主库只读状态的频率。SELECT * FROM monitor.mysql_server_connect_log   ORDER BY time_start_us DESC           LIMIT 3;connect_error：失败原因（如超时、权限拒绝）。time_start_us：连接开始时间（微秒精度）。\n\n主从同步如果报错#主从错误，在主库创建完用户从库就不用创建了，不然冲突主从就停止了#可以通过以下命令查询导致主从停止的语句，并且修改SELECT * FROM performance_schema.replication_applier_status_by_worker\\G#重新启动STOP REPLICA;START REPLICA;\n","categories":["中间件"]},{"title":"python ThreadPoolExecutor","url":"/2025/08/26/python-ThreadPoolExecutor/","content":"并发执行方法对比（submit&#x2F;as_completed&#x2F;map）核心特性对比表\n\n\n特征\nexecutor.map()\nsubmit+顺序处理\nas_completed\n\n\n\n执行顺序\n并发执行\n并发执行\n并发执行\n\n\n结果顺序\n保持输入顺序\n保持提交顺序\n按完成顺序\n\n\n异常处理\n遇到第一个异常立即抛出\n可逐个处理异常\n可单独处理每个任务异常\n\n\n代码复杂度\n★☆☆ 最简单\n★★☆ 中等\n★★★ 最灵活\n\n\n内存消耗\n低（惰性迭代）\n高（需存储所有future）\n中（动态处理）\n\n\n进度反馈\n无法实时获取\n需手动实现\n自动实时反馈\n\n\n适用场景\n简单转换&#x2F;批量处理\n需要严格顺序的结果\n需要及时处理完成的场景\n\n\n\n方法详解1. executor.map()典型用法：\nfrom concurrent.futures import ThreadPoolExecutordef process_data(x):    return x * 2with ThreadPoolExecutor() as executor:    results = executor.map(process_data, [1, 2, 3])  # 保持输入顺序    for res in results:        print(res)  # 按1→2→3的顺序输出2,4,6#示例下载有顺序的小说def download_chapter(index, url):    # 模拟下载（并行，执行顺序不确定）    return (index, f&quot;第 &#123;index&#125; 章内容&quot;)# 通过bs4获取列表，输入是有序的章节列表chapters = [    (1, &quot;http://example.com/ch1&quot;),    (2, &quot;http://example.com/ch2&quot;),    (3, &quot;http://example.com/ch3&quot;)]with ThreadPoolExecutor(max_workers=3) as executor:    # 提交任务（按顺序）    results = executor.map(        lambda args: download_chapter(*args),        chapters    )    # 拆解元组参数为独立的参数    lambda args: download_chapter(*args)    # 等效于：    # def unpack_and_call(args):    #     return download_chapter(args[0], args[1])  # 解包元组    # 按输入顺序写入文件    with open(&quot;book.txt&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:        for index, content in results:            f.write(f&quot;&#123;content&#125;\\n&quot;)\n\n特点：\n\n自动将可迭代参数映射到函数\n结果顺序与输入参数严格一致\n遇到第一个异常时会立即停止迭代\n\n最佳场景：\n\n数据并行转换（如批量图片压缩）\n需要保持输入输出顺序对应的任务\n\n\n2. submit + 顺序处理典型用法：参数必须是可迭代对象，如 i for i in range(1, 4)；submit不需要因为是手动提交\ndef multiply(x, y):    return x * ywith ThreadPoolExecutor() as executor:    # 生成器作为可迭代对象    nums1 = (i for i in range(1, 4))    nums2 = (i for i in range(10, 13))    results = executor.map(multiply, nums1, nums2)    print(list(results))  # 输出 [10, 22, 36]# 提交单个任务，参数直接传递，可以不用是列表future = executor.submit(multiply, 2, 3)print(future.result())  # 输出 8#示例代码，不同任务 定义三类不同参数的任务函数def download(url, timeout):    &quot;&quot;&quot;模拟下载任务（参数：URL + 超时时间）&quot;&quot;&quot;    print(f&quot;开始下载: &#123;url&#125;, 超时设置: &#123;timeout&#125;秒&quot;)    time.sleep(random.uniform(0.5, 2))    if random.random() &lt; 0.2:        raise URLError(f&quot;无法访问 &#123;url&#125;&quot;)    return f&quot;下载完成: &#123;url&#125;&quot;def calculate(a, b, operator):    &quot;&quot;&quot;模拟计算任务（参数：两个数 + 运算符）&quot;&quot;&quot;    print(f&quot;计算: &#123;a&#125; &#123;operator&#125; &#123;b&#125;&quot;)    time.sleep(0.5)    if operator == &quot;+&quot;:        return a + b    elif operator == &quot;*&quot;:        return a * b    else:        raise ValueError(f&quot;不支持的运算符: &#123;operator&#125;&quot;)def log_message(message, priority=&quot;INFO&quot;):    &quot;&quot;&quot;模拟日志任务（参数：消息 + 优先级）&quot;&quot;&quot;    print(f&quot;[&#123;priority&#125;] 记录日志: &#123;message&#125;&quot;)    time.sleep(0.1)    return f&quot;日志已保存: &#123;message&#125;&quot;if __name__ == &quot;__main__&quot;:    with ThreadPoolExecutor(max_workers=3) as executor:        futures = []        # 动态提交不同类型的任务        # 任务1：下载任务（参数：url, timeout）        futures.append(executor.submit(download, &quot;https://example.com&quot;, timeout=3))        # 任务2：计算任务（参数：5, 3, &quot;+&quot;）        futures.append(executor.submit(calculate, 5, 3, &quot;+&quot;))        # 任务3：日志任务（参数：message=&quot;系统启动&quot;, priority=&quot;HIGH&quot;）        futures.append(executor.submit(log_message, &quot;系统启动&quot;, &quot;HIGH&quot;))        # 动态追加任务（根据条件）        if random.choice([True, False]):            # 任务4：随机添加一个计算任务（参数：8, 4, &quot;*&quot;）            futures.append(executor.submit(calculate, 8, 4, &quot;*&quot;))        # 处理结果（按完成顺序，独立捕获异常）        for future in futures:            try:                result = future.result()                print(f&quot;结果: &#123;result&#125;&quot;)            except URLError as e:                print(f&quot;下载失败: &#123;e.reason&#125;&quot;)            except ValueError as e:                print(f&quot;计算错误: &#123;e&#125;&quot;)            except Exception as e:                print(f&quot;未知错误: &#123;e&#125;&quot;)\n\n特点：\n\n手动控制每个任务的提交\n结果处理顺序固定\n可以单独处理每个任务的异常\n\n最佳场景：\n\n需要跟踪任务来源的场景\n需要逐步处理结果的日志系统\n\n\n3. as_completed典型用法：\nfrom concurrent.futures import as_completedfutures = [executor.submit(task, param) for param in params]for future in as_completed(futures):    res = future.result()    print(f&quot;收到结果: &#123;res&#125;&quot;)  # 按完成顺序输出\n\n特点：\n\n实时获取已完成任务结果\n可以优先处理耗时短的任务\n需要额外维护future列表\n\n最佳场景：\n\n文件下载（小文件优先完成）\n实时仪表盘更新\n需要快速获取部分结果的场景\n\n\n性能特征对比模拟耗时任务（3个任务分别需要3s&#x2F;1s&#x2F;2s）import timefrom concurrent.futures import ThreadPoolExecutor, as_completeddef task(sec):    time.sleep(sec)    return f&quot;&#123;sec&#125;秒任务&quot;params = [3, 1, 2]\n\n\n\n\n方法\n输出顺序\n总耗时\n首个结果时间\n\n\n\nmap\n3→1→2\n3s\n3s后\n\n\nsubmit顺序处理\n3→1→2\n3s\n3s后\n\n\nas_completed\n1→2→3\n3s\n1s后\n\n\n\n总结对比\n\n\n维度\nmap\nsubmit+顺序\nas_completed\n\n\n\n代码简洁度\n最简洁（自动管理）\n中等（需手动维护）\n最复杂（需动态处理）\n\n\n结果顺序\n输入顺序\n提交顺序\n完成顺序\n\n\n实时反馈\n无\n无\n有\n\n\n异常容忍度\n低（遇到错误立即停止）\n高（可单独处理）\n高（可单独处理）\n\n\n内存效率\n高（惰性迭代）\n低（全存储）\n中（动态释放）\n\n\n","categories":["python"]},{"title":"python as_completed","url":"/2025/08/26/python-as-completed/","content":"as_completed 方法详解🎯 核心区别：处理顺序\n\n\n方法\n执行顺序\n结果获取顺序\n适用场景\n\n\n\nsubmit + 顺序处理\n按提交顺序执行\n按提交顺序获取\n需要严格保持结果顺序的场景\n\n\nas_completed\n并行执行\n按完成顺序获取\n需要及时处理已完成任务的场景\n\n\n\n📌 使用场景分析1. submit + 顺序处理典型代码：\nfrom concurrent.futures import ThreadPoolExecutorwith ThreadPoolExecutor() as executor:    futures = [executor.submit(task, param) for param in params_list]    for future in futures:  # 按提交顺序处理        print(future.result())\n\n特点：\n\n必须等待前一个任务完成才能处理下一个\n严格保持任务提交顺序\n适合场景：\n日志处理需要按时间顺序记录\n结果需要顺序写入文件&#x2F;数据库\n\n\n\n\n2. as_completed典型代码：\nfrom concurrent.futures import as_completedwith ThreadPoolExecutor() as executor:    futures = [executor.submit(task, param) for param in params_list]    for future in as_completed(futures):  # 按完成顺序处理        print(future.result())\n\n特点：\n\n优先处理最快完成的任务\n不保证结果顺序\n适合场景：\n需要实时显示进度条\n处理时间差异大的任务（如不同大小的文件下载）\n快速获取部分可用结果（如爬虫先抓取先分析）\n\n\n\n\n🧪 性能对比实验模拟耗时任务import timefrom concurrent.futures import ThreadPoolExecutor, as_completeddef task(n):    time.sleep(n)  # 模拟耗时操作    return f&quot;任务 &#123;n&#125;s 完成&quot;if __name__ == &quot;__main__&quot;:    times = [3, 1, 2]  # 三个任务分别需要3秒、1秒、2秒        with ThreadPoolExecutor() as executor:        futures = [executor.submit(task, t) for t in times]                print(&quot;--- 使用 as_completed ---&quot;)        start = time.time()        for f in as_completed(futures):            print(f&quot;&#123;time.time()-start:.1f&#125;s 收到: &#123;f.result()&#125;&quot;)                print(&quot;\\n--- 按提交顺序处理 ---&quot;)        start = time.time()        for f in futures:            print(f&quot;&#123;time.time()-start:.1f&#125;s 收到: &#123;f.result()&#125;&quot;)\n\n实验结果--- 使用 as_completed ---1.0s 收到: 任务 1s 完成2.0s 收到: 任务 2s 完成3.0s 收到: 任务 3s 完成--- 按提交顺序处理 ---3.0s 收到: 任务 3s 完成3.0s 收到: 任务 1s 完成3.0s 收到: 任务 2s 完成\n\n\n💡 最佳实践建议1. 优先使用 as_completed 当：✅ 需要实时显示进度状态✅ 任务执行时间差异较大（如同时处理图片缩略图和4K视频）✅ 不需要保持结果顺序（如独立的数据抓取任务）\n2. 使用顺序处理当：⛔ 必须保持结果顺序（如时间序列数据分析）⛔ 后续任务依赖前序结果（如分步骤数据处理流水线）⛔ 需要严格控制资源使用（如顺序写入数据库）\n3. 混合使用技巧# 同时获取结果和原始任务索引for future in as_completed(futures):    original_index = futures.index(future)  # 获取提交时的顺序索引    result = future.result()    print(f&quot;第 &#123;original_index&#125; 个提交的任务完成：&#123;result&#125;&quot;)\n\n\n📚 扩展知识concurrent.futures 模块对比\n\n\n方法\n特点\n适用场景\n\n\n\nThreadPoolExecutor\n使用线程池，适合IO密集型任务\n网络请求&#x2F;文件操作等\n\n\nProcessPoolExecutor\n使用进程池，适合CPU密集型任务\n数学计算&#x2F;图像处理等\n\n\n# 进程池用法（接口与线程池一致）\nfrom concurrent.futures import ProcessPoolExecutor\nwith ProcessPoolExecutor() as executor:\n    ...\n\n","categories":["python"]},{"title":"python threading","url":"/2025/08/26/python-threading/","content":"threading.Thread\n适用场景：任务逻辑差异大；每个线程需要执行完全不同的逻辑\n三个比较重要的参数\n\n\n锁：threading.Lock()两种使用方法推荐with下方演示，第二种手动加锁lock.acquire()，然后释放lock.release()\n#未使用的情况下def sing():    #with stats_lock:        for i in range(3):            print(&quot;正在唱歌...%d&quot;%i)            sleep(1)def dance():    #with stats_lock:        for i in range(3):            print(&quot;正在跳舞...%d&quot;%i)            sleep(1)if __name__ == &#x27;__main__&#x27;:    print(&#x27;---开始---:%s&#x27;%ctime())    t1 = threading.Thread(target=sing)    t2 = threading.Thread(target=dance)    t1.start()    t2.start()#输出是混乱的就是因为没有给线程加锁---开始---:Tue Aug 26 10:19:56 2025正在唱歌...0正在跳舞...0正在唱歌...1正在跳舞...1正在跳舞...2正在唱歌...2======================================================================#加锁后import threadingfrom time import sleep,ctimestats_lock = threading.Lock()def sing():    with stats_lock:        #stats_lock.acquire()        for i in range(3):            print(&quot;正在唱歌...%d&quot;%i)            sleep(1)        #stats_lock.release()def dance():    with stats_lock:        for i in range(3):            print(&quot;正在跳舞...%d&quot;%i)            sleep(1)if __name__ == &#x27;__main__&#x27;:    print(&#x27;---开始---:%s&#x27;%ctime())    t1 = threading.Thread(target=sing)    t2 = threading.Thread(target=dance)    t1.start()    t2.start()#输出正常---开始---:Tue Aug 26 10:23:18 2025正在唱歌...0正在唱歌...1正在唱歌...2正在跳舞...0正在跳舞...1正在跳舞...2\n\n\n\n线程中的join等待阻塞函数\n\n\n\n当有线程在统计信息时，必须等待执行完成才可以import threadingfrom time import sleep,ctimestats_lock = threading.Lock()def sing(num):    with stats_lock:        for i in range(num):            print(&quot;正在唱歌...%d&quot;%i)            sleep(1)def dance(num):    with stats_lock:        for i in range(num):            print(&quot;正在跳舞...%d&quot;%i)            sleep(1)if __name__ == &#x27;__main__&#x27;:    print(&#x27;---开始---:%s&#x27;%ctime())    t1 = threading.Thread(target=sing,args=(3,),name=&quot;唱歌线程&quot;)    t2 = threading.Thread(target=dance,args=(3,))    t1.start()    t2.start()    # t1.join()    # t2.join()    #sleep(5) # 屏蔽此行代码，试试看，程序是否会立马结束？    print(&#x27;---结束---:%s&#x27;%ctime())#未使用join等待函数输出结果,主线程直接结束，不符合预期---开始---:Tue Aug 26 10:35:09 2025正在唱歌...0---结束---:Tue Aug 26 10:35:09 2025正在唱歌...1正在唱歌...2正在跳舞...0正在跳舞...1正在跳舞...2#使用join后---开始---:Tue Aug 26 10:36:35 2025正在唱歌...0正在唱歌...1正在唱歌...2正在跳舞...0正在跳舞...1正在跳舞...2---结束---:Tue Aug 26 10:36:41 2025=================================================================================#注意锁的颗粒度，如果锁循环则是线程二要等线程一执行完才会运行影响效率import threadingfrom time import sleep,ctimestats_lock = threading.Lock()def sing(num):    #with stats_lock:        for i in range(num):            with stats_lock:                print(&quot;正在唱歌...%d&quot;%i)            sleep(1)def dance(num):    #with stats_lock:        for i in range(num):            with stats_lock:                print(&quot;正在跳舞...%d&quot;%i)            sleep(1)if __name__ == &#x27;__main__&#x27;:    print(&#x27;---开始---:%s&#x27;%ctime())    t1 = threading.Thread(target=sing,args=(3,),name=&quot;唱歌线程&quot;)    t2 = threading.Thread(target=dance,args=(3,))    t1.start()    t2.start()    t1.join()    t2.join()    #sleep(5) # 屏蔽此行代码，试试看，程序是否会立马结束？    print(&#x27;---结束---:%s&#x27;%ctime())#输出结果，同步执行，只锁输出---开始---:Tue Aug 26 10:39:38 2025正在唱歌...0正在跳舞...0正在跳舞...1正在唱歌...1正在跳舞...2正在唱歌...2---结束---:Tue Aug 26 10:39:41 2025\n\n\n队列函数 queue.Queue 来实现线程间的通信和数据交换\n\n\n生产者（如网络请求接收）和消费者（如任务处理线程）速度不一致建议使用\n比如爬取m3u8视频片段，就需要使用队列按照先进先出的顺序下载避免多线程片段混乱无法组合\n\n\n\n\n作用\n说明\n\n\n\n线程安全的数据传递\n自动处理多线程并发操作，无需手动加锁&#x2F;释放锁。\n\n\n任务解耦\n生产任务的线程（如主线程）和消费任务的线程（工作线程）完全解耦。\n\n\n流量控制\n通过队列大小限制（maxsize）防止内存爆炸。\n\n\n任务状态跟踪\n支持 task_done() 和 join() 机制，方便等待所有任务完成。\n\n\n#未使用tasks = []  # 全局任务列表lock = threading.Lock()# 生产者线程def producer():    global tasks    for i in range(100):        with lock:            tasks.append(i)# 消费者线程def consumer():    while True:        with lock:            if not tasks:                break            item = tasks.pop(0)        process(item)#使用import threadingfrom queue import Queuetask_queue = Queue(maxsize=10)  # 队列容量限制def producer():    for i in range(100):        task_queue.put(i)  # 自动阻塞队列满时def consumer():    while True:        item = task_queue.get()  # 自动阻塞队列空时        process(item)        task_queue.task_done()# 启动线程producer_thread = threading.Thread(target=producer)consumer_thread = threading.Thread(target=consumer)producer_thread.start()consumer_thread.start()task_queue.join()  # 等待所有任务完成producer_thread.join()consumer_thread.join()#顺序先入先出import threadingfrom queue import Queueimport timeimport random# 共享队列和结果容器task_queue = Queue()results = &#123;&#125;lock = threading.Lock()  # 保证结果字典的线程安全def worker():    &quot;&quot;&quot;工作线程：处理无序任务，保存结果到字典&quot;&quot;&quot;    while True:        # 获取任务（包含序号和参数）        index, url = task_queue.get()        print(f&quot;开始处理第 &#123;index&#125; 章: &#123;url&#125;&quot;)        time.sleep(random.uniform(0.5, 2))  # 模拟耗时操作        content = f&quot;第 &#123;index&#125; 章内容&quot;                # 保存结果（加锁保证线程安全）        with lock:            results[index] = content                task_queue.task_done()def download_ordered_chapters(chapters):    &quot;&quot;&quot;主线程：提交任务、启动工作线程、等待并排序结果&quot;&quot;&quot;    # 提交任务到队列    for index, url in chapters:        task_queue.put((index, url))        # 启动工作线程（3个线程）    threads = []    for _ in range(3):        t = threading.Thread(target=worker, daemon=True)        t.start()        threads.append(t)        # 等待所有任务完成    task_queue.join()     # 等待所有线程结束（非守护线程必须调用 join()）    # for t in threads:    #     t.join()  # 确保线程完全结束        # 按序号排序结果    sorted_indices = sorted(results.keys())    ordered_results = [results[i] for i in sorted_indices]        return ordered_results# 示例调用if __name__ == &quot;__main__&quot;:    chapters = [        (1, &quot;http://example.com/ch1&quot;),        (2, &quot;http://example.com/ch2&quot;),        (3, &quot;http://example.com/ch3&quot;)    ]        ordered_contents = download_ordered_chapters(chapters)    for content in ordered_contents:        print(f&quot;保存: &#123;content&#125;&quot;)\n\n\n\n\n\n综合示例代码import queueimport threadingimport timeimport requestsfrom queue import Queue# 压测配置CONFIG = &#123;    &quot;target_url&quot;: &quot;http://localhost/&quot;,  # 目标地址    &quot;thread_num&quot;: 5000,  # 并发线程数    &quot;total_requests&quot;: 100000,  # 总请求量 (设置为0表示无限持续)    &quot;timeout&quot;: 5,  # 单请求超时时间（秒）    &quot;headers&quot;: &#123;  # 请求头（按需修改）        &quot;User-Agent&quot;: &quot;Stress Test/1.0&quot;    &#125;&#125;# 全局统计stats = &#123;    &#x27;total&#x27;: 0,    &#x27;success&#x27;: 0,    &#x27;fail&#x27;: 0,    &#x27;total_time&#x27;: 0.0,    &#x27;max_time&#x27;: 0.0,    &#x27;min_time&#x27;: float(&#x27;inf&#x27;)&#125;stats_lock = threading.Lock()  # 线程安全锁# 请求任务队列task_queue = Queue()def worker():    &quot;&quot;&quot;工作线程函数&quot;&quot;&quot;    while True:        try:            # 从队列获取任务（阻塞模式）            task_id = task_queue.get(timeout=2)            start_time = time.time()            try:                # 发送请求（可修改为POST等其他方法）                response = requests.get(                    CONFIG[&quot;target_url&quot;],                    headers=CONFIG[&quot;headers&quot;],                    timeout=CONFIG[&quot;timeout&quot;]                )                elapsed = time.time() - start_time                # 更新统计（200~399状态码视为成功）                with stats_lock:                    stats[&#x27;total&#x27;] += 1                    if 200 &lt;= response.status_code &lt; 400:                        stats[&#x27;success&#x27;] += 1                    else:                        stats[&#x27;fail&#x27;] += 1                    stats[&#x27;total_time&#x27;] += elapsed                    stats[&#x27;max_time&#x27;] = max(stats[&#x27;max_time&#x27;], elapsed)                    stats[&#x27;min_time&#x27;] = min(stats[&#x27;min_time&#x27;], elapsed)            except Exception as e:                with stats_lock:                    stats[&#x27;fail&#x27;] += 1                    stats[&#x27;total&#x27;] += 1            # 标记任务完成            task_queue.task_done()        except queue.Empty:            breakdef print_stats():    &quot;&quot;&quot;实时打印统计信息&quot;&quot;&quot;    start_time = time.time()    while True:        time.sleep(1)  # 每秒更新        with stats_lock:            if stats[&#x27;total&#x27;] == 0:                continue            duration = time.time() - start_time            qps = stats[&#x27;total&#x27;] / duration            avg_time = stats[&#x27;total_time&#x27;] / stats[&#x27;total&#x27;]            print(f&quot;\\r[STAT] &quot;                  f&quot;Requests: &#123;stats[&#x27;total&#x27;]&#125; | &quot;                  f&quot;Success: &#123;stats[&#x27;success&#x27;]&#125; | &quot;                  f&quot;Fail: &#123;stats[&#x27;fail&#x27;]&#125; | &quot;                  f&quot;QPS: &#123;qps:.1f&#125; | &quot;                  f&quot;Avg: &#123;avg_time:.3f&#125;s | &quot;                  f&quot;Min/Max: &#123;stats[&#x27;min_time&#x27;]:.3f&#125;s/&#123;stats[&#x27;max_time&#x27;]:.3f&#125;s&quot;,                  end=&#x27;&#x27;, flush=True)        # 检查是否完成所有任务        if CONFIG[&quot;total_requests&quot;] &gt; 0 and stats[&#x27;total&#x27;] &gt;= CONFIG[&quot;total_requests&quot;]:            breakif __name__ == &quot;__main__&quot;:    # 初始化任务队列    if CONFIG[&quot;total_requests&quot;] &gt; 0:        for i in range(CONFIG[&quot;total_requests&quot;]):            task_queue.put(i)    else:  # 持续模式填充队列        while True:            task_queue.put(1)    # 创建工作者线程    threads = []    for _ in range(CONFIG[&quot;thread_num&quot;]):        t = threading.Thread(target=worker)        t.daemon = True        t.start()        threads.append(t)    # 启动统计线程    stat_thread = threading.Thread(target=print_stats)    stat_thread.start()    # 等待任务完成    task_queue.join()    stat_thread.join()    print(&quot;\\n压力测试完成&quot;)#使用了join等待压测结束统计信息#使用了queue.put填充队列为请求数量，线程为并发数量#使用了with stats_lock加锁避免线程冲突#推荐使用这种方式，因为是大量重复任务#使用ThreadPoolExecutor线程池优化，因为是大量重复任务，thread每次都要新创建线程消耗较大import threadingimport timeimport requestsfrom concurrent.futures import ThreadPoolExecutorCONFIG = &#123;    &quot;target_url&quot;: &quot;http://localhost/&quot;,    &quot;thread_num&quot;: 300,    &quot;total_requests&quot;: 10000,    &quot;timeout&quot;: 5,    &quot;headers&quot;: &#123;        &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36&quot;    &#125;,    &quot;show_progress&quot;: True&#125;stats = &#123;    &#x27;total&#x27;: 0, &#x27;success&#x27;: 0, &#x27;fail&#x27;: 0,    &#x27;total_time&#x27;: 0.0, &#x27;max_time&#x27;: 0.0, &#x27;min_time&#x27;: float(&#x27;inf&#x27;)&#125;stats_lock = threading.Lock()def worker(_):    start_time = time.time()    try:        response = requests.get(            CONFIG[&quot;target_url&quot;],            headers=CONFIG[&quot;headers&quot;],            timeout=CONFIG[&quot;timeout&quot;]        )        elapsed = time.time() - start_time        with stats_lock:            stats[&#x27;total&#x27;] += 1            if 200 &lt;= response.status_code &lt; 400:                stats[&#x27;success&#x27;] += 1            else:                stats[&#x27;fail&#x27;] += 1            stats[&#x27;total_time&#x27;] += elapsed            stats[&#x27;max_time&#x27;] = max(stats[&#x27;max_time&#x27;], elapsed)            stats[&#x27;min_time&#x27;] = min(stats[&#x27;min_time&#x27;], elapsed)    except Exception as e:        with stats_lock:            stats[&#x27;fail&#x27;] += 1            stats[&#x27;total&#x27;] += 1def print_stats():    start_time = time.time()    while True:        time.sleep(1)        with stats_lock:            current_total = stats[&#x27;total&#x27;]            duration = time.time() - start_time            qps = current_total / duration if duration &gt; 0 else 0            avg_time = stats[&#x27;total_time&#x27;] / current_total if current_total &gt; 0 else 0            progress_percent = (current_total / CONFIG[&quot;total_requests&quot;]) * 100 if CONFIG[&quot;total_requests&quot;] &gt; 0 else 0            progress_bar = &quot;&quot;            if CONFIG[&quot;show_progress&quot;] and CONFIG[&quot;total_requests&quot;] &gt; 0:                bar_length = 20                filled = int(bar_length * current_total // CONFIG[&quot;total_requests&quot;])                progress_bar = &quot;[&quot; + &quot;=&quot; * filled + &quot; &quot; * (bar_length - filled) + &quot;] &quot;            output = (                f&quot;\\r[STAT] &quot;                f&quot;进度: &#123;progress_bar&#125;&#123;progress_percent:.1f&#125;% | &quot;                f&quot;请求: &#123;current_total&#125;/&#123;CONFIG[&#x27;total_requests&#x27;] if CONFIG[&#x27;total_requests&#x27;] &gt; 0 else &#x27;∞&#x27;&#125; | &quot;                f&quot;成功: &#123;stats[&#x27;success&#x27;]&#125; | &quot;                f&quot;失败: &#123;stats[&#x27;fail&#x27;]&#125; | &quot;                f&quot;QPS: &#123;qps:.1f&#125; | &quot;                f&quot;平均: &#123;avg_time:.3f&#125;s | &quot;                f&quot;最慢: &#123;stats[&#x27;max_time&#x27;]:.3f&#125;s&quot;            )            print(output, end=&#x27;&#x27;, flush=True)            if CONFIG[&quot;total_requests&quot;] &gt; 0 and current_total &gt;= CONFIG[&quot;total_requests&quot;]:                breakif __name__ == &quot;__main__&quot;:    stat_thread = threading.Thread(target=print_stats)    stat_thread.start()    with ThreadPoolExecutor(max_workers=CONFIG[&quot;thread_num&quot;]) as executor:        if CONFIG[&quot;total_requests&quot;] &gt; 0:            executor.map(worker, range(CONFIG[&quot;total_requests&quot;]))        else:            while True:                executor.submit(worker, None)    stat_thread.join()    print(&quot;\\n压力测试完成&quot;)\n\n额外\nThreadPoolExecutor 适用场景：短期、批量、同质化任务\n\nmultiprocessing 适用场景：大量cpu密集型计算，多进程绕过GIL；io密集型建议使用异步编程\n\n\n","categories":["python"]},{"title":"rsync","url":"/2025/08/05/rsync/","content":"命令主要参数-a, ––archive\t归档模式，表示以递归方式传输文件，并保持所有文件属性，等价于 -rlptgoD (注意不包括 -H)-r, ––recursive\t对子目录以递归模式处理-l, ––links\t保持符号链接文件-H, ––hard-links\t保持硬链接文件-p, ––perms\t保持文件权限-t, ––times\t保持文件时间信息-g, ––group\t保持文件属组信息-o, ––owner\t保持文件属主信息 (super-user only)-D\t保持设备文件和特殊文件 (super-user only)-z, ––compress\t在传输文件时进行压缩处理––exclude=PATTERN\t指定排除一个不需要传输的文件匹配模式––exclude-from=FILE\t从 FILE 中读取排除规则––include=PATTERN\t指定需要传输的文件匹配模式––include-from=FILE\t从 FILE 中读取包含规则––copy-unsafe-links\t拷贝指向SRC路径目录树以外的链接文件––safe-links\t忽略指向SRC路径目录树以外的链接文件（默认）––existing\t仅仅更新那些已经存在于接收端的文件，而不备份那些新创建的文件––ignore-existing\t忽略那些已经存在于接收端的文件，仅备份那些新创建的文件-b, ––backup\t当有变化时，对目标目录中的旧版文件进行备份––backup-dir=DIR\t与 -b 结合使用，将备份的文件存到 DIR 目录中––link-dest=DIR\t当文件未改变时基于 DIR 创建硬链接文件––delete\t删除那些接收端还有而发送端已经不存在的文件––delete-before\t接收者在传输之前进行删除操作 (默认)––delete-during\t接收者在传输过程中进行删除操作––delete-after\t接收者在传输之后进行删除操作––delete-excluded\t在接收方同时删除被排除的文件-e, ––rsh=COMMAND\t指定替代 rsh 的 shell 程序––ignore-errors\t即使出现 I/O 错误也进行删除––partial\t保留那些因故没有完全传输的文件，以是加快随后的再次传输––progress\t在传输时显示传输过程-P\t等价于 ––partial ––progress––delay-updates\t将正在更新的文件先保存到一个临时目录（默认为 “.~tmp~”），待传输完毕再更新目标文件-v, ––verbose\t详细输出模式-q, ––quiet\t精简输出模式-h, ––human-readable\t输出文件大小使用易读的单位（如，K，M等）-n, ––dry-run\t显示哪些文件将被传输––list-only\t仅仅列出文件而不进行复制––rsyncpath=PROGRAM\t指定远程服务器上的 rsync 命令所在路径––password-file=FILE\t从 FILE 中读取口令，以避免在终端上输入口令，通常在 cron 中连接 rsync 服务器时使用-4, ––ipv4\t使用 IPv4-6, ––ipv6\t使用 IPv6\n\n命令行模式#常用参数rsync -avzSP \\ #端点续传整合小文件  --contimeout=120 \\    # 连接超时 120 秒  --timeout=60 \\       # 数据传输超时 60 秒  --delay-updates \\    # 原子性替换文件  --log-file=rsync.log  #日志记录/cygdrive/c/     /cygdrive/d/ #windows必须加上/cygdrive前缀#可选参数 --delay-updates 需要目标磁盘空间较大，对正在进行io操作的先跳过后更新#--bwlimit=6000 限制带宽在6MB/s#--exclude=&#x27;*.log&#x27; 过滤文件不传输支持正则#--delete  保证源和目标完全一致#--password-file=/etc/rsyncd_users.db backuper@127.0.0.1::wwwroot# /lib/systemd/system/rsync.service[Unit]Description=fast remote file copy program daemonConditionPathExists=/etc/rsyncd.conf[Service]ExecStart=/usr/bin/rsync --daemon --no-detach[Install]WantedBy=multi-user.target\n\n\n后台server模式linux配置cat &gt;&gt; /etc/rsyncd.conf  &lt;&lt; EOFuid = root\t\t\t\t\t     gid = root\t\t\t\t\t    use chroot = yes\t\t\t\t\taddress = 0.0.0.0\t\t\tport 873\t\t\t\t\t\t    log file = /var/log/rsyncd.log\t\tpid file = /var/run/rsyncd.pid\t\thosts allow = *\t\t[wwwroot]\t\t\t\t\t        path = /data/\t\t\t\tcomment = Document Root read only = yes\t\t\t\t\t    dont compress = *.gz *.bz2 *.tgz *.zip *.rar *.z  auth users = backuper srs\t\t\tsecrets file = /etc/rsyncd_users.db\t\t\t      EOFecho &#x27;backuper:backuperpasswd&#x27; |tee -a /etc/rsyncd_users.db\tchmod 600 /etc/rsyncd_users.db#客户端操作\t#echo &#x27;backuperpasswd&#x27; |tee /etc/client.pass &amp;&amp; chmod 600 /etc/client.pass#拉取#rsync -avzPS --password-file=/etc/client.pass backuper@127.0.0.1::wwwroot /tmp/rsync_daemon#发送；相当于把/tmp/rsync_daemon同步到/data/ read only 要设置成no#rsync -avzPS --password-file=/etc/client.pass /tmp/rsync_daemon backuper@127.0.0.1::wwwroot ==================================================================#正常配置里面不能有注释uid = root\t\t\t\t\t     gid = root\t\t\t\t\t    use chroot = yes\t\t\t\t\t#禁锢在源目录address = 0.0.0.0\t\t\t#监听地址，监听本机地址port 873\t\t\t\t\t\t    #监听端口 tcp/udp 873，log file = /var/log/rsyncd.log\t\t#日志文件位置pid file = /var/run/rsyncd.pid\t\t#存放进程 ID 的文件位置hosts allow = *\t\t#允许同步的客户机网段max connections = 5 #最大五个连接，默认没有限制[wwwroot]\t\t\t\t\t        #共享模块名称path = /data\t\t\t\t#源目录的实际路径（同步的目录）comment = Document Root read only = yes\t\t\t\t\t    #是否为只读dont compress = *.gz *.bz2 *.tgz *.zip *.rar *.z  #同步时不再压缩的文件类型auth users = backuper srs\t\t\t#授权账户，多个账号以空格分隔secrets file = /etc/rsyncd_users.db\t\t\t      #存放账户信息的数据文件EOF\nwindows配置cygwin下载地址\n#windowsuid = Administrator    gid = Users  use chroot = yesaddress = 0.0.0.0port 873    log file = /var/log/rsyncd.logpid file = /var/run/rsyncd.pidhosts allow = *[wwwroot]        path = /cygdrive/c/datacomment = Document Root read only = yes    dont compress = *.gz *.bz2 *.tgz *.zip *.rar *.z  auth users = backuper srssecrets file = /etc/rsyncd_users.db#在cygwin终端执行#echo &#x27;backuperpasswd&#x27; |tee /etc/client.pass &amp;&amp; chmod 600 /etc/client.pass      #rsync -avzPS --password-file=/etc/client.pass backuper@127.0.0.1::wwwroot /cygdrive/c/rsync_daemon\n\n额外大量文件添加失败重试#!/bin/bash# 配置参数PASSWORD=&#x27;pass&#x27;#REMOTE_PATH=&quot;administrator@1.1.1.1:/cygdrive/c/data&quot;REMOTE_PATH=&quot;root@127.0.0.1:/data&quot;LOCAL_PATH=&quot;/tmp/rsync/&quot;#windows必选#RSYNC_PATH=&quot;C:\\\\cygwin64\\\\bin\\\\rsync.exe&quot;LOG_FILE=&quot;rsync.log&quot;# 最大重试次数MAX_RETRIES=10# 重试间隔（秒）RETRY_INTERVAL=60# 循环重试retry=0while [ $retry -lt $MAX_RETRIES ]; do  echo &quot;$(date) - 第 $((retry+1)) 次尝试同步...&quot; | tee -a &quot;$LOG_FILE&quot;    # 执行同步命令  sshpass -p &quot;$PASSWORD&quot; rsync -avzSP \\    --log-file=&quot;$LOG_FILE&quot; \\  #  --rsync-path=&quot;$RSYNC_PATH&quot; \\    --timeout=30 \\    --contimeout=30 \\    &quot;$REMOTE_PATH&quot; &quot;$LOCAL_PATH&quot;    # 检查退出状态码  if [ $? -eq 0 ]; then    echo &quot;$(date) - 同步成功！&quot; | tee -a &quot;$LOG_FILE&quot;    exit 0  else    echo &quot;$(date) - 同步失败，$&#123;RETRY_INTERVAL&#125;秒后重试...&quot; | tee -a &quot;$LOG_FILE&quot;    sleep $RETRY_INTERVAL    ((retry++))  fidoneecho &quot;$(date) - 达到最大重试次数，同步终止。&quot; | tee -a &quot;$LOG_FILE&quot;exit 1\n两种同步模式1.服务端推送；需要每个客户端启动rsync –deamon添加配置文件不然需要使用ssh模式涉及密码不安全,监控服务端文件变化去同步客户端节点大部分情况用这种，弊端就是节点较多服务端同步起来负载会比较高2.客户端推送；只需要在服务端配置rsync –deamon监控客户端文件变化去推送数据到服务端，由于多节点存在数据不一致这种情况建议不使用–delete不然一个节点操作删除，服务端也会被删除；或者使用客户端拉取这种情况只有通过定时任务实现就无法使用监控程序了\nrsync+inotify\n异地备份cdn节点少量同步；变动不频繁inotify-tools 包含 inotifywatch  inotifywait两个命令inotifywatch -v -t 60 -r /var/log #统计次数inotifywait -mrq --format &quot;%T %w%f %e&quot; --timefmt &quot;%F-%T&quot; -e create,delete,move,modify,attrib /data/ |    while read TIME FILE EVENT; do  echo &quot;时间: $TIME | 文件: $FILE | 事件: $EVENT &quot;done%T\t时间戳（需配合 --timefmt 定义格式）%w\t监控目录的路径（绝对或相对路径）%f\t触发事件的文件名（不含路径）%e\t事件类型（多个事件用逗号分隔）-m 持续监听-r 使用递归形式监视目录-q 减少冗余信息，只打印出需要的信息-e 指定要监视的事件，多个时间使用逗号隔开–timefmt 时间格式–format 监听到的文件变化的信息access\t文件被读取modify\t文件内容被修改attrib\t文件元数据（如权限、时间戳）变更create\t文件/目录创建delete\t文件/目录删除open, close\t文件被打开或关闭#在client运行脚本，client目录发送变化会同步到rsync服务端cat &gt; ./inotify_rsync.sh &lt;&lt; &#x27;EOF&#x27;  #!/bin/bash# Rsync配置RSYNC_CMD=&quot;rsync -avzS --partial --delay-updates --delete --password-file=/etc/client.pass /data/ backuper@10.0.1.122::wwwroot&quot;LOG_FILE=&quot;/var/log/inotify_rsync.log&quot;# 创建日志文件（如果不存在）touch &quot;$LOG_FILE&quot;# 开始监控并处理事件inotifywait -mrq --format &quot;%T %w%f %e&quot; --timefmt &quot;%F-%T&quot; -e create,delete,move,modify,attrib /data/ |  while read TIME FILE EVENT; do    # 记录事件到日志    echo &quot;[事件] 时间: $TIME | 文件: $FILE | 操作: $EVENT&quot; &gt;&gt; &quot;$LOG_FILE&quot;        # 执行rsync同步（添加错误重试机制）    if ! $RSYNC_CMD &gt;&gt; &quot;$LOG_FILE&quot; 2&gt;&amp;1; then        echo &quot;[错误] 同步失败！时间: $(date &#x27;+%F-%T&#x27;)&quot; &gt;&gt; &quot;$LOG_FILE&quot;    else        echo &quot;[同步] 成功完成！时间: $(date &#x27;+%F-%T&#x27;)&quot; &gt;&gt; &quot;$LOG_FILE&quot;    fidoneEOFchmod +x inotify_rsync.shcat &gt;  /etc/systemd/system/inotify_rsync.service &lt;&lt; &#x27;EOF&#x27;  [Unit]Description=Auto Sync Service via inotify+rsync[Service]Type=simpleUser=rootExecStart=/tmp/rsync_daemon/inotify_rsync.shRestart=always[Install]WantedBy=multi-user.targetEOF\n\nrsync+lsyncd\n适合大量数据同步场景；变动频繁官方文档参数解读#ubuntu /etc/lsyncd/lsyncd.conf.luacat &gt; /etc/lsyncd.conf &lt;&lt; &#x27;EOF&#x27;settings &#123;  logfile = &quot;/var/log/lsyncd.log&quot;,  statusFile = &quot;/var/log/lsyncd.status&quot;,  insist = true,  statusInterval = 10&#125;sync &#123;  default.rsync,  source = &quot;/tmp/rsync_ly&quot;,  target = &quot;backuper@10.0.1.122::wwwroot&quot;,  -- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,  delete = true,  delay = 20,  maxDelays = 1,  rsync = &#123;    binary = &quot;/usr/bin/rsync&quot;,    archive = true,    compress = true,    verbose = false,    password_file = &quot;/etc/client.pass&quot;,    _extra    = &#123;            &quot;--partial&quot;,                      &quot;--timeout=300&quot;      --          &quot;--bwlimit=5000&quot;              &#125;,  &#125;&#125;EOF========================================================-- 全局配置：settings &#123;        logfile =&quot;/var/log/lsyncd/lsyncd.log&quot;, -- 定义日志文件        statusFile =&quot;/var/log/lsyncd/lsyncd.status&quot;,  -- 定义状态文件        pidfile = &quot;/var/log/lsyncd/lsyncd.pid&quot;,-- 定义pid文件        inotifyMode = &quot;CloseWrite&quot;,-- 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify      \tmaxProcesses = 7,-- 同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程        nodaemon =true,-- 表示不启用守护模式，默认；        maxDelays = 1, --  累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到        inist = ture --keep running at startup although one or more targets failed due to not being reachable.  一般不用配置       &#125;-- sync部分配置：sync &#123;      default.rsync,     -- rsync、rsyncssh、direct三种模式：    -- default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；    -- default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；    -- default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证；      source = &quot;/tmp/src&quot;, -- source 同步的源目录，使用绝对路径      target = &quot;/tmp/dest&quot;, -- target 定义目的地址.对应不同的模式有几种写法:    \t-- /tmp/dest ：本地目录同步，可用于direct和rsync模式；    \t-- 10.4.7.10:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd --delete --include-from=- --exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步；   \t\t-- 10.4.7.10::module ：同步到远程服务器目录，用于rsync模式；      init = true,  -- init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true；      delay = 3, -- delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）;      excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;,  -- excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = &quot;/etc/lsyncd.exclude&quot;，如果是简单的排除，可以使用exclude = LIST。这里的排除规则写法与原生rsync有点不同，更为简单：\t\t-- 监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo\t\t-- 如果规则以斜线/开头，则从头开始要匹配全部\t\t-- 如果规则以/结尾，则要匹配监控路径的末尾\t\t-- ?匹配任何字符，但不包括/\t\t-- *匹配0或多个字符，但不包括/\t\t-- **匹配0或多个字符，可以是/      delete\t=\t&#x27;running&#x27;,  -- delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值：      -- delete\t=\ttrue       # 在目标上删除源中没有的内容。在启动时以及在正常操作期间删除的内容      -- delete\t=\tfalse      # 不会删除目标上的任何文件。不在启动时也不在正常操作上      -- delete\t=\t&#x27;startup&#x27;  # Lsyncd将在启动时删除目标上的文件，但不会在正常操作时删除      -- delete\t=\t&#x27;running&#x27;  # Lsyncd在启动时不会删除目标上的文件，但会删除正常操作期间删除的文件    -- rsync部分配置：          -- delete和exclude本来都是rsync的选项，上面是配置在sync中的，这样做的原因是为了减少rsync的开销      rsync = &#123;             bwlimit=200, -- bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）；             binary = &quot;/usr/bin/rsync&quot;, -- rsync可执行程序地址，默认/usr/bin/rsync             archive = true, -- 默认false，以递归方式传输文件，并保持所有文件属性             compress = true,-- 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false；             verbose = true,--同步详细模式输出        \t perms = true -- perms 保留文件权限,默认为true；      &#125;&#125;#-- excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, #*.log#/cache/#/temp/#.git/\n\n","categories":["linux"]},{"title":"screen","url":"/2025/04/27/screen/","content":"多终端管理神器ctrl +a + d 退出终端exit 退出加销毁终端\n常用参数$&gt; screen [-AmRvx -ls -wipe][-d &lt;作业名称&gt;][-h &lt;行数&gt;][-r &lt;作业名称&gt;][-s ][-S &lt;作业名称&gt;] -A 　将所有的视窗都调整为目前终端机的大小。-d   &lt;作业名称&gt; 　将指定的screen作业离线。-h   &lt;行数&gt; 　指定视窗的缓冲区行数。-m 　即使目前已在作业中的screen作业，仍强制建立新的screen作业。-r   &lt;作业名称&gt; 　恢复离线的screen作业。-R 　先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。-s 　指定建立新视窗时，所要执行的shell。-S   &lt;作业名称&gt; 　指定screen作业的名称。-v 　显示版本信息。-x 　恢复之前离线的screen作业。-ls或--list 　显示目前所有的screen作业。-wipe 　检查目前所有的screen作业，并删除已经无法使用的screen作业。screen -S yourname -&gt; 新建一个叫yourname的sessionscreen -ls         -&gt; 列出当前所有的sessionscreen -r yourname -&gt; 回到yourname这个sessionscreen -d yourname -&gt; 远程detach某个sessionscreen -d -r yourname -&gt; 结束当前session并回到yourname这个session\n常用快捷键C-a ? -&gt; 显示所有键绑定信息C-a c -&gt; 创建一个新的运行shell的窗口并切换到该窗口C-a n -&gt; Next，切换到下一个 window C-a p -&gt; Previous，切换到前一个 window C-a 0..9 -&gt; 切换到第 0..9 个 windowCtrl+a [Space] -&gt; 由视窗0循序切换到视窗9C-a C-a -&gt; 在两个最近使用的 window 间切换 C-a x -&gt; 锁住当前的 window，需用用户密码解锁C-a d -&gt; detach，暂时离开当前session，将目前的 screen session (可能含有多个 windows) 丢到后台执行，并会回到还没进 screen 时的状态，此时在 screen session 里，每个 window 内运行的 process (无论是前台/后台)都在继续执行，即使 logout 也不影响。 C-a z -&gt; 把当前session放到后台执行，用 shell 的 fg 命令则可回去。C-a w -&gt; 显示所有窗口列表C-a t -&gt; time，显示当前时间，和系统的 load C-a k -&gt; kill window，强行关闭当前的 windowC-a [ -&gt; 进入 copy mode，在 copy mode 下可以回滚、搜索、复制就像用使用 vi 一样    C-b Backward，PageUp     C-f Forward，PageDown     H(大写) High，将光标移至左上角     L Low，将光标移至左下角     0 移到行首     $ 行末     w forward one word，以字为单位往前移     b backward one word，以字为单位往后移     Space 第一次按为标记区起点，第二次按为终点     Esc 结束 copy mode C-a ] -&gt; paste，把刚刚在 copy mode 选定的内容贴上\n","categories":["linux"]},{"title":"tcp","url":"/2025/07/25/tcp/","content":"三握四挥\n （1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。  （2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。  （3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了客户端发起fin位为1的FIN报文，此时客户端进入FIN_WAIT_1状态服务端接受到FIN 报文后，发送ack应答报文，此时服务端进入close_wait状态客户端接受到ack应答报文后，进入FIN_WAIT_2状态服务端处理完数据后，向客户端发送FIN报文，此时服务端进入LAST_ACK状态客户端接受到FIN报文后，客户端发送应答ack报文，进入TIME_WAIT阶段服务端接受到ack报文后，断开连接，处于close状态客户端过一段时间后，也就是2MSL后，进入close状态\n\n\n\n\nTime Wait概念\n谁先关闭谁最后进入timewait状态，time_wait 状态下，TCP 连接占用的端口，无法被再次使用close 短连接每个HTTP请求都需要重新完成TCP三次握手建立连接，数据传输完成后四次挥手关闭连接keep-alive 长连接在HTTP1.1协议中默认长连接，有个 Connection 头，Connection有两个值，close和keep-alive，这个头就相当于客户端告诉服务端，服务端你执行完成请求之后，是关闭连接还是保持连接，保持连接就意味着在保持连接期间，只能由客户端主动断开连接。还有一个keep-alive的头，设置的值就代表了服务端保持连接保持多久#ngxkeepalive 100;          # 保持的空闲连接数keepalive_timeout 60s;   # 空闲超时时间keepalive_requests 100;  # 单连接最大请求数location / &#123;    proxy_pass http://backend_servers;    proxy_http_version 1.1;     # 关键：使用 HTTP/1.1    proxy_set_header Connection &quot;&quot;;  # 清除 Connection 头（避免传递错误值）&#125;# Linux 内核参数（默认值通常为 7200 秒）默认不启用sysctl -w net.ipv4.tcp_keepalive_time=1800  # 空闲 1800 秒后发送探针sysctl -w net.ipv4.tcp_keepalive_probes=3   # 发送 3 次无响应后关闭sysctl -w net.ipv4.tcp_keepalive_intvl=15   # 每次探针间隔 15 秒\n\n相关参数netstat -ant | awk &#x27;/^tcp/ &#123;++y[$NF]&#125; END &#123;for(w in y) print w, y[w]&#125;&#x27;net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30==============================================net.ipv4.tcp_tw_reuse = 1表示开启重用。允许将一个处于TIME-WAIT状态的端口重新用于新的TCP连接，默认为0，表示关闭，其防止重复报文的原理也是时间戳net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，意思就是系统会保存最近一次该socket连接上的传输报文（包括数据或者仅仅是ACK报文）的时间戳，当相同四元组socket过来的报文的时间戳小于缓存下来的时间戳则丢弃该数据包，并回收这个socket，默认为0，表示关闭。开启这个功能风险有点大，NAT环境可能导致DROP掉SYN包（回复RST），在NAT场景下不要使用。需要注意在Linux内核4.10版本以后该参数就已经被移除了。net.ipv4.tcp_fin_timeout = 60这个时间不是修改2MSL的时长，主动关闭连接的一方接收到ACK之后会进入，FIN_WAIT-2状态，然后等待被动关闭一方发送FIN，这个时间是设置主动关闭的一方等待对方发送FIN的最长时长，默认是60秒。在这个状态下端口是不可能被重用的，文件描述符和内存也不会被释放，因为这个阶段被动关闭的一方有可能还有数据要发送，因为对端处于CLOSE_WAIT状态，也就是等待上层应用程序。关于这个的真实含义我希望大家清楚，而且不要调整的太小当然太大也不行，至少在3.10内核版本上这个参数不是调整的TIME_WAIT时长。net.ipv4.ip_local_port_range = 32768 60999表示用于外连使用的随机高位端口范围，也就是作为客户端连接其他服务的时候系统从这个范围随机取出一个端口来作为源端口使用来去连接对端服务器，这个范围也就决定了最多主动能同时建立多少个外连。net.ipv4.tcp_max_tw_buckets = 6000同时保持TIME_WAIT套接字的最大个数，超过这个数字那么该TIME_WAIT套接字将立刻被释放并在/var/log/message日志中打印警告信息（TCP: time wait bucket table overflow）。这个过多主要是消耗内存，单个TIME_WAIT占用内存非常小，但是多了就不好了，这个主要看内存以及你的服务器是否直接对外。使用net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle 的前提是开启时间戳net.ipv4.tcp_timestamps = 1不过这一项默认是开启的\n\nCLOSE_WAIT\n这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是查看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。CLOSE_WAIT一般是由于对端主动关闭，而我方没有正确处理的原因引起的，临时解决重启服务，永久解决就是修改程序逻辑客户端（主动关闭方）          服务器（被动关闭方）       |                               |       |--- GET /bigfile.zip ---------&gt;|        |&lt;--- 200 OK + 文件数据 ---------|       |                               |       |--- FIN (我要关闭) ------------&gt;| → 客户端进入 FIN_WAIT_1       |&lt;--- ACK ----------------------| → 服务端进入 CLOSE_WAIT       |                               |（此时服务端还在发送剩余文件数据）       |&lt;--- 剩余数据包 ----------------|       |&lt;--- FIN (我也关闭) ------------| → 服务端进入 LAST_ACK       |--- ACK -----------------------&gt;| → 客户端进入 TIME_WAIT                #没有调用s.close()关闭socket，会造成大量CLOSE_WAITimport socketimport timedef create_sockets(num_sockets):    sockets = []    for _ in range(num_sockets):        # 创建一个 TCP 套接字        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)        print(f&quot;创建 socket &#123;_ + 1&#125;: &#123;s.fileno()&#125;，状态为 alloc&quot;)        sockets.append(s)    return socketsif __name__ == &quot;__main__&quot;:    num_sockets = 10    while True:        num_sockets  += 10        sockets = create_sockets(num_sockets)        print(f&quot;总共创建了 &#123;num_sockets&#125; 个 socket 对象。&quot;)        time.sleep(10)#shellcat /proc/net/sockstat | grep sockets | awk &#x27;&#123;print $3&#125;&#x27;netstat -n | awk &#x27;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,&quot;\\t&quot;,state[key]&#125;&#x27;for i in `ls /proc/ |grep &#x27;[0-9]&#x27;`do    mycount=`ls /proc/$i/fd|wc -l`    echo &quot;$i $mycount&quot;done\n\n","categories":["linux"]},{"title":"websocket","url":"/2025/05/28/websocket/","content":"异步因为websocket会使用到异步操作先了解一下异步\nimport asyncioimport timeasync def task(name, duration):    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 开始&quot;)    await asyncio.sleep(duration)  # 模拟并发等待    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 完成&quot;)def task_(name, duration):    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 开始&quot;)    time.sleep(duration)  # 模拟耗时操作    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 完成&quot;)async def main():    start_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 异步任务开始&quot;)    await asyncio.gather(        task(&quot;A&quot;, 2),        task(&quot;B&quot;, 3),        task(&quot;C&quot;, 1)    )    end_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 异步任务总耗时: &#123;end_time - start_time:.2f&#125; 秒&quot;)def main_():    start_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 同步任务开始&quot;)    task_(&quot;A&quot;, 2)    task_(&quot;B&quot;, 3)    task_(&quot;C&quot;, 1)    end_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 同步任务总耗时: &#123;end_time - start_time:.2f&#125; 秒&quot;)if __name__ == &quot;__main__&quot;:    print(&quot;======================异步==========================&quot;)    asyncio.run(main())    print(&quot;======================同步==========================&quot;)    main_()#结果可以看出异步不需要等待会直接执行下一步操作，任务完成可以使用await来回调处理完成结果======================异步==========================[14:45:43] 异步任务开始[14:45:43] 任务 A 开始[14:45:43] 任务 B 开始[14:45:43] 任务 C 开始[14:45:44] 任务 C 完成[14:45:45] 任务 A 完成[14:45:46] 任务 B 完成[14:45:46] 异步任务总耗时: 3.00 秒======================同步==========================[14:45:46] 同步任务开始[14:45:46] 任务 A 开始[14:45:48] 任务 A 完成[14:45:48] 任务 B 开始[14:45:51] 任务 B 完成[14:45:51] 任务 C 开始[14:45:52] 任务 C 完成[14:45:52] 同步任务总耗时: 6.00 秒\nwebsocket服务端import asyncioimport websockets#https://websockets.readthedocs.io/en/stable/# 处理客户端连接async def handle_client(websocket):    async for message in websocket:        print(f&quot;收到客户端消息: &#123;message&#125;&quot;)        reply = f&quot;机器人回复：你说的是 &#x27;&#123;message&#125;&#x27; 对吗？&quot;        await websocket.send(reply)# async def main_logic(websocket, path):#    # await check_permit(websocket)##     await handle_client(websocket)# 启动服务器async def main():    async with websockets.serve(handle_client, &quot;localhost&quot;, 8765):        print(&quot;WebSocket 服务器已启动，端口 8765&quot;)        await asyncio.Future()  # 永久运行asyncio.run(main())\n\n\n\n客户端import asyncioimport websocketsasync def client():    async with websockets.connect(&quot;ws://localhost:8765&quot;) as websocket:        while True:            message = input(&quot;请输入消息（输入 q 退出）: &quot;)            if message == &#x27;q&#x27;:                break            await websocket.send(message)            response = await websocket.recv()            print(f&quot;收到回复: &#123;response&#125;&quot;)asyncio.run(client())#效果，相当于打开了一个通道双方都可以发消息WebSocket 服务器已启动，端口 8765请输入消息（输入 q 退出）: hello websockets收到回复: 机器人回复：你说的是 &#x27;hello websockets&#x27; 对吗？请输入消息（输入 q 退出）: \n额外fastapi框架使用websocketfrom fastapi import FastAPI, WebSocket, WebSocketDisconnectfrom fastapi.responses import HTMLResponsefrom fastapi.middleware.cors import CORSMiddlewareimport jsonapp = FastAPI()# 配置CORS跨域app.add_middleware(    CORSMiddleware,    allow_origins=[&quot;*&quot;],    allow_credentials=True,    allow_methods=[&quot;*&quot;],    allow_headers=[&quot;*&quot;],)# HTML页面（修改了前端WebSocket实现）HTML_TEMPLATE = &#x27;&#x27;&#x27;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;FastAPI 聊天&lt;/title&gt;    &lt;style&gt;        body &#123; max-width: 800px; margin: 20px auto; padding: 20px; &#125;        #output &#123;             height: 300px;             border: 1px solid #ccc;             overflow-y: auto;             padding: 10px;             margin-bottom: 10px;        &#125;        #input &#123;             width: 80%;             padding: 8px;            margin-right: 10px;        &#125;        button &#123;            padding: 8px 16px;            background: #007bff;            color: white;            border: none;            border-radius: 4px;            cursor: pointer;        &#125;        button:hover &#123;            opacity: 0.8;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;output&quot;&gt;&lt;/div&gt;    &lt;input type=&quot;text&quot; id=&quot;input&quot; placeholder=&quot;输入消息...&quot;&gt;    &lt;button onclick=&quot;sendMessage()&quot;&gt;发送&lt;/button&gt;    &lt;script&gt;        // 初始化WebSocket连接        const socket = new WebSocket(`ws://$&#123;window.location.host&#125;/ws`);        // 连接成功回调        socket.onopen = () =&gt; &#123;            addMessage(&#x27;系统&#x27;, &#x27;已连接到服务器&#x27;);        &#125;;        // 接收消息处理        socket.onmessage = (event) =&gt; &#123;            const data = JSON.parse(event.data);            addMessage(&#x27;机器人&#x27;, data.message);        &#125;;        // 错误处理        socket.onerror = (error) =&gt; &#123;            addMessage(&#x27;系统&#x27;, `连接错误: $&#123;error.message&#125;`);        &#125;;        // 关闭连接处理        socket.onclose = () =&gt; &#123;            addMessage(&#x27;系统&#x27;, &#x27;连接已断开&#x27;);        &#125;;        // 发送消息        function sendMessage() &#123;            const input = document.getElementById(&#x27;input&#x27;);            const message = input.value.trim();            if (message) &#123;                socket.send(JSON.stringify(&#123;                    type: &quot;user_message&quot;,                    content: message                &#125;));                addMessage(&#x27;我&#x27;, message);                input.value = &#x27;&#x27;;            &#125;        &#125;        // 添加消息到界面        function addMessage(sender, content) &#123;            const output = document.getElementById(&#x27;output&#x27;);            const div = document.createElement(&#x27;div&#x27;);            div.innerHTML = `&lt;strong&gt;$&#123;sender&#125;:&lt;/strong&gt; $&#123;content&#125;`;            output.appendChild(div);            // 自动滚动到底部            output.scrollTop = output.scrollHeight;        &#125;    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&#x27;&#x27;&#x27;@app.get(&quot;/&quot;)async def index():    return HTMLResponse(HTML_TEMPLATE)# WebSocket端点@app.websocket(&quot;/ws&quot;)async def websocket_endpoint(websocket: WebSocket):    await websocket.accept()    try:        while True:            # 接收客户端消息            data = await websocket.receive_text()            message_data = json.loads(data)            # 处理客户端消息            if message_data[&#x27;type&#x27;] == &#x27;user_message&#x27;:                print(f&quot;收到客户端消息: &#123;message_data[&#x27;content&#x27;]&#125;&quot;)                # 构造回复消息                reply = &#123;                    &quot;type&quot;: &quot;server_response&quot;,                    &quot;message&quot;: f&quot;机器人回复：你说的是 &#x27;&#123;message_data[&#x27;content&#x27;]&#125;&#x27; 对吗？&quot;                &#125;                # 发送回复                await websocket.send_json(reply)    except WebSocketDisconnect:        print(&quot;客户端断开连接&quot;)    except Exception as e:        print(f&quot;发生错误: &#123;str(e)&#125;&quot;)if __name__ == &quot;__main__&quot;:    import uvicorn    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8001)\nflask使用websocketimport eventleteventlet.monkey_patch()  # 关键：启用异步支持from flask import Flask, render_template_string#pip install flask-socketio eventletfrom flask_socketio import SocketIO, emitapp = Flask(__name__)app.config[&#x27;SECRET_KEY&#x27;] = &#x27;secret!&#x27;socketio = SocketIO(app, cors_allowed_origins=&quot;*&quot;)  # 允许跨域@app.route(&#x27;/&#x27;)def index():    return render_template_string(&#x27;&#x27;&#x27;    &lt;!DOCTYPE html&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;Socket.IO 聊天&lt;/title&gt;        &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.7.2/socket.io.js&quot;&gt;&lt;/script&gt;        &lt;style&gt;            /* 保持原有样式不变 */            body &#123; max-width: 800px; margin: 20px auto; padding: 20px; &#125;            #output &#123; height: 300px; border: 1px solid #ccc; overflow-y: auto; padding: 10px; &#125;        &lt;/style&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div id=&quot;output&quot;&gt;&lt;/div&gt;        &lt;input id=&quot;input&quot; placeholder=&quot;输入消息&quot;&gt;        &lt;button onclick=&quot;send()&quot;&gt;发送&lt;/button&gt;        &lt;script&gt;            const socket = io();  // 自动连接当前域名            // 连接成功回调            socket.on(&#x27;connect&#x27;, () =&gt; &#123;                addMessage(&#x27;系统&#x27;, &#x27;已连接到服务器&#x27;);            &#125;);            // 接收服务器消息            socket.on(&#x27;server_response&#x27;, (data) =&gt; &#123;                addMessage(&#x27;机器人&#x27;, data.message);            &#125;);            // 发送消息            function send() &#123;                const input = document.getElementById(&#x27;input&#x27;);                const message = input.value.trim();                if (message) &#123;                    socket.emit(&#x27;client_message&#x27;, message);                    addMessage(&#x27;我&#x27;, message);                    input.value = &#x27;&#x27;;                &#125;            &#125;            // 添加消息到界面            function addMessage(sender, content) &#123;                const div = document.createElement(&#x27;div&#x27;);                div.innerHTML = `&lt;strong&gt;$&#123;sender&#125;:&lt;/strong&gt; $&#123;content&#125;`;                document.getElementById(&#x27;output&#x27;).appendChild(div);                // 自动滚动到底部                const output = document.getElementById(&#x27;output&#x27;);                output.scrollTop = output.scrollHeight;            &#125;        &lt;/script&gt;    &lt;/body&gt;    &lt;/html&gt;    &#x27;&#x27;&#x27;)# Socket.IO 事件处理@socketio.on(&#x27;client_message&#x27;)def handle_message(message):    print(f&#x27;收到客户端消息: &#123;message&#125;&#x27;)    # 构造回复消息    reply = f&quot;机器人回复：你说的是 &#x27;&#123;message&#125;&#x27; 对吗？&quot;    # 发送消息给客户端    emit(&#x27;server_response&#x27;, &#123;&#x27;message&#x27;: reply&#125;)if __name__ == &#x27;__main__&#x27;:    socketio.run(app, host=&#x27;0.0.0.0&#x27;, port=8000, debug=True)\n大模型使用websocket聊天# main.pyfrom fastapi import FastAPI, WebSocketfrom fastapi.responses import HTMLResponseimport requestsimport jsonapp = FastAPI()# 存储对话历史 (生产环境建议使用数据库)conversation_history = []# 集成前端页面与后端逻辑HTML_TEMPLATE = &quot;&quot;&quot;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;AI 对话助手&lt;/title&gt;    &lt;style&gt;        body &#123;            max-width: 800px;            margin: 0 auto;            padding: 20px;            font-family: Arial, sans-serif;        &#125;        #chatContainer &#123;            height: 60vh;            border: 1px solid #ddd;            border-radius: 8px;            overflow-y: auto;            padding: 15px;            margin-bottom: 15px;            background: #f9f9f9;        &#125;        .message &#123;            margin: 10px 0;            padding: 12px;            border-radius: 15px;            max-width: 80%;            word-wrap: break-word;        &#125;        .user-message &#123;            background: #e3f2fd;            margin-left: auto;            border-bottom-right-radius: 5px;        &#125;        .bot-message &#123;            background: #fff;            border: 1px solid #eee;            margin-right: auto;            border-bottom-left-radius: 5px;        &#125;        #inputContainer &#123;            display: flex;            gap: 10px;        &#125;        #userInput &#123;            flex: 1;            padding: 12px;            border: 1px solid #ddd;            border-radius: 25px;            outline: none;        &#125;        button &#123;            padding: 12px 25px;            background: #007bff;            color: white;            border: none;            border-radius: 25px;            cursor: pointer;            transition: background 0.3s;        &#125;        button:hover &#123;            background: #0056b3;        &#125;        .status &#123;            color: #666;            text-align: center;            padding: 10px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;AI 对话助手&lt;/h1&gt;    &lt;div id=&quot;chatContainer&quot;&gt;&lt;/div&gt;    &lt;div id=&quot;inputContainer&quot;&gt;        &lt;input type=&quot;text&quot; id=&quot;userInput&quot; placeholder=&quot;输入消息...&quot; /&gt;        &lt;button onclick=&quot;sendMessage()&quot;&gt;发送&lt;/button&gt;    &lt;/div&gt;    &lt;div class=&quot;status&quot; id=&quot;status&quot;&gt;连接状态：正常&lt;/div&gt;       // &lt;iframe   //      src=&quot;http://47.237.81.149/chatbot/9h9nyQcblGTesiGJ&quot;    //     style=&quot;width: 100%; height: 100%; min-height: 700px&quot;   //      frameborder=&quot;0&quot;  //       allow=&quot;microphone&quot;&gt;   // &lt;/iframe&gt;    &lt;script&gt;        const ws = new WebSocket(&#x27;ws://&#x27; + window.location.host + &#x27;/ws&#x27;);        const chatContainer = document.getElementById(&#x27;chatContainer&#x27;);        let isBotResponding = false;        // WebSocket 事件处理        ws.onopen = () =&gt; updateStatus(&#x27;已连接&#x27;);        ws.onclose = () =&gt; updateStatus(&#x27;连接已断开&#x27;);        ws.onerror = () =&gt; updateStatus(&#x27;连接错误&#x27;);        ws.onmessage = (event) =&gt; &#123;            const data = JSON.parse(event.data);            handleResponse(data);        &#125;;        function handleResponse(data) &#123;            switch(data.type) &#123;                case &#x27;user_message&#x27;:                    appendMessage(data.content, &#x27;user&#x27;);                    break;                case &#x27;assistant_start&#x27;:                    isBotResponding = true;                    appendMessage(&#x27;&#x27;, &#x27;bot&#x27;);                    break;                case &#x27;assistant_chunk&#x27;:                    appendChunk(data.content);                    break;                case &#x27;assistant_end&#x27;:                    isBotResponding = false;                    break;                case &#x27;error&#x27;:                    appendMessage(`错误：$&#123;data.content&#125;`, &#x27;error&#x27;);                    break;            &#125;        &#125;        function appendMessage(content, role) &#123;            const div = document.createElement(&#x27;div&#x27;);            div.className = `message $&#123;role&#125;-message`;            div.textContent = content;            chatContainer.appendChild(div);            scrollToBottom();        &#125;        function appendChunk(content) &#123;            const messages = document.getElementsByClassName(&#x27;bot-message&#x27;);            const lastMsg = messages[messages.length - 1];            lastMsg.textContent += content;            scrollToBottom();        &#125;        function scrollToBottom() &#123;            chatContainer.scrollTop = chatContainer.scrollHeight;        &#125;        function updateStatus(text) &#123;            document.getElementById(&#x27;status&#x27;).textContent = `状态：$&#123;text&#125;`;        &#125;        function sendMessage() &#123;            const input = document.getElementById(&#x27;userInput&#x27;);            const message = input.value.trim();            if (message &amp;&amp; !isBotResponding) &#123;                ws.send(message);                input.value = &#x27;&#x27;;            &#125;        &#125;        // 支持回车发送        document.getElementById(&#x27;userInput&#x27;).addEventListener(&#x27;keypress&#x27;, (e) =&gt; &#123;            if (e.key === &#x27;Enter&#x27;) sendMessage();        &#125;);    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot;@app.get(&quot;/&quot;)async def get():    return HTMLResponse(HTML_TEMPLATE)@app.websocket(&quot;/ws&quot;)async def websocket_endpoint(websocket: WebSocket):    await websocket.accept()    try:        while True:            # 接收用户消息            user_message = await websocket.receive_text()            # 更新对话历史            conversation_history.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message&#125;)            # 发送用户消息到前端            await websocket.send_json(&#123;                &quot;type&quot;: &quot;user_message&quot;,                &quot;content&quot;: user_message            &#125;)            # 准备流式请求            await websocket.send_json(&#123;&quot;type&quot;: &quot;assistant_start&quot;&#125;)            # 构造请求数据            request_data = &#123;                &quot;model&quot;: &quot;deepseek-r1:latest&quot;,                &quot;messages&quot;: conversation_history,                &quot;stream&quot;: True            &#125;            # 流式获取响应            full_response = []            with requests.post(                    &quot;http://1.1.1.1:11434/api/chat&quot;,#大模型接口地址                    json=request_data,                    stream=True            ) as response:                response.raise_for_status()                for line in response.iter_lines():                    if line:                        chunk = json.loads(line.decode(&#x27;utf-8&#x27;))                        if &#x27;message&#x27; in chunk:                            content = chunk[&#x27;message&#x27;][&#x27;content&#x27;]                            full_response.append(content)                            await websocket.send_json(&#123;                                &quot;type&quot;: &quot;assistant_chunk&quot;,                                &quot;content&quot;: content                            &#125;)            # 保存完整响应            conversation_history.append(&#123;                &quot;role&quot;: &quot;assistant&quot;,                &quot;content&quot;: &quot;&quot;.join(full_response)            &#125;)            await websocket.send_json(&#123;&quot;type&quot;: &quot;assistant_end&quot;&#125;)    except Exception as e:        await websocket.send_json(&#123;            &quot;type&quot;: &quot;error&quot;,            &quot;content&quot;: f&quot;系统错误: &#123;str(e)&#125;&quot;        &#125;)    finally:        await websocket.close()if __name__ == &quot;__main__&quot;:    import uvicorn    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)","tags":["websocket"]},{"title":"使用kubekey快速安装k8s","url":"/2025/04/27/%E4%BD%BF%E7%94%A8kubekey%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85k8s/","content":"官方地址https://github.com/kubesphere/kubekey\n安装\ncurl -sfL https://get-kk.kubesphere.io | sh -\n\n单节点测试使用kk create cluster#默认 v1.23.17--with-kubernetes v1.24.1 #默认docker--container-manager containerd#如果不使用--with-kubesphere默认不安装；默认版本为 v3.4.1--with-kubesphere\n多节点kk create config -f deploy.yml#-f 指定配置文件开始安装kk create cluster -f deploy.yml#deploy.yml;其他节点的ip用户名密码的修改成实际的apiVersion: kubekey.kubesphere.io/v1alpha2kind: Clustermetadata:  name: samplespec:  hosts:  - &#123;name: node1, address: 172.16.0.2, internalAddress: 172.16.0.2, user: ubuntu, password: &quot;Qcloud@123&quot;&#125;  - &#123;name: node2, address: 172.16.0.3, internalAddress: 172.16.0.3, user: ubuntu, password: &quot;Qcloud@123&quot;&#125;  roleGroups:    etcd:    - node1    control-plane:     - node1    worker:    - node1    - node2  controlPlaneEndpoint:    ## Internal loadbalancer for apiservers     # internalLoadbalancer: haproxy    domain: lb.kubesphere.local    address: &quot;&quot;    port: 6443  kubernetes:    version: v1.23.17    clusterName: cluster.local    autoRenewCerts: true    containerManager: docker  etcd:    type: kubekey  network:    plugin: calico    kubePodsCIDR: 10.233.64.0/18    kubeServiceCIDR: 10.233.0.0/18    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni    multusCNI:      enabled: false  registry:    privateRegistry: &quot;&quot;    namespaceOverride: &quot;&quot;    registryMirrors: []    insecureRegistries: []  addons: []----------------------------------------------------#默认不安装kubesphere需要指定--with-kubespherekk create config --with-kubesphere -f deploy-with.yml\n新增删除#新增节点接入集群kk add nodes -f  deploy.yml#删除节点kk delete node &lt;nodeName&gt; -f deploy.yml#删除集群kk delete cluster [-f deploy.yml]\n\n升级集群使用指定版本升级集群。kk upgrade [--with-kubernetes version] [--with-kubesphere version] 仅支持升级 Kubernetes。仅支持升级 KubeSphere。支持升级 Kubernetes 和 KubeSphere。多节点使用指定的配置文件升级集群。kk upgrade [--with-kubernetes version] [--with-kubesphere version] [(-f | --filename) path]如果指定了--with-kubernetes或--with-kubesphere，配置文件也将被更新。用于-f指定为集群创建而生成的配置文件。\n\n更新集群证书\n#默认一年kk  certs renew\n\n","categories":["k8s"]},{"title":"使用maven打包","url":"/2025/05/12/%E4%BD%BF%E7%94%A8maven%E6%89%93%E5%8C%85/","content":"使用springboot&lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.5.9&lt;/version&gt;        &lt;relativePath/&gt;    &lt;/parent&gt;    &lt;groupId&gt;org.ecs&lt;/groupId&gt;    &lt;artifactId&gt;springboot01&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n其他&lt;groupId&gt;org.example&lt;/groupId&gt;    &lt;artifactId&gt;CpuLoad&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;3.1.0&lt;/version&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;manifest&gt;                            &lt;!-- 指定入口函数 --&gt;                             \t\t\t    &lt;mainClass&gt;org.example.CpuLoad&lt;/mainClass&gt;                            &lt;!-- 是否添加依赖的jar路径配置 --&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;!-- 依赖的jar包存放未知，和生成的jar放在同一级目录下 --&gt;                            &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;                        &lt;/manifest&gt;                    &lt;/archive&gt;                    &lt;!-- 不打包com.yh.excludes下面的所有类 --&gt;                    &lt;excludes&gt;com/xx/excludes/*&lt;/excludes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n","tags":["maven"]},{"title":"常用命令记录","url":"/2025/08/12/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","content":"perf#进程热点函数分析perf top -g -p 21515perf record -F 99 -a -g -p $pid -- sleep 60-e选项允许您在perf list命令中列出的多个类别中选择一个事件类别。perf report -i 文件 -gperf report -g graph,0.3#默认0.5，低于不显示堆栈#隐藏CPUperf sched record -C 0 -- sleep 5 (-C后面的参数，填CPU使用率高的cpu序号，0表示第一个CPU)perf report 选择 sched:sched_switch 按回车键perf sched latency --sort max\nstracestrace -tt -T -v -f -e trace=file -o /data/log/strace.log -s 1024 -p 23489● -tt：在每行输出的前面，显示毫秒级别的时间● -T：显示每次系统调用所花费的时间● -v：对于某些相关调用，把完整的环境变量，文件 stat 结构等打出来。● -f：跟踪目标进程，以及目标进程创建的所有子进程● -e：控制要跟踪的事件和跟踪行为，比如指定要跟踪的系统调用名称● -o：把 strace 的输出单独写到指定的文件● -s：当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是 32 个字节● -p：指定要跟踪的进程 pid，要同时跟踪多个 pid，重复多次 -p 选项即可。-e trace=file     跟踪和文件访问相关的调用(参数中有文件名)-e trace=process  和进程管理相关的调用，比如fork/exec/exit_group-e trace=network  和网络通信相关的调用，比如socket/sendto/connect-e trace=signal    信号发送和处理相关，比如kill/sigaction-e trace=desc  和文件描述符相关，比如write/read/select/epoll等\n\ndddd if=/dev/zero  of=/data/test  bs=10M status=progress  count=10000 oflag=direct  写入dd if=/data/test  of=/dev/null   bs=10M  count=10000 oflag=direct  status=progress  读取#direct　　　　　　　　　　　　　　　  读写数据采用直接IO方式；#status=progress 显示进度\ntcpdump• 选择所有端口，指定host域名抓包，抓包文件存入/tmp/中：tcpdump –nni any –s 0 host www.ex.com –w /tmp/ex.com.pcap• 指定eth0，指定目标IP和端口，并指定抓取1000个报文tcpdump –nni eth0 host 1.1.1.1 and port 80 –c 1000• 指定某网段，如下表达式默认为/24位tcpdump –nni eth0 net 1.1.1.1 and portrange 8000-8080常用语句•循环抓包（抓取前500个字节，500M一个文件，保存10个）tcpdump -i eth0 -s 500 host 1.1.1.1 -w /tmp/test.pcap -C 500 -W 10特殊场景语句，抓取特定的tcp置位报文tcpdump -nni any tcp[tcpflags]=tcp-syn/tcp-rst/tcp-ack/tcp-ack\n\niperf3Client/Server: # 客户端和服务端公有的参数指定端口号，默认为5201                 -p, --port      #        server port to listen on/connect to 回显报告的间隔时间                           -i, --interval  #        seconds between periodic bandwidth reports  显示帮助菜单      -h, --help               print this message and quit   显示版本    -v, --version            print version information and quit    Server specific:  #服务端私有参数指定以服务端运行                                                                -s, --server             run in server mode                                               Client specific:  #客户端私有参数带宽参数，单位：字节每秒：KMG，为2的n次方，比如1K=1024,；设置为0代表无限制，此参数UDP默认1M/s，TCP无限制     -b, --bandwidth #[KMG][/#] target bandwidth in bits/sec (0 for unlimited)                            (default 1 Mbit/sec for UDP, unlimited for TCP)                            (optional slash and packet count for burst mode) 指定以客户端运行，后面要带服务端的IP地址                                -c, --client    &lt;host&gt;   run in client mode, connecting to &lt;host&gt;   udp模式，不带-u默认为tcp模式    -u, --udp                use UDP rather than TCP   指定测试时间，不带参数默认测试10s            -t, --time      #        time in seconds to transmit for (default 10 secs)  翻转测试，这是iperf3比iperf2方便的主要亮点，iperf2不支持此功能，无法使用       -R, --reverse            reverse the test (client receives, server sends)  tcp窗口大小，默认无上限，可以不设此参数，作为udp模式测试时也不需要此参数 ，单位：KM，1K=1024         -w, --window    #[KMG]    set window size / socket buffer size  iperf -s -i 1# 作为服务端运行，报告回显间隔时间1siperf3 -c 192.168.3.250 -i 1 -t 10 -b 7M#作为客户端，连接服务端ip地址192.168.3.250，报告回显间隔1s，测试时间10s,带宽限制为7M。iperf3 -c 192.168.3.250 -i 1 -t 10 -b 7M -R#作为客户端，连接服务端ip地址192.168.3.250，报告回显间隔1s，测试时间10s,带宽限制为7M,-R为反向测试，这个参数也是iperf3的主要亮点，支持直接转换数据发送方向#udp不指定-b默认1Miperf -s -i 1# 作为服务端运行，报告回显间隔时间1s，服务端不区分tcp或udpiperf3 -u -c 192.168.3.250 -b 70M -i 1 -t 10#作为客户端运行，限制带宽70M，报告回显间隔1s，测试时间10siperf3 -u -c 192.168.3.250 -b 70M -i 1 -t 10 -R#作为客户端运行，限制带宽70M，报告回显间隔1s，测试时间10s\n\n额外常用时间while  true; do date +%Y-%m-%d&#x27; &#x27;%H:%M:%S.%N | cut -b 1-23 &amp;&amp; sleep 1;donecurlcurl localhost:3000/api/json -X POST -d &#x27;&#123;&quot;hello&quot;: &quot;world&quot;&#125;&#x27; --header &quot;Content-Type: application/jsoncurl -v -o output.html &quot;https://dana.lobn.com.cn/&quot; \\     --resolve dana.lobn.com.cn:443:8.152.0.157curl -L -XPOST -H &#x27;Cookie: authToken $token&#x27; -F &quot;uploadFiles=@/home/user/test1&quot; https://gdw-3.com/api/v1/detail/upload 端口nmap -v  -sS  -sV  -T 5 39.105.26.196  -p 9984sed -i.bak &#x27;/^\\s*[^#].*\\/data\\s/s/^/#/&#x27; /etc/fstab  badblocks -sv /dev/vda● -v：显示详情。● -s：显示进度。● -w：写模式测试（慎用！会覆盖数据）登录日志lastb | awk &#x27;&#123; print&quot; IP地址为：&quot; $3&#125;&#x27; | sort | uniq -c | sort -nr|head网络netstat -ant | awk &#x27;/^tcp/ &#123;++y[$NF]&#125; END &#123;for(w in y) print w, y[w]&#125;&#x27;while true;do netstat -n | awk &#x27;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a,S[a]&#125;&#x27;;sleep 1;done | grep TIME_WAITtraceroute  -n -T global-cs.aceux.net -p 80 || yum install traceroute -ynetstat -s |grep -e &quot;passive connections rejected because of time stamp&quot; netstat -s | grep &quot;SYNs to LISTEN&quot;netstat -s|egrep -i &#x27;syn|ignore|overflow|reject|becau|error|drop|back&#x27; 进程ps -A -ostat,ppid,pid,cmd | grep -e &#x27;^[Zz]&#x27;ps  -e -L h o state,cmd,pid | awk &#x27;&#123;if($1==&quot;R&quot;||$1==&quot;D&quot;)&#123;print $0&#125;&#125;&#x27; | sort | uniq -c | sort -k 1nrps -auxww --sort=-%cpu|headps -eT -o%cpu,pid,tid,ppid,comm | grep -v CPU | sort -n -r | head -20ps -auxww --sort=-%mem|headps -T -o%cpu,pid,tid,ppid,comm -p           # 查看指定进程的所有线程ps -Lf &lt;PID&gt;            # 显示线程的详细信息ps axjf --no-header  #进程树systemctl list-units --type=service --state=runningsystemctl list-units --type=service --state=running --no-pager |grep running |awk &#x27;&#123;print $1&#125;&#x27; |xargs systemctl cat |grep -i execstartlsof -nw|awk &#x27;&#123;print $2&#125;&#x27;| sort | uniq -c | sort -nr | head# 自定义终端提示符PS1=&#x27;\\[\\e[38;5;208m\\]\\u@\\h\\[\\e[0m\\] \\[\\e[38;5;34m\\]\\D&#123;%H:%M:%S&#125;\\[\\e[0m\\] \\[\\e[38;5;33m\\]\\w\\[\\e[0m\\] \\[\\e[1;31m\\]$(git branch 2&gt;/dev/null | grep &quot;^*&quot; | colrm 1 2)\\[\\e[0m\\]\\n\\[\\e[1;32m\\]➜ \\[\\e[0m\\]&#x27;PS1=&#x27;\\[\\033[1;31m\\][\\t] \\[\\033[1;32m\\]\\u\\[\\033[1;36m\\]@\\[\\033[1;34m\\]\\h \\[\\033[1;33m\\]\\w\\[\\033[0m\\] &#x27;#pythonpip cache purgepip cache remove package-namepip install --no-cache-dir torch pip show  torchpip install --target=/mnt/xinference \\ --cache-dir=/mnt/xinference/pip_cache \\ &quot;xinference[all]&quot;python -c &quot;import os; print(&#x27;\\n&#x27;.join(dir(os)))&quot; | grep &#x27;kill&#x27;nginx -V 2&gt;&amp;1 | grep -o with-http_stub_status_module\n","categories":["linux"]},{"title":"数据库","url":"/2025/07/24/%E6%95%B0%E6%8D%AE%E5%BA%93/","content":"数据库mysql索引失效情况\n回表概念1.聚集索引的B+树，性能最优，叶子节点存储的数据是整行的所有字段数据(主键索引)2.非聚集索引的B+树，非聚集索引列可能是一列，也可能是多列（联合索引），  叶子节点存储的数据是非聚集索引列（1列或多列）的数据和聚集索引列用户user表4列（id, userCode, userName, userSex）id是主键（聚集索引）；userCode 是非聚集索引，此时会创建2个索引的B+树聚集索引的B+树，叶子节点保存了4列（id, userCode, userName, userSex）的数据非聚集索引的B+树，叶子节点保存了2列（id, userCode）的数据不回表走主键索引不回表，因为挂载的是整列数据select * from user where id = 1 走非聚集索引不回表，因为叶子结点挂载了非聚集索引和聚集索引的值select id,userCode from user where userCode = 1 回表因为查询的列除了主键id和非聚集索引userCode还有userName, userSex，这两个叶子节点没有存数据，会通过主键索引id回表来查询userName, userSex的值，因为主键索引id挂载的整列的值select id,userCode，userSex from user where userCode = 1select id,userCode，userName from user where userCode = 1select * from user where userCode = 1\n常用sql元数据#指定数据库的详细信息SELECT   TABLE_SCHEMA AS &#x27;数据库&#x27;,  TABLE_NAME AS &#x27;表名&#x27;,  TABLE_ROWS AS `行数`,  ROUND( (DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) AS &#x27;总大小(MB)&#x27;,  ROUND(DATA_LENGTH / 1024 / 1024, 2) AS &#x27;数据大小(MB)&#x27;,  ROUND(INDEX_LENGTH / 1024 / 1024, 2) AS &#x27;索引大小(MB)&#x27;,  TABLE_ROWS AS &#x27;数据行数（估算值）&#x27;FROM information_schema.TABLESWHERE TABLE_SCHEMA = &#x27;y_back&#x27;  -- 替换为你的数据库名ORDER BY (DATA_LENGTH + INDEX_LENGTH) DESC;  -- 按总大小排序#数据库表的行数SELECT   TABLE_NAME AS &#x27;表名&#x27;,  TABLE_ROWS AS &#x27;估算行数&#x27;,  (SELECT COUNT(*) FROM y_back.t_work) AS &#x27;精确行数&#x27;  -- 替换为实际表名FROM information_schema.TABLESWHERE TABLE_SCHEMA = &#x27;y_back&#x27;;#allSELECT\ttable_schema AS &#x27;数据库&#x27;,\tsum( table_rows ) AS &#x27;记录数&#x27;,\tsum(\tTRUNCATE ( data_length / 1024 / 1024, 2 )) AS &#x27;数据容量(MB)&#x27;,\tsum(\tTRUNCATE ( index_length / 1024 / 1024, 2 )) AS &#x27;索引容量(MB)&#x27; FROM\tinformation_schema.TABLES GROUP BY\ttable_schema ORDER BY\tsum( data_length ) DESC,\tsum( index_length ) DESC;#过滤元数据库SELECT  table_schema AS &#x27;数据库&#x27;,  SUM(table_rows) AS &#x27;记录数&#x27;,  TRUNCATE(SUM(data_length) / 1024 / 1024, 2) AS &#x27;数据容量(MB)&#x27;,  -- 先求和再转换单位  TRUNCATE(SUM(index_length) / 1024 / 1024, 2) AS &#x27;索引容量(MB)&#x27;FROM  information_schema.TABLESWHERE  table_schema NOT IN (    &#x27;information_schema&#x27;,     &#x27;mysql&#x27;,     &#x27;performance_schema&#x27;,     &#x27;sys&#x27;  )GROUP BY  table_schemaORDER BY  SUM(data_length) DESC,  SUM(index_length) DESC;ANALYZE TABLE - 更新统计信息OPTIMIZE TABLE - 表优化重组俗称清理碎片#造数据CREATE TABLE `t_work_db01` (  `id` bigint NOT NULL AUTO_INCREMENT,  `name` varchar(256) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci DEFAULT NULL,  `age` int DEFAULT NULL,  `sex` char(1) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci DEFAULT NULL,  `money` float DEFAULT NULL COMMENT &#x27;金额&#x27;,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=100001 DEFAULT CHARSET=utf8mb3 ROW_FORMAT=DYNAMICDELIMITER $$CREATE PROCEDURE InsertDummyData()BEGIN    DECLARE i INT DEFAULT 0;    WHILE i &lt; 100000 DO        INSERT INTO t_work (NAME, age, sex, money)        VALUES (            -- 随机生成用户名（示例：User_XXXX）            CONCAT(&#x27;User_&#x27;, SUBSTRING(MD5(RAND()) FROM 1 FOR 8)),            -- 随机年龄 18~65 岁            FLOOR(18 + RAND() * 48),            -- 随机性别（M/F）            IF(RAND() &lt; 0.5, &#x27;M&#x27;, &#x27;F&#x27;),            -- 随机金额 1000~10000（保留两位小数）            ROUND(1000 + RAND() * 9000, 2)        );        SET i = i + 1;    END WHILE;END$$DELIMITER ;-- 执行存储过程CALL InsertDummyData();DROP PROCEDURE IF EXISTS InsertDummyData;  -- 强制删除（如果存在）\nmysql读写分离github ProxySqlMaxScale\nmysql分表分库mycat\npgsqlPostgreSQL psql 常用命令\n概念PUBLIC 是 PostgreSQL 数据库中一个特殊的角色组，在元数据表（pg_roles）中都查不到该角色，数据库中所创建的角色都可以理解为是 PUBLIC 角色组成员。而且对 PUBLIC 权限的继承完全不受 NOINHERIT 的控制，一旦创建了一个拥有 login 权限的角色，它会立即继承 PUBLIC 角色组拥有的权限，此时如果想通过 revoke（比如 revoke connect on database）来回收的话不会成功，只能从 PUBLIC 组回收相关权限（比如 revoke connect on database from PUBLIC）REVOKE CONNECT ON DATABASE test FROM PUBLIC;--这样普通用户就无法自由切换数据库，默认数据库下面有一个public的schemeMySQL 的 datadir ≈ PostgreSQL 的默认表空间 pg_defaultPostgreSQL 的 pg_default 表空间对应默认数据目录（由参数 data_directory 配置），类似于 MySQL 的 datadir。PostgreSQL 的数据库 ≈ MySQL 的实例（但更轻量）。PostgreSQL 的模式 ≈ MySQL 的数据库\n\n基本使用命令docker run -id --name=pgsql -v postgre-data:/var/lib/postgresql/data -p 54222:5432 -e POSTGRES_PASSWORD=123456 -e LANG=C.UTF-8 bitnami/postgresqldocker exec -it -uroot pgsql bashpsql -U postgres -W -ncat .psql_history psql -h host -p port -d dbname -U  user -W使用反斜线作为命令前缀.  postgres=# \\db# 输出的信息如下：       List of tablespaces    Name    |  Owner   | Location ------------+----------+---------- pg_default | postgres |  pg_global  | postgres | (2 rows)退出    \\q 列出所有的数据库      \\l 列出所有的数据库的大小      \\l+ 更改当前连接的数据库       \\c 列出当前数据库的连接信息    \\connect 列出当前数据库和连接的详细信息 \\conninfo 查看当前数据库里面的表和拥有者和表大小         \\dt+ 展示所有用户           \\dg ​模式 \\dn 查看所有表名的列表             \\d 获取表结构                   \\da 展示所有用户               \\du 查看t_sms表的结构      \\d t_sms  展示数据库里面的所有的表         \\dt 列出所有的数据库的详细信息（包括数据库大小和字符格式）         \\l+ 显示用户访问权限。                            \\z或\\dp 显示所有可设置的访问权限                     \\h GRAN 显示用户的对所有数据库表的详细访问权限     \\dp或者\\z 确认当前连接的用户为超级用户postgres，且该用户后创建角色和数据库的权限等     #select current_user; 在超级用户连接postgres后，设置不允许普通用户a连接数据库         #alter role a nologin; ​ 使用普通用户a连接数据库正常                   #\\c highgo a快速查看当前所有用户：\\du查看详细用户信息：select * from pg_user;查看详细角色信息：select * from pg_roles;查看当前登录用户：select user;一般建议先创建用户然后使用这个用户去创建数据库模式，因为数据库那个用户创建的默认Owner就是这个用户创建用户：CREATE USER $user_name PASSWORD &#x27;$password&#x27;;创建角色：CREATE ROLE $role_name; 修改用户与角色：ALTER USER[ROLE] $user_name         e.g.        //修改用户名：ALTER USER U2 RENAME TO U22;        //修改用户的密码：ALTER USER U22 PASSWORD&#x27;U22;        //修改用户的权限：ALTER USER u22 CREATEROLE;        //修改数据库 testdb中的参数重设为默认值：ALTER USER u22 IN DATABASE testdb RESET all1;        //修改角色的名字：ALTER ROLE dev RENAME TO dev1;        //修改角色的权限：ALTER ROLE dev1 SUPERUSER;        //修改角色的权限：ALTER ROLE dev1 LOGIN; 删除用户与角色：DROP USER[ROLE] [IF EXISTS] $user_name 授权用户某个角色:GRANT $role_name TO $user_name;    (授权后set role $role_name启用生效） create user test with password &#x27;rong &#x27;;CREATE DATABASE testdb OWNER test;GRANT ALL PRIVILEGES ON DATABASE testdb TO test;alter user qh with password &#x27;123&#x27;;\\password qh;  //需要输入两次密码（推荐）\n\n\n\nmanggodb详细使用教程\ndocker run -itd --name mongo -v /docker_volume/mongodb/data:/data/db -p 27017:27017 mongo:4.4 --auth–auth：需要密码才能访问容器服务；mongodb安装好后第一次进入是不需要密码的，也没有任何用户，通过shell命令可直接进入use admin 使用admin数据库并进行验证，如果不验证，是做不了任何操作的db.auth(&quot;root&quot;,&quot;123456&quot;)  返回1表示成功 验证之后还是做不了操作，因为root只有用户管理权限，下面创建用户，用户都跟着库走use mydb db.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;123456&quot;,roles: [&#123; role: &quot;readWrite&quot;, db: &quot;mydb&quot; &#125;]&#125;) 通过admin用户增删改查docker exec -it mongo mongo admindb.createUser(&#123; user:&#x27;root&#x27;,pwd:&#x27;123456&#x27;,roles:[ &#123; role:&#x27;userAdminAnyDatabase&#x27;, db: &#x27;admin&#x27;&#125;,&#x27;readWriteAnyDatabase&#x27;]&#125;);【role:‘userAdminAnyDatabase’】：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限【db: ‘admin’】：可操作的数据库【‘readWriteAnyDatabase’】：赋予用户读写权限mongoDB 没有无敌用户root，只有能管理用户的用户 userAdminAnyDatabase SQL 术语/概念\tMongoDB 术语/概念   解释/说明database\t    database\t       数据库table\t        collection\t       数据库表/集合row\t            document\t       数据记录行/文档column\t        field\t           数据字段/域index\t        index\t           索引table joins\t \t表连接,            MongoDB不支持primary key\t    primary key\t       主键,MongoDB自动将_id字段设置为主键\nsqlserverdocker run -d \\  --name sqlserver --user=root \\  -e &quot;ACCEPT_EULA=Y&quot; \\  -e &quot;SA_PASSWORD=Testing@123&quot;  -p 1433:1433  -v /data/sqlserver:/var/opt/mssql \\  --cap-add SYS_PTRACE mcr.microsoft.com/mssql/server:2019-latest  /opt/mssql-tools18/bin/sqlcmd -S localhost -U SA -P &quot;Testing@123&quot; -C  -- 数据库级  SELECT name, type_desc FROM sys.database_principals WHERE type IN (&#x27;S&#x27;, &#x27;U&#x27;, &#x27;G&#x27;);  select * from master.dbo.SysDatabases  --服务器级  SELECT name, type_desc FROM sys.server_principals WHERE type IN (&#x27;S&#x27;, &#x27;U&#x27;, &#x27;G&#x27;);  go  SELECT DB_NAME() AS [CurrentDatabase];  USE master; SELECT name FROM sys.schemas  USE master; SELECT name FROM sys.tables  SELECT name, USER_NAME(principal_id) FROM sys.schemas;CREATE TABLE Users (    UserID INT PRIMARY KEY IDENTITY(1,1),     UserName NVARCHAR(50) NOT NULL,   Email NVARCHAR(100) NOT NULL, RegistrationDate DATETIME DEFAULT GETDATE(), IsActive BIT DEFAULT 1);INSERT INTO Users (UserName, Email) VALUES     (&#x27;王五&#x27;, &#x27;wangwu@example.com&#x27;),    (&#x27;赵六&#x27;, &#x27;zhaoliu@example.com&#x27;),    (&#x27;孙七&#x27;, &#x27;sunqi@example.com&#x27;);--cdcuse y_testEXEC sys.sp_cdc_enable_db;go SELECT name AS [y_test],    is_cdc_enabled AS [CDCEnabled]FROM   sys.databases WHERE     name = DB_NAME(); \n","categories":["db"]},{"title":"斗地主","url":"/2025/08/15/%E6%96%97%E5%9C%B0%E4%B8%BB/","content":"\n简易gui斗地主摸鱼小游戏；启动服务端和三个客户端即可使用\n\n服务端#!/usr/bin/python# -*- coding: utf-8 -*-# 文件名：server.pyimport socketimport jsonimport randomimport threadingimport timeClient_Number = 0  # 客户端数FLAG = 0FLAG1 = 0FLAG2 = 0  # 抢地主判定符# 牌型全局type = &#x27;init&#x27;value = 0seq_num = 0jumpCounter = 0POKER = [0 for i in range(54)]for i in range(1, 55):    POKER[i - 1] = irandom.shuffle(POKER)  # 洗牌# print(POKER)s = socket.socket()  # 创建 socket 对象#host = socket.gethostname()  # 获取本地主机名host = &#x27;0.0.0.0&#x27;port = 12345  # 设置端口s.bind((host, port))  # 绑定端口s.listen(3)  # 等待客户端连接def Turner(num):    if num == 0:        return 1    if num == 1:        return 2    if num == 2:        return 0def send_message(socket, string):    json = &#123;        &#x27;status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;message&#x27;,        &#x27;Card&#x27;: [0],        &#x27;message&#x27;: &#x27;&#x27;    &#125;    json[&#x27;message&#x27;] = string    socket.sendall(str.encode(str(json)))def ask_select(socket, socket1, socket2):    json = &#123;        &#x27;Status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;AskS&#x27;    &#125;    socket.sendall(str.encode(str(json)))    socket1.sendall(str.encode(str(json)))    socket2.sendall(str.encode(str(json)))def set_turn(socket, Type, value, seq_num):    json = &#123;        &#x27;Status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;SetTurn&#x27;,        &#x27;type&#x27;: Type,        &#x27;value&#x27;: value    &#125;    print(&#x27;sent:type=&#x27;, Type, &#x27; value=&#x27;, value, &#x27; seq_num=&#x27;, seq_num)    socket.sendall(str.encode(str(json)))def json_prase(js, socket=s, socket1=s, socket2=s):    recjs = eval(js)    global type    global value    global seq_num    global jumpCounter    if recjs[&#x27;Operation&#x27;] == &#x27;AnsS&#x27;:        return recjs[&#x27;message&#x27;]    elif recjs[&#x27;Operation&#x27;] == &#x27;AnsTurn&#x27;:        print(recjs)        # 这里会收到回牌        json = &#123;            &#x27;Status&#x27;: 200,            &#x27;Operation&#x27;: &#x27;Announce&#x27;,            &#x27;message&#x27;: recjs[&#x27;message&#x27;]        &#125;        socket.sendall(str.encode(str(json)))        socket1.sendall(str.encode(str(json)))        socket2.sendall(str.encode(str(json)))        if recjs[&#x27;type&#x27;] == &#x27;Jump&#x27;:            if jumpCounter == 1:                type = &#x27;init&#x27;                value = 0                seq_num = 0                jumpCounter = 0            else:                jumpCounter += 1        else:            jumpCounter = 0            type = recjs[&#x27;type&#x27;]            value = recjs[&#x27;value&#x27;]            seq_num = recjs[&#x27;seq_num&#x27;]        print(&#x27;JC=&#x27;, jumpCounter)        time.sleep(0.5)    elif recjs[&#x27;Operation&#x27;] == &#x27;Clear&#x27;:        send_message(socket, &#x27;Game Over!&#x27;)        send_message(socket1, &#x27;Game Over!&#x27;)        send_message(socket2, &#x27;Game Over!&#x27;)        socket.close()        socket1.close()        socket2.close()    else:        print(&#x27;Unknown json&#x27;)        return -1def send_card(socket):    ADD = [0 for i in range(3)]    ADD[0] = POKER[53]    ADD[1] = POKER[52]    ADD[2] = POKER[51]    json = &#123;        &#x27;status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;Add&#x27;,        &#x27;message&#x27;: &#x27;&#x27;    &#125;    json[&#x27;message&#x27;] = ADD    print(json)    socket.sendall(str.encode(str(json)))def init_card(socket, socket1, socket2):    SET = [0 for i in range(20)]    SET1 = [0 for i in range(20)]    SET2 = [0 for i in range(20)]    for i in range(0, 17):        SET[i] = POKER[i]  # poker的0到16号        SET1[i] = POKER[i + 17]  # poker的17到34        SET2[i] = POKER[i + 34]  # poker的34到51    print(&#x27;SET:&#x27;)    print(sorted(SET))    print(&#x27;SET1&#x27;)    print(sorted(SET1))    print(&#x27;SET2&#x27;)    print(sorted(SET2))    json = &#123;        &#x27;status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;init&#x27;,        &#x27;Card&#x27;: [0],        &#x27;message&#x27;: SET    &#125;    json1 = &#123;        &#x27;status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;init&#x27;,        &#x27;Card&#x27;: [0],        &#x27;message&#x27;: SET1    &#125;    json2 = &#123;        &#x27;status&#x27;: 200,        &#x27;Operation&#x27;: &#x27;init&#x27;,        &#x27;Card&#x27;: [0],        &#x27;message&#x27;: SET2    &#125;    socket.sendall(str.encode(str(json)))    socket1.sendall(str.encode(str(json1)))    socket2.sendall(str.encode(str(json2)))# def receive_card(socket,socket1,socket2):# START REGISTERRINGwhile True:    if Client_Number == 9:  # 暂存        c, addr = s.accept()  # 建立客户端连接。 c是本连接的socket        Client_Number = Client_Number + 1        print(&#x27;Connected by&#x27;, addr)  # 输出客户端的IP地址        data = c.recv(1024)  # 把接收的数据实例化        if len(data.strip()) == 0:            c.sendall(b&quot;Done&quot;)        else:            recData = eval(data)  # str 转 Dict            string = bytes.decode(data)  # byte to str            print(string)            print(recData[&#x27;massage&#x27;])        c.sendall(b&#x27;successfully connected&#x27;)    elif Client_Number == 0:        c, addr = s.accept()        Client_Number = Client_Number + 1        print(&#x27;Connected by&#x27;, addr)        # c.sendall(str.encode(&#x27;successfully connected from&#x27;+addr.__str__()))        send_message(c, &#x27;hello!&#x27;)    elif Client_Number == 1:        c1, addr1 = s.accept()        Client_Number = Client_Number + 1        print(&#x27;Connected by&#x27;, addr1)        # c1.sendall(str.encode(&#x27;successfully connected from&#x27;+addr1.__str__()))        send_message(c1, &#x27;hello!&#x27;)    else:        c2, addr2 = s.accept()        Client_Number = Client_Number + 1        print(&#x27;Connected By&#x27;, addr2)        # c2.sendall(str.encode(&#x27;successfully connected from&#x27;+addr1.__str__()))        send_message(c2, &#x27;hello!&#x27;)    if Client_Number == 3:        print(&#x27;Players all connected&#x27;)        time.sleep(2)        send_message(c, &#x27;Players all connected&#x27;)        send_message(c1, &#x27;Players all connected&#x27;)        send_message(c2, &#x27;Players all connected&#x27;)        break    # START PLAYINGtime.sleep(2)init_card(c, c1, c2)  # 发牌# START APPLICATINGTURN = 0while True:    ask_select(c, c1, c2)  # 要求客户端回复抢地主结果    Client_Number = 0  ##收到回应数    time.sleep(1)    # Waiting for Client 0    receive = c.recv(1024)    if len(receive.strip()) == 0:        continue    else:        FLAG = json_prase(receive)        Client_Number = Client_Number + 1    # Waiting for Client 1    time.sleep(1)  # 等待buffer    receive1 = c1.recv(1024)    if len(receive1.strip()) == 0:        continue    else:        FLAG1 = json_prase(receive1)        Client_Number = Client_Number + 1    # Waiting for Client 2    time.sleep(1)    receive2 = c2.recv(1024)    if len(receive.strip()) == 0:        continue    else:        FLAG2 = json_prase(receive2)        Client_Number = Client_Number + 1    if Client_Number == 3:        # print(&#x27;FLAG=&#x27;,FLAG)        # print(&#x27;FLAG1=&#x27;,FLAG1)        # print(&#x27;FLAG2=&#x27;,FLAG2)        if FLAG + FLAG1 + FLAG2 == 0:            continue        elif FLAG + FLAG1 + FLAG2 != 1:            continue  # 这里之后要有个加倍积分的函数        else:            if FLAG == 1:                send_message(c, &#x27;You are the king!&#x27;)                send_message(c1, &#x27;Player0 is the king!&#x27;)                send_message(c2, &#x27;Player0 is the king!&#x27;)                time.sleep(2)                send_card(c)            if FLAG1 == 1:                send_message(c1, &#x27;You are the king!&#x27;)                send_message(c, &#x27;Player1 is the king!&#x27;)                send_message(c2, &#x27;Player1 is the king!&#x27;)                time.sleep(2)                send_card(c1)                TURN = 1            if FLAG2 == 1:                send_message(c2, &#x27;You are the king!&#x27;)                send_message(c, &#x27;Player2 is the king!&#x27;)                send_message(c1, &#x27;Player2 is the king!&#x27;)                time.sleep(2)                send_card(c2)                TURN = 2            break# GAME START!while True:    time.sleep(2)    if TURN == 0:        set_turn(c, type, value, seq_num)        while True:            time.sleep(0.1)            receive = c.recv(1024)            if len(receive.strip()) == 0:                continue            else:                json_prase(receive, c, c1, c2)                TURN = Turner(TURN)                break    elif TURN == 1:        set_turn(c1, type, value, seq_num)        while True:            time.sleep(0.1)            receive = c1.recv(1024)            if len(receive.strip()) == 0:                continue            else:                json_prase(receive, c, c1, c2)                TURN = Turner(TURN)                break    elif TURN == 2:        set_turn(c2, type, value, seq_num)        while True:            time.sleep(0.1)            receive = c2.recv(1024)            if len(receive.strip()) == 0:                continue            else:                json_prase(receive, c, c1, c2)                TURN = Turner(TURN)                breakprint(&#x27;Shutting down server...&#x27;)c.close()c1.close()c2.close()\n\n\n\n客户端#!/usr/bin/python# -*- coding: utf-8 -*-import tkinter as tkfrom tkinter import ttk, messageboximport socketimport jsonimport threadingimport timeclass DouDiZhuGUI:    def __init__(self, root):        self.root = root        self.root.title(&quot;斗地主游戏&quot;)        self.root.geometry(&quot;800x600&quot;)        # 游戏状态变量        self.CARD = [0 for i in range(20)]        self.Card_num = 17        self.CURRENT = []        self.selected_cards = []  # 当前选中的牌        # 当前牌型要求        self.required_type = &#x27;init&#x27;        self.required_value = 0        self.required_count = 0        # 玩家信息        self.player_id = 0  # 默认玩家ID        self.current_player = 0  # 当前出牌玩家        self.landlord = -1  # 地主玩家ID        # 游戏状态        self.game_over = False        # Socket连接        self.s = None        self.connected = False        # 扑克牌映射        self.A = [&#x27;红桃&#x27;, &#x27;黑桃&#x27;, &#x27;方片&#x27;, &#x27;梅花&#x27;]        self.B = [&#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;10&#x27;, &#x27;J&#x27;, &#x27;Q&#x27;, &#x27;K&#x27;, &#x27;A&#x27;, &#x27;2&#x27;]        self.POKERS = []        n = 1        for i in self.A:            for j in self.B:                self.POKERS.append(((i + j + &#x27;(&#x27; + str(n) + &#x27;)&#x27;)))                n += 1        self.POKERS.append(&#x27;小王(53)&#x27;)        self.POKERS.append(&#x27;大王(54)&#x27;)        # 创建UI界面        self.create_widgets()        # 启动接收消息的线程        self.receive_thread = None    def map_card(self, Cno):        &quot;&quot;&quot;将牌编号映射为牌面&quot;&quot;&quot;        if Cno == 0:            return None        else:            return self.POKERS[Cno - 1]    def get_card_color(self, card_num):        &quot;&quot;&quot;获取牌的颜色&quot;&quot;&quot;        if card_num &gt;= 1 and card_num &lt;= 13:  # 红桃            return &quot;red&quot;        elif card_num &gt;= 14 and card_num &lt;= 26:  # 黑桃            return &quot;black&quot;        elif card_num &gt;= 27 and card_num &lt;= 39:  # 方片            return &quot;red&quot;        elif card_num &gt;= 40 and card_num &lt;= 52:  # 梅花            return &quot;black&quot;        else:  # 王            return &quot;gold&quot;    def get_card_display_info(self, card_num):        &quot;&quot;&quot;获取牌的显示信息（文本和颜色）&quot;&quot;&quot;        card_text = self.map_card(card_num)        card_color = self.get_card_color(card_num)        return card_text, card_color    def sort_cards_for_display(self, cards):        &quot;&quot;&quot;按牌面大小排序，相同大小的牌放在一起&quot;&quot;&quot;        if not cards:            return []        # 按照牌面值分组        card_groups = &#123;&#125;        for card in cards:            card_value = self.get_card_value(card)            if card_value not in card_groups:                card_groups[card_value] = []            card_groups[card_value].append(card)        # 对组进行排序（按牌值大小）        sorted_groups = sorted(card_groups.items(), key=lambda x: x[0])        # 合并排序后的牌        sorted_cards = []        for value, group in sorted_groups:            # 组内按花色排序            group.sort()            sorted_cards.extend(group)        return sorted_cards    def get_card_value(self, card_num):        &quot;&quot;&quot;获取牌的数值用于比较大小&quot;&quot;&quot;        if card_num == 53:  # 小王            return 16        elif card_num == 54:  # 大王            return 17        else:            return (card_num - 1) % 13 + 3  # 3到17的值，其中3最小，2最大（15）    def parse_cards_type(self, cards):        &quot;&quot;&quot;分析牌型&quot;&quot;&quot;        if not cards:            return None, 0, 0        sorted_cards = sorted(cards)        card_values = [self.get_card_value(card) for card in sorted_cards]        # 特殊牌型：王炸        if sorted_cards == [53, 54]:            return &#x27;DualKing&#x27;, 17, 2  # 王炸是最大的牌型        # 获取牌的点数分布        value_counts = &#123;&#125;        for value in card_values:            value_counts[value] = value_counts.get(value, 0) + 1        unique_values = sorted(value_counts.keys())        counts = sorted(value_counts.values(), reverse=True)        card_count = len(cards)        # 分析牌型        if card_count == 1:            # 单张            return &#x27;Single&#x27;, card_values[0], 1        elif card_count == 2:            if len(value_counts) == 1:                # 对子                return &#x27;Dual&#x27;, card_values[0], 2        elif card_count == 3:            if len(value_counts) == 1:                # 三张                return &#x27;Tri&#x27;, card_values[0], 3        elif card_count == 4:            if len(value_counts) == 1:                # 炸弹                return &#x27;Quad&#x27;, card_values[0], 4            elif len(value_counts) == 2 and 3 in counts:                # 三带一                tri_value = [v for v, c in value_counts.items() if c == 3][0]                return &#x27;3+1&#x27;, tri_value, 4        elif card_count == 5:            if len(value_counts) == 2 and 3 in counts:                # 三带二                tri_value = [v for v, c in value_counts.items() if c == 3][0]                return &#x27;3+2&#x27;, tri_value, 5            elif len(value_counts) == 5:                # 顺子（5张）                if unique_values[-1] - unique_values[0] == 4 and len(unique_values) == 5:                    return &#x27;Sequ&#x27;, unique_values[0], 5        elif card_count &gt;= 5 and len(value_counts) == card_count:            # 检查是否为顺子（所有牌点数连续，且无重复）            if unique_values[-1] - unique_values[0] == card_count - 1:                # 还需要检查不能包含2（除非是最后一张）                if 15 not in unique_values or unique_values[-1] == 15:                    return &#x27;Sequ&#x27;, unique_values[0], card_count        elif card_count % 2 == 0 and card_count &gt;= 6:            # 双顺子检查            if self._is_double_sequence(value_counts):                return &#x27;doubleSequ&#x27;, unique_values[0], card_count        elif card_count % 3 == 0 and card_count &gt;= 6:            # 三顺子检查            if self._is_triple_sequence(value_counts):                return &#x27;triSequ&#x27;, unique_values[0], card_count        # 其他牌型        return None, 0, 0    def _is_double_sequence(self, value_counts):        &quot;&quot;&quot;检查是否为双顺子&quot;&quot;&quot;        # 每个点数都必须出现2次，且点数连续        values = sorted(value_counts.keys())        counts = [value_counts[v] for v in values]        # 检查每个点数是否都出现2次        if not all(c == 2 for c in counts):            return False        # 检查点数是否连续（不能包含2）        if 15 in values:            return False        # 检查是否连续        for i in range(1, len(values)):            if values[i] - values[i - 1] != 1:                return False        return True    def _is_triple_sequence(self, value_counts):        &quot;&quot;&quot;检查是否为三顺子&quot;&quot;&quot;        # 每个点数都必须出现3次，且点数连续        values = sorted(value_counts.keys())        counts = [value_counts[v] for v in values]        # 检查每个点数是否都出现3次        if not all(c == 3 for c in counts):            return False        # 检查点数是否连续（不能包含2）        if 15 in values:            return False        # 检查是否连续        for i in range(1, len(values)):            if values[i] - values[i - 1] != 1:                return False        return True    def is_valid_play(self, selected_cards, required_type, required_value, required_count):        &quot;&quot;&quot;验证出牌是否符合规则&quot;&quot;&quot;        if not selected_cards:            return False, &quot;没有选择牌&quot;        # 分析当前出牌的牌型        card_type, card_value, card_count = self.parse_cards_type(selected_cards)        if card_type is None:            return False, &quot;无效的牌型&quot;        # 如果是跳过，直接返回True        if card_type == &#x27;Jump&#x27;:            return True, &quot;&quot;        # 如果是初始出牌（required_type为&#x27;init&#x27;），则不需要匹配牌型        if required_type == &#x27;init&#x27;:            return True, &quot;&quot;        # 检查牌数是否匹配        if required_count &gt; 0 and card_count != required_count and card_type not in [&#x27;Quad&#x27;, &#x27;DualKing&#x27;]:            return False, f&quot;牌数不匹配，需要&#123;required_count&#125;张&quot;        # 特殊牌型可以直接压制任何非特殊牌型        if card_type == &#x27;Quad&#x27;:  # 炸弹可以压制非炸弹            return True, &quot;&quot;        elif card_type == &#x27;DualKing&#x27;:  # 王炸是最大的            return True, &quot;&quot;        # 如果上家是特殊牌型，当前牌必须也是特殊牌型且能压制        if required_type == &#x27;Quad&#x27; and card_type != &#x27;Quad&#x27; and card_type != &#x27;DualKing&#x27;:            return False, &quot;只能用炸弹或王炸压制炸弹&quot;        elif required_type == &#x27;DualKing&#x27;:            return False, &quot;王炸无法被压制&quot;        # 检查牌型是否匹配        if card_type != required_type:            return False, f&quot;牌型不匹配，需要&#123;required_type&#125;&quot;        # 检查牌力是否足够大        if required_value &gt; 0 and card_value &lt;= required_value:            return False, f&quot;牌力不够大，需要大于&#123;required_value&#125;&quot;        return True, &quot;&quot;    def create_widgets(self):        &quot;&quot;&quot;创建GUI界面&quot;&quot;&quot;        # 顶部信息栏        self.info_frame = ttk.Frame(self.root)        self.info_frame.pack(fill=tk.X, padx=10, pady=5)        self.info_label = ttk.Label(self.info_frame, text=&quot;欢迎来到斗地主游戏！&quot;)        self.info_label.pack(side=tk.LEFT)        # 玩家信息标签        self.player_info_label = ttk.Label(self.info_frame, text=&quot;玩家ID: 0&quot;)        self.player_info_label.pack(side=tk.LEFT, padx=10)        # 当前玩家标签        self.current_player_label = ttk.Label(self.info_frame, text=&quot;当前玩家: 0&quot;)        self.current_player_label.pack(side=tk.LEFT, padx=10)        # 地主标识标签        self.landlord_label = ttk.Label(self.info_frame, text=&quot;地主: 未确定&quot;)        self.landlord_label.pack(side=tk.LEFT, padx=10)        # 连接按钮        self.connect_button = ttk.Button(self.info_frame, text=&quot;连接服务器&quot;, command=self.connect_to_server)        self.connect_button.pack(side=tk.RIGHT)        # 中间游戏区域        self.game_frame = ttk.Frame(self.root)        self.game_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)        # 手牌显示区域        self.hand_frame = ttk.LabelFrame(self.game_frame, text=&quot;我的手牌&quot;)        self.hand_frame.pack(fill=tk.BOTH, expand=True, pady=5)        # 手牌画布和滚动条        self.hand_canvas = tk.Canvas(self.hand_frame, height=150)        self.hand_scrollbar = ttk.Scrollbar(self.hand_frame, orient=&quot;horizontal&quot;, command=self.hand_canvas.xview)        self.hand_scrollable_frame = ttk.Frame(self.hand_canvas)        self.hand_scrollable_frame.bind(            &quot;&lt;Configure&gt;&quot;,            lambda e: self.hand_canvas.configure(                scrollregion=self.hand_canvas.bbox(&quot;all&quot;)            )        )        self.hand_canvas.create_window((0, 0), window=self.hand_scrollable_frame, anchor=&quot;nw&quot;)        self.hand_canvas.configure(xscrollcommand=self.hand_scrollbar.set)        self.hand_canvas.pack(side=&quot;top&quot;, fill=&quot;both&quot;, expand=True)        self.hand_scrollbar.pack(side=&quot;bottom&quot;, fill=&quot;x&quot;)        # 出牌信息区域        self.play_info_frame = ttk.Frame(self.game_frame)        self.play_info_frame.pack(fill=tk.X, pady=5)        self.current_type_label = ttk.Label(self.play_info_frame, text=&quot;当前牌型: 无&quot;)        self.current_type_label.pack(side=tk.LEFT)        self.current_cards_label = ttk.Label(self.play_info_frame, text=&quot;当前出牌: 无&quot;)        self.current_cards_label.pack(side=tk.RIGHT)        # 操作按钮区域        self.button_frame = ttk.Frame(self.root)        self.button_frame.pack(fill=tk.X, padx=10, pady=5)        self.play_button = ttk.Button(self.button_frame, text=&quot;出牌&quot;, command=self.play_cards, state=tk.DISABLED)        self.play_button.pack(side=tk.LEFT, padx=5)        self.pass_button = ttk.Button(self.button_frame, text=&quot;不出&quot;, command=self.pass_turn, state=tk.DISABLED)        self.pass_button.pack(side=tk.LEFT, padx=5)        self.show_hand_button = ttk.Button(self.button_frame, text=&quot;刷新手牌&quot;, command=self.show_hand)        self.show_hand_button.pack(side=tk.LEFT, padx=5)        # 消息显示区域        self.message_frame = ttk.LabelFrame(self.root, text=&quot;游戏消息&quot;)        self.message_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)        self.message_text = tk.Text(self.message_frame, height=8)        self.message_scrollbar = ttk.Scrollbar(self.message_frame, orient=&quot;vertical&quot;, command=self.message_text.yview)        self.message_text.configure(yscrollcommand=self.message_scrollbar.set)        self.message_text.pack(side=&quot;left&quot;, fill=&quot;both&quot;, expand=True)        self.message_scrollbar.pack(side=&quot;right&quot;, fill=&quot;y&quot;)        # 底部状态栏        self.status_frame = ttk.Frame(self.root)        self.status_frame.pack(fill=tk.X, padx=10, pady=5)        self.status_label = ttk.Label(self.status_frame, text=&quot;未连接&quot;)        self.status_label.pack()    def connect_to_server(self):        &quot;&quot;&quot;连接到游戏服务器&quot;&quot;&quot;        try:            if not self.connected:                self.s = socket.socket()                # host = &#x27;1.1.1.1&#x27;                host = socket.gethostname()                port = 12345                self.s.connect((host, port))                self.connected = True                self.connect_button.config(text=&quot;断开连接&quot;)                self.add_message(&quot;成功连接到服务器&quot;)                self.status_label.config(text=&quot;已连接&quot;)                # 启动接收消息线程                self.receive_thread = threading.Thread(target=self.receive_messages, daemon=True)                self.receive_thread.start()            else:                # 断开连接                self.connected = False                if self.s:                    self.s.close()                self.connect_button.config(text=&quot;连接服务器&quot;)                self.add_message(&quot;已断开服务器连接&quot;)                self.status_label.config(text=&quot;未连接&quot;)        except Exception as e:            messagebox.showerror(&quot;连接错误&quot;, f&quot;无法连接到服务器: &#123;str(e)&#125;&quot;)    def receive_messages(self):        &quot;&quot;&quot;接收服务器消息的线程函数&quot;&quot;&quot;        while self.connected:            try:                receive = self.s.recv(1024)                if len(receive.strip()) == 0:                    continue                else:                    self.root.after(0, self.json_parse, receive)            except Exception as e:                if self.connected:                    self.root.after(0, self.handle_receive_error, str(e))                break    def handle_receive_error(self, error):        &quot;&quot;&quot;处理接收消息错误&quot;&quot;&quot;        self.add_message(f&quot;接收消息错误: &#123;error&#125;&quot;)        self.connected = False        self.connect_button.config(text=&quot;连接服务器&quot;)        self.status_label.config(text=&quot;连接已断开&quot;)    def json_parse(self, js):        &quot;&quot;&quot;解析服务器消息&quot;&quot;&quot;        try:            recjs = eval(js)            if recjs[&#x27;Operation&#x27;] == &#x27;message&#x27;:                self.add_message(recjs[&#x27;message&#x27;])            elif recjs[&#x27;Operation&#x27;] == &#x27;init&#x27;:                self.CARD = recjs[&#x27;message&#x27;]                self.show_hand()                self.add_message(&quot;游戏开始，手牌已发放&quot;)            elif recjs[&#x27;Operation&#x27;] == &#x27;AskS&#x27;:                self.ask_king()            elif recjs[&#x27;Operation&#x27;] == &#x27;Add&#x27;:                self.Card_num = 20                EX_CARD = [0 for x in range(3)]                for i in range(0, 3):                    EX_CARD[i] = recjs[&#x27;message&#x27;][i]                    # 将底牌添加到手牌中                    self.CARD.append(recjs[&#x27;message&#x27;][i])                self.add_message(f&quot;你获得了底牌: &#123;&#x27;, &#x27;.join(filter(None, (list(map(self.map_card, EX_CARD)))))&#125;&quot;)                self.show_hand()                # 更新地主标识                self.landlord = self.player_id                self.landlord_label.config(text=f&quot;地主: &#123;self.landlord&#125;&quot;)                if self.landlord == self.player_id:                    self.info_label.config(text=&quot;你是地主！&quot;)            elif recjs[&#x27;Operation&#x27;] == &#x27;SetTurn&#x27;:                # 保存当前牌型要求                self.required_type = recjs.get(&#x27;type&#x27;, &#x27;init&#x27;)                self.required_value = recjs.get(&#x27;value&#x27;, 0)                self.required_count = recjs.get(&#x27;seq_num&#x27;, 0)                # 更新当前玩家信息                self.current_player = recjs.get(&#x27;player&#x27;, 0)  # 假设服务器会发送player字段                self.current_player_label.config(text=f&quot;当前玩家: &#123;self.current_player&#125;&quot;)                # 启用出牌按钮                self.play_button.config(state=tk.NORMAL)                self.pass_button.config(state=tk.NORMAL)                self.add_message(&quot;轮到你出牌了&quot;)                if self.required_type != &#x27;init&#x27;:                    self.current_type_label.config(                        text=f&quot;当前牌型: &#123;self.required_type&#125; (需要大于&#123;self.required_value&#125;)&quot;)                else:                    self.current_type_label.config(text=&quot;当前牌型: 无限制&quot;)            elif recjs[&#x27;Operation&#x27;] == &#x27;Announce&#x27;:                if recjs[&#x27;message&#x27;] == []:                    self.add_message(&#x27;上家选择跳过&#x27;)                else:                    played_cards = list(filter(None, (list(map(self.map_card, sorted(recjs[&#x27;message&#x27;]))))))                    self.add_message(f&quot;上家打出了: &#123;&#x27;, &#x27;.join(played_cards)&#125;&quot;)            elif recjs[&#x27;Operation&#x27;] == &#x27;GameOver&#x27;:                winner = recjs.get(&#x27;winner&#x27;, &#x27;未知&#x27;)                role = recjs.get(&#x27;role&#x27;, &#x27;未知&#x27;)                if winner == self.player_id:                    messagebox.showinfo(&quot;游戏结束&quot;, f&quot;恭喜你赢了！你的角色是&#123;role&#125;&quot;)                else:                    messagebox.showinfo(&quot;游戏结束&quot;, f&quot;游戏结束！获胜方是玩家&#123;winner&#125;，角色是&#123;role&#125;&quot;)                self.game_over = True                self.play_button.config(state=tk.DISABLED)                self.pass_button.config(state=tk.DISABLED)                self.add_message(f&quot;游戏结束！获胜方是玩家&#123;winner&#125;，角色是&#123;role&#125;&quot;)            else:                self.add_message(&#x27;未知消息类型&#x27;)        except Exception as e:            self.add_message(f&quot;消息解析错误: &#123;str(e)&#125;&quot;)    def show_hand(self):        &quot;&quot;&quot;显示手牌&quot;&quot;&quot;        # 清空当前手牌显示        for widget in self.hand_scrollable_frame.winfo_children():            widget.destroy()        # 显示手牌        self.selected_cards = []  # 清空选中状态        sorted_cards = self.sort_cards_for_display(self.CARD)        filtered_cards = list(filter(None, sorted_cards))  # 过滤掉0        for i, card_num in enumerate(filtered_cards):            card_text, card_color = self.get_card_display_info(card_num)            if card_text:                # 创建牌按钮                card_button = tk.Button(                    self.hand_scrollable_frame,                    text=card_text,                    width=12,                    height=4,                    fg=card_color,  # 设置文字颜色                    font=(&#x27;Arial&#x27;, 8),                    command=lambda idx=i, num=card_num: self.toggle_card_selection(idx, num, card_button)                )                card_button.pack(side=tk.LEFT, padx=2, pady=5)    def toggle_card_selection(self, idx, card_num, button):        &quot;&quot;&quot;切换牌的选中状态&quot;&quot;&quot;        if card_num in self.selected_cards:            self.selected_cards.remove(card_num)            button.config(relief=tk.RAISED, bg=&quot;lightgray&quot;)        else:            self.selected_cards.append(card_num)            button.config(relief=tk.SUNKEN, bg=&quot;yellow&quot;)        # 更新当前选中牌显示        selected_names = list(filter(None, (list(map(self.map_card, sorted(self.selected_cards))))))        self.current_cards_label.config(text=f&quot;选中的牌: &#123;&#x27;, &#x27;.join(selected_names) if selected_names else &#x27;无&#x27;&#125;&quot;)    def play_cards(self):        &quot;&quot;&quot;出牌&quot;&quot;&quot;        if not self.selected_cards:            messagebox.showwarning(&quot;出牌错误&quot;, &quot;请先选择要出的牌&quot;)            return        # 验证出牌是否符合规则        is_valid, message = self.is_valid_play(            self.selected_cards,            self.required_type,            self.required_value,            self.required_count        )        if not is_valid:            messagebox.showwarning(&quot;出牌错误&quot;, message)            return        # 分析当前出牌的牌型        card_type, card_value, card_count = self.parse_cards_type(self.selected_cards)        # 构造JSON消息        json_data = &#123;            &#x27;Status&#x27;: 200,            &#x27;Operation&#x27;: &#x27;AnsTurn&#x27;,            &#x27;type&#x27;: card_type,            &#x27;seq_num&#x27;: card_count,  # 对于顺子等牌型，这个表示牌的数量            &#x27;message&#x27;: self.selected_cards,            &#x27;value&#x27;: card_value        &#125;        try:            self.s.sendall(str.encode(str(json_data)))            # 从手牌中移除已出的牌            for card in self.selected_cards:                if card in self.CARD:                    self.CARD.remove(card)            self.Card_num -= len(self.selected_cards)            # 检查是否出完所有牌            if self.Card_num == 0:                self.game_over = True                self.add_message(&quot;恭喜你出完所有牌！&quot;)                # 禁用按钮                self.play_button.config(state=tk.DISABLED)                self.pass_button.config(state=tk.DISABLED)            self.selected_cards = []            self.show_hand()            self.current_cards_label.config(text=&quot;选中的牌: 无&quot;)            self.play_button.config(state=tk.DISABLED)            self.pass_button.config(state=tk.DISABLED)        except Exception as e:            messagebox.showerror(&quot;出牌错误&quot;, f&quot;出牌失败: &#123;str(e)&#125;&quot;)    def pass_turn(self):        &quot;&quot;&quot;跳过出牌&quot;&quot;&quot;        json_data = &#123;            &#x27;Status&#x27;: 200,            &#x27;Operation&#x27;: &#x27;AnsTurn&#x27;,            &#x27;type&#x27;: &#x27;Jump&#x27;,            &#x27;seq_num&#x27;: 0,            &#x27;message&#x27;: [],            &#x27;value&#x27;: 0        &#125;        try:            self.s.sendall(str.encode(str(json_data)))            self.selected_cards = []            self.current_cards_label.config(text=&quot;选中的牌: 无&quot;)            self.play_button.config(state=tk.DISABLED)            self.pass_button.config(state=tk.DISABLED)        except Exception as e:            messagebox.showerror(&quot;操作错误&quot;, f&quot;跳过出牌失败: &#123;str(e)&#125;&quot;)    def ask_king(self):        &quot;&quot;&quot;询问是否抢地主&quot;&quot;&quot;        result = messagebox.askyesno(&quot;抢地主&quot;, &quot;是否抢地主?&quot;)        json_data = &#123;            &#x27;Status&#x27;: 200,            &#x27;Operation&#x27;: &#x27;AnsS&#x27;,            &#x27;message&#x27;: 1 if result else 0        &#125;        try:            self.s.sendall(str.encode(str(json_data)))        except Exception as e:            messagebox.showerror(&quot;操作错误&quot;, f&quot;抢地主选择发送失败: &#123;str(e)&#125;&quot;)    def add_message(self, message):        &quot;&quot;&quot;添加消息到消息框&quot;&quot;&quot;        self.message_text.insert(tk.END, f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] &#123;message&#125;\\n&quot;)        self.message_text.see(tk.END)def main():    root = tk.Tk()    app = DouDiZhuGUI(root)    root.mainloop()if __name__ == &quot;__main__&quot;:    main()\n","categories":["python"]},{"title":"部署本地大模型","url":"/2025/05/12/%E9%83%A8%E7%BD%B2%E6%9C%AC%E5%9C%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/","content":"模型框架\n\n企业级服务，SGLang 是不二之选：凭借卓越的性能，其吞吐量和结构化输出能力堪称行业翘楚，为企业级应用筑牢根基。https://docs.sglang.ai/start/install.htmlhttps://github.com/sgl-project/sglang\n在线高并发场景，VLLM 独占鳌头：凭借动态批处理和先进的内存管理技术，确保服务在高并发压力下依然稳定高效，保障业务流畅运行。https://docs.vllm.com.cn/en/latest/getting_started/installation/gpu.htmlhttps://github.com/vllm-project/vllm\n个人开发领域，Ollama 崭露头角：简单易用，跨平台支持搭配丰富的模型库，让创意灵感瞬间触手可及，助力个人开发者快速实现想法。https://github.com/ollama/ollama?tab=readme-ov-file\n\n\nLLM webui\n\nDify：适合企业开发复杂 AI 应用，如智能客服、合同处理系统等，支持多模型协作和业务流程自动化。https://dify.ai/zhhttps://github.com/langgenius/dify/blob/main/README_CN.md\nOpen-WebUI：适合个人开发者快速测试本地模型（如 Ollama 部署的 Llama3），或作为 ChatGPT 替代品进行日常交互。https://docs.openwebui.com/\nChatbox：面向非技术用户，提供无需代码的对话界面，支持快速体验多模型（如 GPT、Claude）的聊天能力。https://chatboxai.app/zhhttps://github.com/chatboxai/chatbox\n\n\n部署\n由于vllm和sglang需要资源较多，我们这里采用ollama + openwebui + deepseek\n前提条件服务器已经配置了驱动和cuda nvidia-smi（驱动命令）nvcc（cuda命令）\nhttps://www.nvidia.cn/drivers/lookup/ 显卡下载run脚本运行\nhttps://developer.nvidia.com/cuda-toolkit-archive cuda下载\n\n安装ollama#https://github.com/ollama/ollama/tree/main/docs#OLLAMA_MODELS 模型下载位置默认/usr/share/ollama/.ollama/models#OLLAMA_HOST 监控地址默认127.0.0.1curl -fsSL https://ollama.com/install.sh | shsed -i &#x27;/^Environment=&quot;PATH=/a Environment=&quot;OLLAMA_HOST=0.0.0.0&quot;&#x27; /etc/systemd/system/ollama.servicesystemctl daemon-reloadsystemctl restart ollama.serviceollama run deepseek-r1\n安装docker和nvidia-container-toolkit#添加Docker软件包源#添加Docker软件包源sudo wget -O /etc/yum.repos.d/docker-ce.repo http://mirrors.cloud.aliyuncs.com/docker-ce/linux/centos/docker-ce.reposudo sed -i &#x27;s|https://mirrors.aliyun.com|http://mirrors.cloud.aliyuncs.com|g&#x27; /etc/yum.repos.d/docker-ce.repo#安装Docker社区版本，容器运行时containerd.io，以及Docker构建和Compose插件sudo yum -y install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin#启动Dockersudo systemctl start docker#设置Docker守护进程在系统启动时自动启动sudo systemctl enable docker#配置生产存储库curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \\  sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo#安装 NVIDIA Container Toolkit 软件包sudo yum install -y nvidia-container-toolkit#重启dockersudo systemctl restart docker\n安装webui#可以通过-e OLLAMA_BASE_URL 配置ollama地址,进入web界面也可以配置,镜像差不多9G,在国外需要配置加速源docker run -d -p 3000:8080 --gpus all -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:cuda\n\n额外\ndify功能比Open-WebUI更强大，支持agent和工作流和很多插件，如果不想只单独通过webui来交互建议使用difycurl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composegit clone https://github.com/langgenius/dify.gitcd difycd dockercp .env.example .envdocker compose up -d\n\n","tags":["llm"]}]