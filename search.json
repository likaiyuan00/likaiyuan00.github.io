[{"title":"alertmanager","url":"/2025/04/27/alertmanager/","content":"安装curl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composeversion: &#x27;3&#x27;services:  alertmanager:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/alertmanager:v0.28.1    ports:      - &quot;9093:9093&quot;      - &quot;9094:9094&quot;    volumes:      - ./config:/etc/alertmanager      - alertmanager_data:/alertmanager    command:      - &#x27;--config.file=/etc/alertmanager/alertmanager.yml&#x27;      - &#x27;--storage.path=/alertmanager&#x27;      - &#x27;--cluster.advertise-address=alertmanager:9094&#x27;    networks:      - monitoring-netvolumes:  alertmanager_data:networks:  monitoring-net:    driver: bridge\n配置文件解读global: # 即为全局设置,在Alertmanager配置文件中,只要全局设置配置了的选项,全部为公共设置,可以让其他设置继承,作为默认值,可以子参数中覆盖其设置。  resolve_timeout: 1m # 用于设置处理超时时间,也是生命警报状态为解决的时间,这个时间会直接影响到警报恢复的通知时间,需要自行结合实际生产场景来设置主机的恢复时间,默认是5分钟。  # 整合邮件  smtp_smarthost: &#x27;smtp.qq.com:465&#x27; # 邮箱smtp服务器  smtp_from: &#x27;1451578387@qq.com&#x27; # 发件用的邮箱地址  smtp_auth_username: &#x27;1451578387@qq.com&#x27; # 发件人账号  smtp_auth_password: &#x27;dkuuifhdskaduasdsb&#x27; # 发件人邮箱密码  smtp_require_tls: false # 不进行tls验证route: # 路由分组  group_by: [&#x27;alertname&#x27;] # 报警分组  group_wait: 10s # 组内等待时间,同一分组内收到第一个告警等待多久开始发送,目标是为了同组消息同时发送,不占用告警信息,默认30s。  group_interval: 10s # 当组内已经发送过一个告警,组内若有新增告警需要等待的时间,默认为5m,这条要确定组内信息是影响同一业务才能设置,若分组不合理,可能导致告警延迟,造成影响。  repeat_interval: 1h # 告警已经发送,且无新增告警,若重复告警需要间隔多久,默认4h,属于重复告警,时间间隔应根据告警的严重程度来设置。  receiver: &#x27;webhook&#x27; # 告警的接收者,需要和 receivers[n].name 的值一致。  # 上面所有的属性都由所有子路由继承,并且可以在每个子路由上进行覆盖。  # 当报警信息中标签匹配到team:node时会使用email发送报警,否则使用webhook。 templates:- &#x27;/etc/alertmanager/config/*.tmpl&#x27;# route根路由,该模块用于该根路由下的节点及子路由routes的定义,子树节点如果不对相关配置进行配置,则默认会从父路由树继承该配置选项。每一条告警都要进入route,即要求配置选项group_by的值能够匹配到每一条告警的至少一个labelkey(即通过POST请求向altermanager服务接口所发送告警的labels项所携带的&lt;labelname&gt;),告警进入到route后,将会根据子路由routes节点中的配置项match_re或者match来确定能进入该子路由节点的告警(由在match_re或者match下配置的labelkey:labelvalue是否为告警labels的子集决定,是的话则会进入该子路由节点,否则不能接收进入该子路由节点)。route:  # 例如所有labelkey:labelvalue含cluster=A及altertname=LatencyHigh的labelkey的告警都会被归入单一组中  group_by: [&#x27;job&#x27;, &#x27;altername&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;,&#x27;severity&#x27;]  # 若一组新的告警产生,则会等group_wait后再发送通知,该功能主要用于当告警在很短时间内接连产生时,在group_wait内合并为单一的告警后再发送  group_wait: 30s  # 再次告警时间间隔  group_interval: 5m  # 如果一条告警通知已成功发送,且在间隔repeat_interval后,该告警仍然未被设置为resolved,则会再次发送该告警通知  repeat_interval: 12h  # 默认告警通知接收者,凡未被匹配进入各子路由节点的告警均被发送到此接收者  receiver: &#x27;wechat&#x27;  # 上述route的配置会被传递给子路由节点,子路由节点进行重新配置才会被覆盖  # 子路由树  routes:  # 该配置选项使用正则表达式来匹配告警的labels,以确定能否进入该子路由树  # match_re和match均用于匹配labelkey为service,labelvalue分别为指定值的告警,被匹配到的告警会将通知发送到对应的receiver  - match_re:      service: ^(foo1|foo2|baz)$    receiver: &#x27;wechat&#x27;    # 在带有service标签的告警同时有severity标签时,他可以有自己的子路由,同时具有severity != critical的告警则被发送给接收者team-ops-mails,对severity == critical的告警则被发送到对应的接收者即team-ops-pager    routes:    - match:        severity: critical      receiver: &#x27;wechat&#x27;  # 比如关于数据库服务的告警,如果子路由没有匹配到相应的owner标签,则都默认由team-DB-pager接收  - match:      service: database    receiver: &#x27;wechat&#x27;  # 我们也可以先根据标签service:database将数据库服务告警过滤出来,然后进一步将所有同时带labelkey为database  - match:      severity: critical    receiver: &#x27;wechat&#x27;# 抑制规则,当出现critical(关键的)告警时忽略warning。# 下面的这段配置是指如果出现标签为severity=critical的告警,则抑制severity=warning的告警inhibit_rules:- source_match:    severity: &#x27;critical&#x27;  target_match:    severity: &#x27;warning&#x27;  # 如果警报名称相同,则应用抑制。  # alertname、cluster和service对应的标签值需要相等  equal: [&#x27;alertname&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;]# 收件人配置receivers:- name: &#x27;team-ops-mails&#x27;  email_configs:  - to: &#x27;dukuan@xxx.com&#x27;- name: &#x27;team-X-pager&#x27;  email_configs:  - to: &#x27;team-X+alerts-critical@example.org&#x27;  pagerduty_configs:  - service_key: &lt;team-X-key&gt;- name: &#x27;team-Y-mails&#x27;  email_configs:  - to: &#x27;team-Y+alerts@example.org&#x27;- name: &#x27;webhook&#x27;  webhook_configs:  - url: http://127.0.0.1:8060/dingtalk/webhook1/send    send_resolved: true\n分组和路由\n\n路由match（精确匹配）match_re（正则表达式匹配）每一个告警都会从配置文件中顶级的route进入路由树，需要注意的是顶级的route必须匹配所有告警(即不能有任何的匹配设置match和match_re)，每一个路由都可以定义自己的接受人以及匹配规则。默认情况下，告警进入到顶级route后会遍历所有的子节点，直到找到最深的匹配route，并将告警发送到该route定义的receiver中。但如果route中设置continue的值为false，那么告警在匹配到第一个子节点之后就直接停止。如果continue为true，报警则会继续进行后续子节点的匹配。如果当前告警匹配不到任何的子节点，那该告警将会基于当前路由节点的接收器配置方式进行处理\n分组告警通知进行分组，将多条告警合合并为一个通知。这里我们可以使用group_by来定义分组规则。基于告警中包含的标签，如果满足group_by中定义标签名称，那么这些告警将会合并为一个通知发送给接收器。有的时候为了能够一次性收集和发送更多的相关信息时，可以通过group_wait参数设置等待时间，如果在等待时间内当前group接收到了新的告警，这些告警将会合并为一个通知向receiver发送\n\n\nroute:  group_by: [&#x27;alertname&#x27;,&#x27;team&#x27;]   #在这里添加team匹配的标签  group_wait: 5s  group_interval: 5s  repeat_interval: 5m  # 默认发给&quot;sre_system&quot;组用户  receiver: &#x27;sre_system&#x27;  continue: false  # 配置子路由  routes:    - receiver: &#x27;sre_dba&#x27;      match_re:        job: test      # 建议将continue的值设置为true，表示当前的条件是否匹配，都将继续向下匹配规则      # 这样做的目的是将消息发给最后的系统组(sre_system)      continue: true==================================================================#rule.yml- name: grafana  rules:  - alert: node           #这个相当于alertname的值,与之前匹配的相同    expr: up&#123;job=&quot;grafana&quot;&#125; == 0    for: 10s                      labels:                         severity: 1       job: test  # 对应上面的 match_re      team: grafana        #这里标签设置不同的一会用    annotations:                    summary: &quot;&#123;&#123; \\$labels.instance &#125;&#125; 已停止运行超过 15s&quot;      description: hello world alertname 等于 node 如果相同报警会一起发送team 等于 grafana \n抑制规则inhibit_rules:  - source_match:      severity: &#x27;告警&#x27;    target_match:      severity: &#x27;提示&#x27;    #equal: [&#x27;type&#x27;,&#x27;test&#x27;] 要求 type 和 test签均相同     equal: [&#x27;type&#x27;]type的值必须一样当匹配到 告警 时就会抑制提示的告警通知并检查他们是否来自于同个ssl（即ssl标签的值相同抑制才会生效）当子路由匹配到不同的 severity 时就会将消息发往不同的 receiver，当子路由无法匹配到时，消息会默认发往根路由的 receiver，因此，无论是否匹配到子路由规则，消息都会发往根路由的 receiver对应报警规则配置为groups:- name: node-alerts  rules:  - alert: HighNodeCPU    expr: (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) * 100 &gt; 80    for: 5m    labels:      severity: &quot;告警&quot;      type: ssl    annotations:      summary: &quot;高节点CPU使用率 (&#123;&#123; $labels.instance &#125;&#125;)&quot;      description: &quot;节点 &#123;&#123; $labels.instance &#125;&#125; CPU 使用率超过 80% 已持续 5 分钟&quot;- name: cluster-alerts  rules:  - alert: ClusterWideCPUProblem    expr: |      sum( (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) * 100 &gt; 80 )      /      count( (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) )      * 100 &gt; 50    for: 10m    labels:      severity: &quot;提示&quot;      type: ssl    annotations:      summary: &quot;集群级CPU问题&quot;      description: &quot;超过 50% 的节点持续高CPU使用率达 10 分钟&quot;\n\nalertmanager集成三方告警\n原生alertmanager只有邮件和webhook告警；Alertmanager 的原生 Webhook 告警是一种通过 HTTP POST 请求将告警信息发送到自定义接口（Webhook 接收端）的机制；所以要对接需要开发者自行开发，这里推荐两个现成的工具来对接\n\nPrometheusAlert使用\nPrometheus Alert 是开源的运维告警中心消息转发系统，支持主流的监控系统 Prometheus，日志系统 Graylog 和数据可视化系统 Grafana 发出的预警消息。通知渠道支持钉钉、微信、华为云短信、腾讯云短信、腾讯云电话、阿里云短信、阿里云电话等等\n\nwget https://github.com/feiyu563/PrometheusAlert/releases/download/v4.8.1/linux.zipchmod +x PrometheusAlert启动 nohup ./PrometheusAlert &amp; 后台运行#alertmanager.yml配置集成PrometheusAlert；格式可以登录PrometheusAlert查看receivers:- name: &#x27;web.hook.prometheusalert&#x27;  webhook_configs:  - url: &#x27;http://192.168.197.142:8080/prometheusalert?type=wx&amp;tpl=prometheus-wx&amp;wxurl=https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=53fdb356-4446-42e5-b8bd-f7da63bcfe76&#x27;\n\nprometheus-webhook-dingtalk使用\nPrometheus 的Alertmanager自身不支持钉钉报警，需要通过插件的方式来达到报警条件\n\n安装wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v2.1.0/prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gztar zxf prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gz mv prometheus-webhook-dingtalk-2.1.0.linux-amd64 /usr/local/prometheus-webhook-dingtalkcat &gt; /usr/lib/systemd/system/webhook-dingtalk.service &lt;&lt; EOF[Unit]Description=prometheus-webhook-dingtalkDocumentation=https://github.com/timonwong/prometheus-webhook-dingtalkAfter=network.target[Service]User=rootGroup=rootExecStart=/usr/local/prometheus-webhook-dingtalk/prometheus-webhook-dingtalk  --config.file=/usr/local/prometheus-webhook-dingtalk/config.ymlExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failure[Install]WantedBy=multi-user.targetEOF#集成模版/usr/local/prometheus-webhook-dingtalk/config.ymltemplates:    - /usr/local/prometheus/webhook-dingtalk/template.tmpltargets:  webhook1:    url: https://oapi.dingtalk.com/robot/send?access_token=9ac4354ab7c8#alertmanager配置发送给dingtalk插件receivers:  - name: &#x27;email&#x27;    email_configs:      - to: &#x27;xxxxx@163.com&#x27; #指定发送给谁  - name: &#x27;webhook1&#x27;    webhook_configs:      - send_resolved: false        url: http://localhost:8060/dingtalk/webhook1/send\n\n报警内容模版vim /usr/local/prometheus/webhook-dingtalk/template.tmpl&#123;&#123; define &quot;__subject&quot; &#125;&#125;[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;]&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;__alert_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;---&#123;&#123; if .Labels.owner &#125;&#125;@&#123;&#123; .Labels.owner &#125;&#125;&#123;&#123; end &#125;&#125; **告警主题**: &#123;&#123; .Annotations.summary &#125;&#125;**告警类型**: &#123;&#123; .Labels.alertname &#125;&#125; **告警级别**: &#123;&#123; .Labels.severity &#125;&#125;  **告警主机**: &#123;&#123; .Labels.instance &#125;&#125;  **告警信息**: &#123;&#123; index .Annotations &quot;description&quot; &#125;&#125; **告警时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; &#123;&#123; define &quot;__resolved_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;---&#123;&#123; if .Labels.owner &#125;&#125;@&#123;&#123; .Labels.owner &#125;&#125;&#123;&#123; end &#125;&#125;**告警主题**: &#123;&#123; .Annotations.summary &#125;&#125;**告警类型**: &#123;&#123; .Labels.alertname &#125;&#125;  **告警级别**: &#123;&#123; .Labels.severity &#125;&#125; **告警主机**: &#123;&#123; .Labels.instance &#125;&#125; **告警信息**: &#123;&#123; index .Annotations &quot;description&quot; &#125;&#125; **告警时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125; **恢复时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.EndsAt) &quot;Asia/Shanghai&quot; &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;default.title&quot; &#125;&#125;&#123;&#123; template &quot;__subject&quot; . &#125;&#125;&#123;&#123; end &#125;&#125; &#123;&#123; define &quot;default.content&quot; &#125;&#125;&#123;&#123; if gt (len .Alerts.Firing) 0 &#125;&#125;**====侦测到&#123;&#123; .Alerts.Firing | len  &#125;&#125;个故障====**&#123;&#123; template &quot;__alert_list&quot; .Alerts.Firing &#125;&#125;---&#123;&#123; end &#125;&#125; &#123;&#123; if gt (len .Alerts.Resolved) 0 &#125;&#125;**====恢复&#123;&#123; .Alerts.Resolved | len  &#125;&#125;个故障====**&#123;&#123; template &quot;__resolved_list&quot; .Alerts.Resolved &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;ding.link.title&quot; &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; define &quot;ding.link.content&quot; &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;\n报警规则示例mkdir /usr/local/prometheus/prometheus/rulevim /usr/local/prometheus/prometheus/rule/node_exporter.ymlgroups:- name: 服务器资源监控  rules:  - alert: 内存使用率过高    expr: 100 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 &gt; 80    for: 3m     labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123; $labels.instance &#125;&#125; 内存使用率过高, 请尽快处理！&quot;      description: &quot;&#123;&#123; $labels.instance &#125;&#125;内存使用率超过80%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;            - alert: 服务器宕机    expr: up == 0    for: 1s    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 服务器宕机, 请尽快处理!&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 服务器延时超过3分钟,当前状态&#123;&#123; $value &#125;&#125;. &quot;   - alert: CPU高负荷    expr: 100 - (avg by (instance,job)(irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) * 100) &gt; 90    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; CPU使用率过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; CPU使用大于90%,当前使用率&#123;&#123; $value &#125;&#125;%. &quot;        - alert: 磁盘IO性能    expr: avg(irate(node_disk_io_time_seconds_total[1m])) by(instance,job)* 100 &gt; 90    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入磁盘IO使用率过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入磁盘IO大于90%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;    - alert: 网络流入    expr: ((sum(rate (node_network_receive_bytes_total&#123;device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*&#x27;&#125;[5m])) by (instance,job)) / 100) &gt; 102400    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入网络带宽过高，请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入网络带宽持续5分钟高于100M. RX带宽使用量&#123;&#123;$value&#125;&#125;.&quot;   - alert: 网络流出    expr: ((sum(rate (node_network_transmit_bytes_total&#123;device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*&#x27;&#125;[5m])) by (instance,job)) / 100) &gt; 102400    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流出网络带宽过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流出网络带宽持续5分钟高于100M. RX带宽使用量&#123;$value&#125;&#125;.&quot;    - alert: TCP连接数    expr: node_netstat_Tcp_CurrEstab &gt; 10000    for: 2m    labels:      severity: 严重告警    annotations:      summary: &quot; TCP_ESTABLISHED过高！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; TCP_ESTABLISHED大于100%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;   - alert: 磁盘容量    expr: 100-(node_filesystem_free_bytes&#123;fstype=~&quot;ext4|xfs&quot;&#125;/node_filesystem_size_bytes &#123;fstype=~&quot;ext4|xfs&quot;&#125;*100) &gt; 90    for: 1m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.mountpoint&#125;&#125; 磁盘分区使用率过高，请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 磁盘分区使用大于90%，当前使用率&#123;&#123; $value &#125;&#125;%.&quot;\n","categories":["prometheus"]},{"title":"elfk部署使用","url":"/2025/04/18/elfk/","content":"\nfilebeat不建议容器启动，适合放到每个节点采集日志统一发给logstash；如果全部输出到elasticsearch会导致负载比较高；不建议每个节点用logstash采集因为比较重，filebeat比较轻量级\n\n安装elfkcurl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composeyum install -y https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpmcat &gt;&gt; ./elk.yml &lt;&lt; EOFversion: &#x27;3.8&#x27;services:  elasticsearch:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/elasticsearch:7.14.0    container_name: elasticsearch    environment:      - discovery.type=single-node  # 单节点模式      - ES_JAVA_OPTS=-Xms512m -Xmx512m  # JVM 堆内存限制      - ELASTIC_PASSWORD=Ytest@123  # 设置 Elasticsearch 密码    volumes:      - ./elasticsearch/data:/usr/share/elasticsearch/data  # 数据持久化#      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml  # 自定义配置（可选）    ports:      - &quot;9200:9200&quot;  # REST API      - &quot;9300:9300&quot;  # 集群通信    networks:      - elk  logstash:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/logstash:7.14.0    container_name: logstash    volumes:      - ./logstash/config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf  # 自定义 Logstash 管道配置      - ./logstash/logs:/usr/share/logstash/logs  # 日志持久化    environment:      - LS_JAVA_OPTS=-Xms512m -Xmx512m  # JVM 堆内存限制    ports:      - &quot;5044:5044&quot;  # Beats 输入端口（如 Filebeat）      - &quot;5000:5000/tcp&quot;  # TCP 输入      - &quot;5000:5000/udp&quot;  # UDP 输入    depends_on:      - elasticsearch    networks:      - elk  kibana:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/kibana:7.14.0    container_name: kibana    environment:      - I18N_LOCALE=zh-CN      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200  # 指向 Elasticsearch 服务      - ELASTICSEARCH_USERNAME=elastic  # 默认用户名      - ELASTICSEARCH_PASSWORD=Ytest@123  # 与 Elasticsearch 密码一致    ports:      - &quot;5601:5601&quot;  # Kibana Web 界面    depends_on:      - elasticsearch    networks:      - elknetworks:  elk:    driver: bridgeEOFmkdir ./logstash/config -pcat &gt;&gt; ./logstash/config/logstash.conf &lt;&lt; EOF# ./logstash/config/logstash.confinput &#123;  tcp &#123;    port =&gt; 5000  # 监听 TCP 日志  &#125;  beats &#123;    port =&gt; 5044  # 接收 Filebeat 输入  &#125;&#125;filter &#123;  grok &#123;    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;  # 解析 Apache 日志  &#125;  date &#123;    match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]  # 时间解析  &#125;&#125;output &#123;  elasticsearch &#123;    hosts =&gt; [&quot;elasticsearch:9200&quot;]    user =&gt; &quot;elastic&quot;    password =&gt; &quot;Ytest@123&quot;    index =&gt; &quot;logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引  &#125;&#125;EOFchmod 777 elasticsearch/data\nfilebeat根据不同tag写入不同的logstash后续分割和输出建立索引好区分\nfilebeat.inputs: # filebeat input输入- type: log    # 标准输入  enabled: true  # 启用标准输入  paths:    - /var/log/*  tags: [&quot;system&quot;]  #  fields:  #    type: &quot;system_log&quot;- type: filestream  paths:    - &quot;/var/log/nginx/*.log&quot;  tags: [&quot;nginx&quot;]   # 标记为 nginx 日志#output.console:# enabled: true               # 启用控制台输出  #  pretty: true                # 美化 JSON 格式  # codec.json:  #   pretty: true  # escape_html: false        # 不转义 HTML 符号（保持原始格式） # 输出到 Logstash - 用于生产数据处理output.logstash:  enabled: true               # 启用 Logstash 输出  #  when:  #    equals:  #      fields.type: &quot;system_log&quot;  hosts: [&quot;127.0.0.1:5044&quot;]  # Logstash 的地址和端口（支持多个主机负载均衡）  when.contains:      tags: &quot;system&quot;  # 匹配 tags 包含 &quot;system&quot;  hosts: [&quot;127.0.0.1:5045&quot;]  enabled: true  when.contains:    tags: &quot;nginx&quot;  # 匹配 tags 包含 &quot;nginx&quot;\nlogstash根据不同type进行过滤和输出索引\nLogstash Reference [7.10] | Elasticinput &#123;  tcp &#123;    port =&gt; 5000  # 监听 TCP 日志  &#125;  beats &#123;    port =&gt; 5044  # 接收 Filebeat 输入    type =&gt; &quot;system&quot;  &#125;  beats &#123;    port =&gt; 5045  # 接收 Filebeat 输入    type =&gt; &quot;nginx&quot;  &#125;&#125;   filter &#123;  date &#123;    match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]  # 时间解析  &#125;   if[type] == &quot;nginx&quot; &#123;    grok &#123;      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;HTTPD_COMMONLOG&#125;&quot; &#125;  # 解析 nginx 日志,如果不区分；system类型是解析不了的，会直接报错      remove_field =&gt; [&quot;@version&quot;]     &#125;  &#125;  #对于system类型可以再写个if来单独过滤  if[type] == &quot;system&quot; &#123;    grok &#123;      match =&gt;  &#123;&quot;message&quot; =&gt; &quot;%&#123;IPV4:ip&#125;&quot;&#125;        remove_field =&gt; [&quot;@version&quot;]     &#125;    mutate &#123;  #这里过滤器乱写的，需要根据自身的业务配置        remove_field =&gt; [&quot;timestamp&quot;]        gsub =&gt; [&quot;message&quot;,&quot;\\s&quot;,&quot;| &quot;]        split =&gt; [&quot;message&quot;,&quot;|&quot;]        replace =&gt; &#123; &quot;timenew&quot; =&gt;  &quot;%&#123;+yyyy-MM-dd&#125;&quot; &#125;        add_field =&gt; &#123;         &quot;year&quot; =&gt; &quot;%&#123;+yyyy&#125;&quot;         &quot;month&quot; =&gt; &quot;%&#123;+MM&#125;&quot;         &quot;day&quot; =&gt; &quot;%&#123;+dd&#125;&quot;         &quot;status&quot; =&gt; &quot;%&#123;[message][1]&#125;&quot;         &quot;code&quot; =&gt; &quot;%&#123;[message][2]&#125;&quot;        &#125;    &#125;  &#125;   &#125;#必须通过type指定不同输出创建不同的index =&gt;,否则index的字段不一样，当第一个index结构确定后，第二个输入无法输出到第一个index，因为字段不一样output &#123;  if &quot;system&quot; in [tags] &#123;    elasticsearch &#123;      hosts =&gt; [&quot;elasticsearch:9200&quot;]      user =&gt; &quot;elastic&quot;      password =&gt; &quot;Ytest@123&quot;      index =&gt; &quot;filebeat-system-logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引    &#125;  &#125;    if &quot;nginx&quot; in [tags] &#123;    elasticsearch &#123;      hosts =&gt; [&quot;elasticsearch:9200&quot;]      user =&gt; &quot;elastic&quot;      password =&gt; &quot;Ytest@123&quot;      index =&gt; &quot;filebeat-nginx-logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引    &#125;  &#125;  &#125;\nelasticsearch\n常用语法\n\n&#x2F;_cat &#x2F;_cat&#x2F;master?help&#x2F;_cat&#x2F;indices?v  显示title&#x2F;_cat&#x2F;indiceslogs-2025.03.24 为索引名称&#x2F;logs-2025.03.24&#x2F;_search 查看文档&#x2F;logs-2025.03.24&#x2F; 查看索引结构&#x2F;logs-2025.03.24&#x2F;_doc&#x2F;_search?q&#x3D;message:test\n\n\n","categories":["中间件"]},{"title":"ftp","url":"/2025/07/25/ftp/","content":"主动模式PORT中文称为主动模式，工作的原理： FTP客户端连接到FTP服务器的21端口，发送用户名和密码登录，登录成功后要list列表或者读取数据时，客户端随机开放一个端口（1024以上），发送 PORT命令到FTP服务器，告诉服务器客户端采用主动模式并开放端口；FTP服务器收到PORT主动模式命令和端口号后，通过服务器的20端口和客户端开放的端口连接，发送数据，原理如下图\n被动模式PASV是Passive的缩写，中文成为被动模式，工作原理：FTP客户端连接到FTP服务器的21端口，发送用户名和密码登录，登录成功后要list列表或者读取数据时，发送PASV命令到FTP服务器， 服务器在本地随机开放一个端口（1024以上），然后把开放的端口告诉客户端， 客户端再连接到服务器开放的端口进行数据传输，原理如下图\n从上面的运行原来看到，主动模式和被动模式的不同简单概述为： 主动模式传送数据时是“服务器”连接到“客户端”的端口；被动模式传送数据是“客户端”连接到“服务器”的端口。主动模式需要客户端必须开放端口给服务器，很多客户端都是在防火墙内，开放端口给FTP服务器访问比较困难。被动模式只需要服务器端开放端口给客户端连接就行了,所以推荐被动模式，主动模式可能会被客户端拦截\n","categories":["linux"]},{"title":"iptables防止ddos(cc)","url":"/2025/04/21/iptables%E9%98%B2%E6%AD%A2ddos-cc/","content":"\n基本上发行版都是自带的，轻量级，不需要额外下载Fail2Ban也可以但是需要额外下载\n\n如何配置使用iptables -I INPUT -p tcp --dport 80 -m state --state NEW -m recent --set参数    作用-I INPUT    将规则插入到 INPUT 链的最前面-p tcp --dport 80    匹配目标端口为 80 的 TCP 流量-m state --state NEW    仅匹配 新建连接（如 TCP 的 SYN 包）-m recent --set    将来源 IP 记录到 recent 模块的默认列表（/proc/net/xt_recent/DEFAULT）iptables -I INPUT -p tcp --dport 80 -m state --state NEW -m recent --update --seconds 60 --hitcount 100 -j DROP参数    作用-m recent --update --seconds 60 --hitcount 100    检查 IP 在 60 秒内是否发起超过 100 次新连接-j DROP    若超限，直接丢弃数据包\n\n效果图，到指定次数自动丢弃数据包，端口不通，到达指定时间自动恢复\n经过测试 –hitcount 大于20 会报错\n解决办法echo options xt_recent ip_pkt_list_tot=200 &gt; /etc/modprobe.d/xt.confmodprobe -r xt_recent &amp;&amp; modprobe xt_recent 重新加载查看 lsmod |grep xt  ；cat /sys/module/xt_recent/parameters/ip_pkt_list_tot 对应 xt.conf\n额外补充若其他规则也使用 recent 默认列表，可能导致误判，可以通过–name 指定名称分类\niptables -I INPUT -p tcp –dport 80 -m state –state NEW -m recent –set –name HTTP_CC\niptables -I INPUT -p tcp –dport 80 -m state –state NEW -m recent –update –seconds 60 –hitcount 200 –name HTTP_CC -j DROP\n则 &#x2F;proc&#x2F;net&#x2F;xt_recent&#x2F;HTTP_CC 叫 HTTP_CC\n","categories":["linux"]},{"title":"kubeclt-neat","url":"/2025/07/24/kubeclt-neat/","content":"kubeclt-neat使用\n如果部署的yaml丢失，可以使用kubeclt-neat精简后直接使用导入新的环境，默认的文件有多余的信息是不能直接使用的yum -y install bash-completionsource /usr/share/bash-completion/bash_completionsource &lt;(kubectl completion bash)echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrcwget https://github.com/itaysk/kubectl-neat/releases/download/v2.0.3/kubectl-neat_linux_amd64.tar.gztar -zxvf kubectl-neat_linux_amd64.tar.gzmv kubectl-neat /usr/local/bin/kubectl get deploy my-deployment -o yaml | kubectl neat &gt; current-config.yamlkubectl apply -f current-config.yamldiff current-config.yaml new-config.yaml\n\n","categories":["k8s"]},{"title":"miniconda3","url":"/2025/04/21/miniconda3/","content":"\nconda是一个包和环境管理工具，用于创建、管理和切换Python的虚拟环境\n\n安装mkdir -p ~/miniconda3wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.shbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3rm ~/miniconda3/miniconda.shsource ~/miniconda3/bin/activate\n使用1. conda --version #查看conda版本，验证是否安装2. conda update conda #更新至最新版本，也会更新其它相关包3. conda update --all #更新所有包4. conda update package_name #更新指定的包5. conda create -n env_name package_name #创建名为env_name的新环境，并在该环境下安装名为package_name 的包，可以指定新环境的版本号，例如：conda create -n python2 python=python2.7 numpy pandas，创建了python2环境，python版本为2.7，同时还安装了numpy pandas包6. source activate env_name #切换至env_name环境7. source deactivate #退出环境8. conda info -e #显示所有已经创建的环境9. conda create --name new_env_name --clone old_env_name #复制old_env_name为new_env_name10. conda remove --name env_name –all #删除环境11. conda list #查看所有已经安装的包12. conda install package_name #在当前环境中安装包13. conda install --name env_name package_name #在指定环境中安装包14. conda remove -- name env_name package #删除指定环境中的包15. conda remove package #删除当前环境中的包16. conda env remove -n env_name #采用第10条的方法删除环境失败时，可采用这种方法\n\n\n\n两个环境，一个有request一个没有，隔离作用\n镜像源# 查看镜像源conda config --show-sources# 添加镜像源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main# 从镜像源中安装包时显示来源conda config --set show_channel_urls yes# 删除镜像源conda config --remove channels https://XXX# 删除配置的镜像源，使用默认镜像源conda config --remove-key channels\n\n打包运行环境pip install conda-packconda pack -n my_env_name -o out_name.tar.gztar -zxvf 2.7.tar.gz -C 2.7conda info -esource activate my_env_name\n\n","categories":["python"]},{"title":"nginx_todo","url":"/2025/07/21/nginx-todo/","content":"proxy_pass转发策略请求url和转发一致后端服务实际处理路径为 /api/upload，与客户端请求路径一致。Nginx配置：location /api/ &#123;         # 匹配客户端请求中的 /api/ 前缀    proxy_pass http://backend;  # 不改变路径，直接转发 /api/xxx 到后端&#125;转发效果：客户端请求 → /api/uploadNginx转发 → http://backend/api/upload\n\n后端服务需要基础路径（去掉&#x2F;api&#x2F;前缀）后端路由示例：后端服务处理根路径 /upload，不需要 /api/ 前缀。Nginx配置：nginxlocation /api/ &#123;    # 通过 rewrite 移除 /api/ 前缀    rewrite ^/api/(.*) /$1 break;      proxy_pass http://backend;  &#125;或location /api/ &#123;    # 直接在 proxy_pass 中追加路径    proxy_pass http://backend/;  # 注意结尾的斜杠&#125;● 转发效果：客户端请求 → /api/uploadNginx转发 → http://backend/upload\n\n转发加url注意点curl http://127.0.0.1/api/client-testlocation /api/ &#123;    proxy_pass http://backend/test/;  # 结尾必须加斜杠&#125;127.0.0.1- - [21/Jul/2025:14:32:45 +0800] &quot;GET /test/client-test HTTP/1.0&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://-127.0.0.1- - [21/Jul/2025:14:32:45 +0800] &quot;GET /api/client-test HTTP/1.1&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://127.0.0.1客户端请求 /api/client-test → 后端路径 /test/client-testcurl http://127.0.0.1/api-test/client-testlocation /api-test/ &#123;    proxy_pass http://backend/test;  # 无斜杠 → 路径合并&#125;127.0.0.1- - [21/Jul/2025:14:32:28 +0800] &quot;GET /testclient-test HTTP/1.0&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://-127.0.0.1- - [21/Jul/2025:14:32:28 +0800] &quot;GET /api-test/client-test HTTP/1.1&quot; 404 178 &quot;-&quot; &quot;curl/7.58.0&quot; &quot;-&quot;Proxy: http://127.0.0.1客户端请求: http://example.com/api-test/client-test实际转发路径: http://backend/testclient-test\n\n日志记录常用内置变量$http_ 变量可以自定义比如$http_lky 请求头里面有lky:value则$http_lky等于value$args ： #这个变量等于请求行中的参数，同$query_string$content_length ： # 请求头中的Content-length字段。$content_type ： # 请求头中的Content-Type字段。$document_root ： # 当前请求在root指令中指定的值。$host ： # 请求主机头字段，否则为服务器名称。$http_user_agent ：#  客户端agent信息$http_cookie ： # 客户端cookie信息$limit_rate ： # 这个变量可以限制连接速率。$status  # 请求状态$body_bytes_sent # 发送字节$request_method ： # 客户端请求的动作，通常为GET或POST。$remote_addr ： # 客户端的IP地址。$remote_port ： # 客户端的端口。$remote_user ： # 已经经过Auth Basic Module验证的用户名。$request_filename ： # 当前请求的文件路径，由root或alias指令与URI请求生成。$scheme ： # HTTP方法（如http，https）。$server_protocol ： # 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。$server_addr ： # 服务器地址，在完成一次系统调用后可以确定这个值。$server_name ： # 服务器名称。$server_port ： # 请求到达服务器的端口号。$request_uri ： # 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。$uri ： # 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。$document_uri ： # 与$uri相同。\n日志配置变量location / &#123;      proxy_pass [$Domain]; #必须      index index.html index.htm index.jsp index.shtml;      proxy_redirect off;      proxy_set_header Host $host;      proxy_set_header Lky $remote_addr;      proxy_set_header REMOTE-HOST $remote_addr;      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;      proxy_set_header X-My-Header &quot;My Value&quot;;      #在日志中使用$http_x_my_header就可以获取到值，可以写死也可以用内置变量比如set自定义      经测试 proxy_set_header 第一个字母必须大写，只能用-不能用_      log_format 日志格式必须是$http开头-需要换成_而且必须全部小写    &#125;log_format custom &#x27;$remote_addr [$time_local] &quot;$request&quot; &#x27;                  &#x27;Lky:$http_lky&#x27; ;access_log /var/log/nginx/access.log custom;#如果是  proxy_pass http://127.0.0.1:83 第一跳记录上游日志包含真实ip，第二条是客户端访问的不包含Lky，一个请求有两个日志输出#127.0.0.1 - - [23/May/2025:16:31:41 +0800] &quot;GET / HTTP/1.0&quot; 200 4833 &quot;-&quot; &quot;curl/7.60.0&quot; &quot;10.0.1.100&quot; 10.0.1.100Lky:&quot;10.0.1.100&quot;#这里的日志可以通过proxy_set_header自定义，比如获取客户端真实IP#10.0.1.100 - - [23/May/2025:16:31:41 +0800] &quot;GET / HTTP/1.1&quot; 200 4833 &quot;-&quot; &quot;curl/7.60.0&quot; &quot;-&quot; 10.0.1.100:83Lky:&quot;-&quot;#这个则是客户端直接请求的日志，因为$remote_addr为空#测试响应头add_header Lky $remote_addr always;GET / HTTP/1.1Host: example.comUser-Agent: Mozilla/5.0Lky: 192.168.1.100\n\n","categories":["中间件"]},{"title":"openvpn","url":"/2025/04/21/openvpn/","content":"安装git clone https://github.com/likaiyuan00/openvpn-install.gitcd openvpn-install &amp;&amp; bash openvpn-install.sh#systemctl start openvpn@client.service 启动的账号密码  auth-user-pass 控制客户端密码验证echo &quot;test test@123&quot; &gt;  /etc/openvpn/userfile.sh\n\n配置文件字段解读server端在#openvpn服务端的监听地址local 0.0.0.0#openvpn服务端的监听端口（默认1194）port 1115#使用的协议，tcp/udpproto tcp#使用三层路由ip隧道（tun），还是二层以太网隧道（tap），一般使用tundev tun#ca证书、服务端证书、服务端秘钥和秘钥交换文件ca /etc/openvpn/server/ca.crtcert /etc/openvpn/server/server.crtkey /etc/openvpn/server/server.keydh /etc/openvpn/server/dh.pem#vpn服务端为自己和客户端分配的ip地址池。#服务端自己获取网段的第一个地址（此处是10.8.0.1），后为客户端分配其他的可用地址。以后客户端就可以和10.8.0.1进行通信。注意：以下网段地址不要和已有网段冲突或重复server 10.8.0.0  255.255.255.0#使用一个文件记录已分配虚拟ip的客户端和虚拟ip的对应关系。以后openvpn重启时，将可以按照此文件继续为对应的客户端分配此前相同的ip（自动续借ip）ifconfig-pool-persist ipp.txt#使用tap模式的时候考虑此选项server-bridge XXXXXX#vpn服务端向客户端推送vpn服务端内网网段的路由配置，以便让客户端能够找到服务端的内网。多条路由写多个push指令push &quot;route 10.0.10.0  255.255.255.0&quot;push &quot;route 192.168.10.0 255.255.255.0&quot;  #允许客户端访问的内网网段#让vpn客户端之间可以通信。默认情况客户端只能服务端进行通信#默认此项是注释的，客户端之间不能相互通信client-to-client#允许多个客户端使用同一个vpn账号连接服务端#默认是注释的，不支持多个客户端登录一个账号duplicate-cn#每10秒ping一次，120秒后没收到ping就说明对方挂了keepalive 10 120#加强认证方式，防攻击。如果配置文件中启用此项（默认是启用的），需要执行openvpn --genkey --secret ta.key，并把ta.key放到/etc/openvpn/server/目录，服务端第二个参数为0；同时客户端也要有此文件，且client.conf中此指令的第二个参数需要为1tls-auth /etc/openvpn/server/ta.key 0#选择一个密码。如果在服务器上使用了cipher选项，那么也必须在这里指定它。注意，v2.4客户端/服务端将在tls模式下自动协商AES-256-GCMcipher AES-256-CBC#openvpn 2.4版本的vpn才能设置此选项。表示服务端启用lz4的压缩功能 ，传输数据给客户端时会压缩数据包。Push后在客户端也配置启用lz4的压缩功能，向服务端发数据时也会压缩。如果是2.4版本以下的老版本，则使用用comp-lzo指令compress lz4-v2push &quot;compress lz4-v2&quot;#启用lzo数据压缩格式，此指令用于低于2.4版本的老版本，且如果服务端配置了该指令，客户端也必须要配置comp-lzo#并发客户端的连接数max-clients 1000#通过ping得知超时时，当重启vpn后将使用同一个秘钥文件以及保持tun连接状态persist-keypersist-tun#在文件中输出当前的连接信息，每分钟截断并重写一次该文件status openvpn-status.log#log指令表示每次启动vpn时覆盖式记录到指定日志文件中#log-append则表示每次启动vpn时追加式的记录到指定日志中#但两者只能选其一，或者不选时记录到rsyslog中log  /var/log/openvpn.loglog-append  /var/log/openvpn.log#日志记录的详细级别verb 3#当服务器重新启动时，通知客户端，以便它可以自动重新连接。仅在UDP协议是可用explicit-exit-notify 1#沉默的重复信息。最多20条相同消息类别的连续消息将输出到日志mute 20\nclient#标识这是个客户端client#使用的协议，tcp/udp，服务端是什么客户端就是什么proto tcp#使用三层路由ip隧道（tun），还是二层以太网隧道（tap），服务端是什么客户端就是什么dev tun#服务端的地址和端口remote 10.0.0.190 1194#一直尝试解析OpenVPN服务器的主机名resolv-retry infinite#大多数客户机不需要绑定到特定的本地端口号nobind#初始化后的降级特权(仅非windows)user nobodygroup nobody#尝试在重新启动时保留某些状态persist-keypersist-tun#ca证书、客户端证书、客户端密钥#如果它们和client.conf或client.ovpn在同一个目录下则可以不写绝对路径，否则需要写绝对路径调用ca ca.crtcert client.crtkey client.key#通过检查certicate是否具有正确的密钥使用设置来验证服务器证书。remote-cert-tls server#加强认证方式，防攻击。服务端有配置，则客户端必须有tls-auth ta.key 1#选择一个密码。如果在服务器上使用了cipher选项，那么您也必须在这里指定它。注意，v2.4客户端/服务器将在TLS模式下自动协商AES-256-GCM。cipher AES-256-CBC# 服务端用的什么，客户端就用的什么#表示客户端启用lz4的压缩功能，传输数据给客户端时会压缩数据包comp-lzo# 日志级别verb 3#沉默的重复信息。最多20条相同消息类别的连续消息将输出到日志mute 20\n\n如何直连openvpn服务端其他局域网服务器\n客户端（10.8.0.10） ping (服务端)172.16.1.7 正常 ping (服务端其他内网机器)172.16.1.8失败\n\n\n第一种方法 配置路由route add -net 10.8.0.0 netmask 255.255.255.0 gw 172.16.1.710.8.0.0  客户端IP172.16.1.7 openvpn 服务端IP\n\n\n\n\n\n\n\n第二种方法使用snat转发 iptables -t nat -A POSTROUTING -d 10.8.0.0&#x2F;24 -o eth0 -j MASQUERADEiptables -A FORWARD -s 10.8.0.0 -j ACCEPT\n\n\n\n额外服务端route 192.168.0.0 255.255.0.0   指令作用是在服务端加一条路由，网关是客户端ip\n服务端只能ping通客户端的tun0的ip，内网ip不行，即使加了路由也不行\n客户端push “route 192.168.10.0 255.255.255.0”作用是在客户端多加一条路由。网关是服务端的tun0IP（也就是server 指令配置分配的地址池）\n","categories":["linux"]},{"title":"prometheus","url":"/2025/04/18/prometheus/","content":"https://github.com/likaiyuan00/k8s-prometheus.git\nk8s-prometheus部署kubernetes_sd_configs配置文件只采集了\n\n1 prometheus*  prometheus-server2 container*   kubelet 的10250端口  &#x2F;metrics&#x2F;cadvisor3 node*    node_exporter4 apiserver*  apiserver 6443 端口 &#x2F;metrics5 kube*  kube-state-metrics组件 8080端口 &#x2F;metrics6 coredns*  kubernetes-pods 自动发现 pod需要配置 prometheus.io&#x2F;scrape: “true” 不然抓取不到 默认flaseprometheus.io&#x2F;path: “&#x2F;metrics”   # 指标路径（默认 &#x2F;metrics 可不写）7 kubelet*  apiserver代理端点 &#x2F;api&#x2F;v1&#x2F;nodes&#x2F;&lt;node-name&gt;&#x2F;proxy&#x2F;metrics其他有需要的可以自行配置\n\n导入镜像，执行yml文件即可\nprometheus效果图\ngrafana效果图\nkubelet 组件 kubelet 三个指标 &#x2F;metrics&#x2F;probes（探针） &#x2F;metrics&#x2F;cadvisor（pod） &#x2F;metrics（node）\n对应apiserver的 &#x2F;api&#x2F;v1&#x2F;nodes&#x2F;${node-name}&#x2F;proxy&#x2F;${url};一般为了减少apiserver的负载不建议使用这种方式 **\n直接访问会报401没有权限\n需要先获取token，上面文件执行完会有一个prometheus用户\npod内token路径为 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token\n通过token再去访问发现就正常了\n/metricscurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metricscurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics\n\n对应kubelet*开头\n/metrics/probes（探针）curl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metrics/probescurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics/probes\n\n/metrics/cadvisor（pod）curl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metrics/cadvisorcurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics/cadvisor\n\n对应container*开头，容器指标\nnode_exporter端口暴露到节点了就不需要token了\nnode*开头，节点指标\nkube-state-metrics集群应用状态监控比较重要的一个需要单独安装使用containerPort: 8080 暴露到节点了不需要token\nkube*开头\napiserver主要是监控apiserver的qps,查询成功率失败率等信息\napiserver*开头\nkubernetes-pods 自动发现如果元数据内设置true，该pod才可以被抓取，默认false\n以coredns为例\n以coredns*开头\n这个自动发现还可以配置自身业务的监控，只有保证开启抓取，和符合prometheus抓取规范就可以，如果开启了prometheus.io&#x2F;scrape 但是pod并没有提供数据指标的能力就会直接报错，如图404\n比如现在我想加一个grafana的数据，只需要添加对应元数据就可以了\nprometheus就自动发现了pod的ip\ngrafana*开头\n","categories":["prometheus"],"tags":["prometheus"]},{"title":"screen","url":"/2025/04/27/screen/","content":"多终端管理神器ctrl +a + d 退出终端exit 退出加销毁终端\n常用参数$&gt; screen [-AmRvx -ls -wipe][-d &lt;作业名称&gt;][-h &lt;行数&gt;][-r &lt;作业名称&gt;][-s ][-S &lt;作业名称&gt;] -A 　将所有的视窗都调整为目前终端机的大小。-d   &lt;作业名称&gt; 　将指定的screen作业离线。-h   &lt;行数&gt; 　指定视窗的缓冲区行数。-m 　即使目前已在作业中的screen作业，仍强制建立新的screen作业。-r   &lt;作业名称&gt; 　恢复离线的screen作业。-R 　先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。-s 　指定建立新视窗时，所要执行的shell。-S   &lt;作业名称&gt; 　指定screen作业的名称。-v 　显示版本信息。-x 　恢复之前离线的screen作业。-ls或--list 　显示目前所有的screen作业。-wipe 　检查目前所有的screen作业，并删除已经无法使用的screen作业。screen -S yourname -&gt; 新建一个叫yourname的sessionscreen -ls         -&gt; 列出当前所有的sessionscreen -r yourname -&gt; 回到yourname这个sessionscreen -d yourname -&gt; 远程detach某个sessionscreen -d -r yourname -&gt; 结束当前session并回到yourname这个session\n常用快捷键C-a ? -&gt; 显示所有键绑定信息C-a c -&gt; 创建一个新的运行shell的窗口并切换到该窗口C-a n -&gt; Next，切换到下一个 window C-a p -&gt; Previous，切换到前一个 window C-a 0..9 -&gt; 切换到第 0..9 个 windowCtrl+a [Space] -&gt; 由视窗0循序切换到视窗9C-a C-a -&gt; 在两个最近使用的 window 间切换 C-a x -&gt; 锁住当前的 window，需用用户密码解锁C-a d -&gt; detach，暂时离开当前session，将目前的 screen session (可能含有多个 windows) 丢到后台执行，并会回到还没进 screen 时的状态，此时在 screen session 里，每个 window 内运行的 process (无论是前台/后台)都在继续执行，即使 logout 也不影响。 C-a z -&gt; 把当前session放到后台执行，用 shell 的 fg 命令则可回去。C-a w -&gt; 显示所有窗口列表C-a t -&gt; time，显示当前时间，和系统的 load C-a k -&gt; kill window，强行关闭当前的 windowC-a [ -&gt; 进入 copy mode，在 copy mode 下可以回滚、搜索、复制就像用使用 vi 一样    C-b Backward，PageUp     C-f Forward，PageDown     H(大写) High，将光标移至左上角     L Low，将光标移至左下角     0 移到行首     $ 行末     w forward one word，以字为单位往前移     b backward one word，以字为单位往后移     Space 第一次按为标记区起点，第二次按为终点     Esc 结束 copy mode C-a ] -&gt; paste，把刚刚在 copy mode 选定的内容贴上\n","categories":["linux"]},{"title":"tcp","url":"/2025/07/25/tcp/","content":"三握四挥\n （1）第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。  （2）第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。  （3）第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了客户端发起fin位为1的FIN报文，此时客户端进入FIN_WAIT_1状态服务端接受到FIN 报文后，发送ack应答报文，此时服务端进入close_wait状态客户端接受到ack应答报文后，进入FIN_WAIT_2状态服务端处理完数据后，向客户端发送FIN报文，此时服务端进入LAST_ACK状态客户端接受到FIN报文后，客户端发送应答ack报文，进入TIME_WAIT阶段服务端接受到ack报文后，断开连接，处于close状态客户端过一段时间后，也就是2MSL后，进入close状态\n\n\n\n\nTime Wait概念\n谁先关闭谁最后进入timewait状态，time_wait 状态下，TCP 连接占用的端口，无法被再次使用close 短连接每个HTTP请求都需要重新完成TCP三次握手建立连接，数据传输完成后四次挥手关闭连接keep-alive 长连接在HTTP1.1协议中默认长连接，有个 Connection 头，Connection有两个值，close和keep-alive，这个头就相当于客户端告诉服务端，服务端你执行完成请求之后，是关闭连接还是保持连接，保持连接就意味着在保持连接期间，只能由客户端主动断开连接。还有一个keep-alive的头，设置的值就代表了服务端保持连接保持多久#ngxkeepalive 100;          # 保持的空闲连接数keepalive_timeout 60s;   # 空闲超时时间keepalive_requests 100;  # 单连接最大请求数location / &#123;    proxy_pass http://backend_servers;    proxy_http_version 1.1;     # 关键：使用 HTTP/1.1    proxy_set_header Connection &quot;&quot;;  # 清除 Connection 头（避免传递错误值）&#125;# Linux 内核参数（默认值通常为 7200 秒）默认不启用sysctl -w net.ipv4.tcp_keepalive_time=1800  # 空闲 1800 秒后发送探针sysctl -w net.ipv4.tcp_keepalive_probes=3   # 发送 3 次无响应后关闭sysctl -w net.ipv4.tcp_keepalive_intvl=15   # 每次探针间隔 15 秒\n\n相关参数netstat -ant | awk &#x27;/^tcp/ &#123;++y[$NF]&#125; END &#123;for(w in y) print w, y[w]&#125;&#x27;net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30==============================================net.ipv4.tcp_tw_reuse = 1表示开启重用。允许将一个处于TIME-WAIT状态的端口重新用于新的TCP连接，默认为0，表示关闭，其防止重复报文的原理也是时间戳net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，意思就是系统会保存最近一次该socket连接上的传输报文（包括数据或者仅仅是ACK报文）的时间戳，当相同四元组socket过来的报文的时间戳小于缓存下来的时间戳则丢弃该数据包，并回收这个socket，默认为0，表示关闭。开启这个功能风险有点大，NAT环境可能导致DROP掉SYN包（回复RST），在NAT场景下不要使用。需要注意在Linux内核4.10版本以后该参数就已经被移除了。net.ipv4.tcp_fin_timeout = 60这个时间不是修改2MSL的时长，主动关闭连接的一方接收到ACK之后会进入，FIN_WAIT-2状态，然后等待被动关闭一方发送FIN，这个时间是设置主动关闭的一方等待对方发送FIN的最长时长，默认是60秒。在这个状态下端口是不可能被重用的，文件描述符和内存也不会被释放，因为这个阶段被动关闭的一方有可能还有数据要发送，因为对端处于CLOSE_WAIT状态，也就是等待上层应用程序。关于这个的真实含义我希望大家清楚，而且不要调整的太小当然太大也不行，至少在3.10内核版本上这个参数不是调整的TIME_WAIT时长。net.ipv4.ip_local_port_range = 32768 60999表示用于外连使用的随机高位端口范围，也就是作为客户端连接其他服务的时候系统从这个范围随机取出一个端口来作为源端口使用来去连接对端服务器，这个范围也就决定了最多主动能同时建立多少个外连。net.ipv4.tcp_max_tw_buckets = 6000同时保持TIME_WAIT套接字的最大个数，超过这个数字那么该TIME_WAIT套接字将立刻被释放并在/var/log/message日志中打印警告信息（TCP: time wait bucket table overflow）。这个过多主要是消耗内存，单个TIME_WAIT占用内存非常小，但是多了就不好了，这个主要看内存以及你的服务器是否直接对外。使用net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle 的前提是开启时间戳net.ipv4.tcp_timestamps = 1不过这一项默认是开启的\n\nCLOSE_WAIT\n这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是查看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。CLOSE_WAIT一般是由于对端主动关闭，而我方没有正确处理的原因引起的，临时解决重启服务，永久解决就是修改程序逻辑客户端（主动关闭方）          服务器（被动关闭方）       |                               |       |--- GET /bigfile.zip ---------&gt;|        |&lt;--- 200 OK + 文件数据 ---------|       |                               |       |--- FIN (我要关闭) ------------&gt;| → 客户端进入 FIN_WAIT_1       |&lt;--- ACK ----------------------| → 服务端进入 CLOSE_WAIT       |                               |（此时服务端还在发送剩余文件数据）       |&lt;--- 剩余数据包 ----------------|       |&lt;--- FIN (我也关闭) ------------| → 服务端进入 LAST_ACK       |--- ACK -----------------------&gt;| → 客户端进入 TIME_WAIT                #没有调用s.close()关闭socket，会造成大量CLOSE_WAITimport socketimport timedef create_sockets(num_sockets):    sockets = []    for _ in range(num_sockets):        # 创建一个 TCP 套接字        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)        print(f&quot;创建 socket &#123;_ + 1&#125;: &#123;s.fileno()&#125;，状态为 alloc&quot;)        sockets.append(s)    return socketsif __name__ == &quot;__main__&quot;:    num_sockets = 10    while True:        num_sockets  += 10        sockets = create_sockets(num_sockets)        print(f&quot;总共创建了 &#123;num_sockets&#125; 个 socket 对象。&quot;)        time.sleep(10)#shellcat /proc/net/sockstat | grep sockets | awk &#x27;&#123;print $3&#125;&#x27;netstat -n | awk &#x27;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,&quot;\\t&quot;,state[key]&#125;&#x27;for i in `ls /proc/ |grep &#x27;[0-9]&#x27;`do    mycount=`ls /proc/$i/fd|wc -l`    echo &quot;$i $mycount&quot;done\n\n","categories":["linux"]},{"title":"使用kubekey快速安装k8s","url":"/2025/04/27/%E4%BD%BF%E7%94%A8kubekey%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85k8s/","content":"官方地址https://github.com/kubesphere/kubekey\n安装\ncurl -sfL https://get-kk.kubesphere.io | sh -\n\n单节点测试使用kk create cluster#默认 v1.23.17--with-kubernetes v1.24.1 #默认docker--container-manager containerd#如果不使用--with-kubesphere默认不安装；默认版本为 v3.4.1--with-kubesphere\n多节点kk create config -f deploy.yml#-f 指定配置文件开始安装kk create cluster -f deploy.yml#deploy.yml;其他节点的ip用户名密码的修改成实际的apiVersion: kubekey.kubesphere.io/v1alpha2kind: Clustermetadata:  name: samplespec:  hosts:  - &#123;name: node1, address: 172.16.0.2, internalAddress: 172.16.0.2, user: ubuntu, password: &quot;Qcloud@123&quot;&#125;  - &#123;name: node2, address: 172.16.0.3, internalAddress: 172.16.0.3, user: ubuntu, password: &quot;Qcloud@123&quot;&#125;  roleGroups:    etcd:    - node1    control-plane:     - node1    worker:    - node1    - node2  controlPlaneEndpoint:    ## Internal loadbalancer for apiservers     # internalLoadbalancer: haproxy    domain: lb.kubesphere.local    address: &quot;&quot;    port: 6443  kubernetes:    version: v1.23.17    clusterName: cluster.local    autoRenewCerts: true    containerManager: docker  etcd:    type: kubekey  network:    plugin: calico    kubePodsCIDR: 10.233.64.0/18    kubeServiceCIDR: 10.233.0.0/18    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni    multusCNI:      enabled: false  registry:    privateRegistry: &quot;&quot;    namespaceOverride: &quot;&quot;    registryMirrors: []    insecureRegistries: []  addons: []----------------------------------------------------#默认不安装kubesphere需要指定--with-kubespherekk create config --with-kubesphere -f deploy-with.yml\n新增删除#新增节点接入集群kk add nodes -f  deploy.yml#删除节点kk delete node &lt;nodeName&gt; -f deploy.yml#删除集群kk delete cluster [-f deploy.yml]\n\n升级集群使用指定版本升级集群。kk upgrade [--with-kubernetes version] [--with-kubesphere version] 仅支持升级 Kubernetes。仅支持升级 KubeSphere。支持升级 Kubernetes 和 KubeSphere。多节点使用指定的配置文件升级集群。kk upgrade [--with-kubernetes version] [--with-kubesphere version] [(-f | --filename) path]如果指定了--with-kubernetes或--with-kubesphere，配置文件也将被更新。用于-f指定为集群创建而生成的配置文件。\n\n更新集群证书\n#默认一年kk  certs renew\n\n","categories":["k8s"]},{"title":"websocket","url":"/2025/05/28/websocket/","content":"异步因为websocket会使用到异步操作先了解一下异步\nimport asyncioimport timeasync def task(name, duration):    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 开始&quot;)    await asyncio.sleep(duration)  # 模拟并发等待    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 完成&quot;)def task_(name, duration):    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 开始&quot;)    time.sleep(duration)  # 模拟耗时操作    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 完成&quot;)async def main():    start_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 异步任务开始&quot;)    await asyncio.gather(        task(&quot;A&quot;, 2),        task(&quot;B&quot;, 3),        task(&quot;C&quot;, 1)    )    end_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 异步任务总耗时: &#123;end_time - start_time:.2f&#125; 秒&quot;)def main_():    start_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 同步任务开始&quot;)    task_(&quot;A&quot;, 2)    task_(&quot;B&quot;, 3)    task_(&quot;C&quot;, 1)    end_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 同步任务总耗时: &#123;end_time - start_time:.2f&#125; 秒&quot;)if __name__ == &quot;__main__&quot;:    print(&quot;======================异步==========================&quot;)    asyncio.run(main())    print(&quot;======================同步==========================&quot;)    main_()#结果可以看出异步不需要等待会直接执行下一步操作，任务完成可以使用await来回调处理完成结果======================异步==========================[14:45:43] 异步任务开始[14:45:43] 任务 A 开始[14:45:43] 任务 B 开始[14:45:43] 任务 C 开始[14:45:44] 任务 C 完成[14:45:45] 任务 A 完成[14:45:46] 任务 B 完成[14:45:46] 异步任务总耗时: 3.00 秒======================同步==========================[14:45:46] 同步任务开始[14:45:46] 任务 A 开始[14:45:48] 任务 A 完成[14:45:48] 任务 B 开始[14:45:51] 任务 B 完成[14:45:51] 任务 C 开始[14:45:52] 任务 C 完成[14:45:52] 同步任务总耗时: 6.00 秒\nwebsocket服务端import asyncioimport websockets#https://websockets.readthedocs.io/en/stable/# 处理客户端连接async def handle_client(websocket):    async for message in websocket:        print(f&quot;收到客户端消息: &#123;message&#125;&quot;)        reply = f&quot;机器人回复：你说的是 &#x27;&#123;message&#125;&#x27; 对吗？&quot;        await websocket.send(reply)# async def main_logic(websocket, path):#    # await check_permit(websocket)##     await handle_client(websocket)# 启动服务器async def main():    async with websockets.serve(handle_client, &quot;localhost&quot;, 8765):        print(&quot;WebSocket 服务器已启动，端口 8765&quot;)        await asyncio.Future()  # 永久运行asyncio.run(main())\n\n\n\n客户端import asyncioimport websocketsasync def client():    async with websockets.connect(&quot;ws://localhost:8765&quot;) as websocket:        while True:            message = input(&quot;请输入消息（输入 q 退出）: &quot;)            if message == &#x27;q&#x27;:                break            await websocket.send(message)            response = await websocket.recv()            print(f&quot;收到回复: &#123;response&#125;&quot;)asyncio.run(client())#效果，相当于打开了一个通道双方都可以发消息WebSocket 服务器已启动，端口 8765请输入消息（输入 q 退出）: hello websockets收到回复: 机器人回复：你说的是 &#x27;hello websockets&#x27; 对吗？请输入消息（输入 q 退出）: \n额外fastapi框架使用websocketfrom fastapi import FastAPI, WebSocket, WebSocketDisconnectfrom fastapi.responses import HTMLResponsefrom fastapi.middleware.cors import CORSMiddlewareimport jsonapp = FastAPI()# 配置CORS跨域app.add_middleware(    CORSMiddleware,    allow_origins=[&quot;*&quot;],    allow_credentials=True,    allow_methods=[&quot;*&quot;],    allow_headers=[&quot;*&quot;],)# HTML页面（修改了前端WebSocket实现）HTML_TEMPLATE = &#x27;&#x27;&#x27;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;FastAPI 聊天&lt;/title&gt;    &lt;style&gt;        body &#123; max-width: 800px; margin: 20px auto; padding: 20px; &#125;        #output &#123;             height: 300px;             border: 1px solid #ccc;             overflow-y: auto;             padding: 10px;             margin-bottom: 10px;        &#125;        #input &#123;             width: 80%;             padding: 8px;            margin-right: 10px;        &#125;        button &#123;            padding: 8px 16px;            background: #007bff;            color: white;            border: none;            border-radius: 4px;            cursor: pointer;        &#125;        button:hover &#123;            opacity: 0.8;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;output&quot;&gt;&lt;/div&gt;    &lt;input type=&quot;text&quot; id=&quot;input&quot; placeholder=&quot;输入消息...&quot;&gt;    &lt;button onclick=&quot;sendMessage()&quot;&gt;发送&lt;/button&gt;    &lt;script&gt;        // 初始化WebSocket连接        const socket = new WebSocket(`ws://$&#123;window.location.host&#125;/ws`);        // 连接成功回调        socket.onopen = () =&gt; &#123;            addMessage(&#x27;系统&#x27;, &#x27;已连接到服务器&#x27;);        &#125;;        // 接收消息处理        socket.onmessage = (event) =&gt; &#123;            const data = JSON.parse(event.data);            addMessage(&#x27;机器人&#x27;, data.message);        &#125;;        // 错误处理        socket.onerror = (error) =&gt; &#123;            addMessage(&#x27;系统&#x27;, `连接错误: $&#123;error.message&#125;`);        &#125;;        // 关闭连接处理        socket.onclose = () =&gt; &#123;            addMessage(&#x27;系统&#x27;, &#x27;连接已断开&#x27;);        &#125;;        // 发送消息        function sendMessage() &#123;            const input = document.getElementById(&#x27;input&#x27;);            const message = input.value.trim();            if (message) &#123;                socket.send(JSON.stringify(&#123;                    type: &quot;user_message&quot;,                    content: message                &#125;));                addMessage(&#x27;我&#x27;, message);                input.value = &#x27;&#x27;;            &#125;        &#125;        // 添加消息到界面        function addMessage(sender, content) &#123;            const output = document.getElementById(&#x27;output&#x27;);            const div = document.createElement(&#x27;div&#x27;);            div.innerHTML = `&lt;strong&gt;$&#123;sender&#125;:&lt;/strong&gt; $&#123;content&#125;`;            output.appendChild(div);            // 自动滚动到底部            output.scrollTop = output.scrollHeight;        &#125;    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&#x27;&#x27;&#x27;@app.get(&quot;/&quot;)async def index():    return HTMLResponse(HTML_TEMPLATE)# WebSocket端点@app.websocket(&quot;/ws&quot;)async def websocket_endpoint(websocket: WebSocket):    await websocket.accept()    try:        while True:            # 接收客户端消息            data = await websocket.receive_text()            message_data = json.loads(data)            # 处理客户端消息            if message_data[&#x27;type&#x27;] == &#x27;user_message&#x27;:                print(f&quot;收到客户端消息: &#123;message_data[&#x27;content&#x27;]&#125;&quot;)                # 构造回复消息                reply = &#123;                    &quot;type&quot;: &quot;server_response&quot;,                    &quot;message&quot;: f&quot;机器人回复：你说的是 &#x27;&#123;message_data[&#x27;content&#x27;]&#125;&#x27; 对吗？&quot;                &#125;                # 发送回复                await websocket.send_json(reply)    except WebSocketDisconnect:        print(&quot;客户端断开连接&quot;)    except Exception as e:        print(f&quot;发生错误: &#123;str(e)&#125;&quot;)if __name__ == &quot;__main__&quot;:    import uvicorn    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8001)\nflask使用websocketimport eventleteventlet.monkey_patch()  # 关键：启用异步支持from flask import Flask, render_template_string#pip install flask-socketio eventletfrom flask_socketio import SocketIO, emitapp = Flask(__name__)app.config[&#x27;SECRET_KEY&#x27;] = &#x27;secret!&#x27;socketio = SocketIO(app, cors_allowed_origins=&quot;*&quot;)  # 允许跨域@app.route(&#x27;/&#x27;)def index():    return render_template_string(&#x27;&#x27;&#x27;    &lt;!DOCTYPE html&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;Socket.IO 聊天&lt;/title&gt;        &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.7.2/socket.io.js&quot;&gt;&lt;/script&gt;        &lt;style&gt;            /* 保持原有样式不变 */            body &#123; max-width: 800px; margin: 20px auto; padding: 20px; &#125;            #output &#123; height: 300px; border: 1px solid #ccc; overflow-y: auto; padding: 10px; &#125;        &lt;/style&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div id=&quot;output&quot;&gt;&lt;/div&gt;        &lt;input id=&quot;input&quot; placeholder=&quot;输入消息&quot;&gt;        &lt;button onclick=&quot;send()&quot;&gt;发送&lt;/button&gt;        &lt;script&gt;            const socket = io();  // 自动连接当前域名            // 连接成功回调            socket.on(&#x27;connect&#x27;, () =&gt; &#123;                addMessage(&#x27;系统&#x27;, &#x27;已连接到服务器&#x27;);            &#125;);            // 接收服务器消息            socket.on(&#x27;server_response&#x27;, (data) =&gt; &#123;                addMessage(&#x27;机器人&#x27;, data.message);            &#125;);            // 发送消息            function send() &#123;                const input = document.getElementById(&#x27;input&#x27;);                const message = input.value.trim();                if (message) &#123;                    socket.emit(&#x27;client_message&#x27;, message);                    addMessage(&#x27;我&#x27;, message);                    input.value = &#x27;&#x27;;                &#125;            &#125;            // 添加消息到界面            function addMessage(sender, content) &#123;                const div = document.createElement(&#x27;div&#x27;);                div.innerHTML = `&lt;strong&gt;$&#123;sender&#125;:&lt;/strong&gt; $&#123;content&#125;`;                document.getElementById(&#x27;output&#x27;).appendChild(div);                // 自动滚动到底部                const output = document.getElementById(&#x27;output&#x27;);                output.scrollTop = output.scrollHeight;            &#125;        &lt;/script&gt;    &lt;/body&gt;    &lt;/html&gt;    &#x27;&#x27;&#x27;)# Socket.IO 事件处理@socketio.on(&#x27;client_message&#x27;)def handle_message(message):    print(f&#x27;收到客户端消息: &#123;message&#125;&#x27;)    # 构造回复消息    reply = f&quot;机器人回复：你说的是 &#x27;&#123;message&#125;&#x27; 对吗？&quot;    # 发送消息给客户端    emit(&#x27;server_response&#x27;, &#123;&#x27;message&#x27;: reply&#125;)if __name__ == &#x27;__main__&#x27;:    socketio.run(app, host=&#x27;0.0.0.0&#x27;, port=8000, debug=True)\n大模型使用websocket聊天# main.pyfrom fastapi import FastAPI, WebSocketfrom fastapi.responses import HTMLResponseimport requestsimport jsonapp = FastAPI()# 存储对话历史 (生产环境建议使用数据库)conversation_history = []# 集成前端页面与后端逻辑HTML_TEMPLATE = &quot;&quot;&quot;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;AI 对话助手&lt;/title&gt;    &lt;style&gt;        body &#123;            max-width: 800px;            margin: 0 auto;            padding: 20px;            font-family: Arial, sans-serif;        &#125;        #chatContainer &#123;            height: 60vh;            border: 1px solid #ddd;            border-radius: 8px;            overflow-y: auto;            padding: 15px;            margin-bottom: 15px;            background: #f9f9f9;        &#125;        .message &#123;            margin: 10px 0;            padding: 12px;            border-radius: 15px;            max-width: 80%;            word-wrap: break-word;        &#125;        .user-message &#123;            background: #e3f2fd;            margin-left: auto;            border-bottom-right-radius: 5px;        &#125;        .bot-message &#123;            background: #fff;            border: 1px solid #eee;            margin-right: auto;            border-bottom-left-radius: 5px;        &#125;        #inputContainer &#123;            display: flex;            gap: 10px;        &#125;        #userInput &#123;            flex: 1;            padding: 12px;            border: 1px solid #ddd;            border-radius: 25px;            outline: none;        &#125;        button &#123;            padding: 12px 25px;            background: #007bff;            color: white;            border: none;            border-radius: 25px;            cursor: pointer;            transition: background 0.3s;        &#125;        button:hover &#123;            background: #0056b3;        &#125;        .status &#123;            color: #666;            text-align: center;            padding: 10px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;AI 对话助手&lt;/h1&gt;    &lt;div id=&quot;chatContainer&quot;&gt;&lt;/div&gt;    &lt;div id=&quot;inputContainer&quot;&gt;        &lt;input type=&quot;text&quot; id=&quot;userInput&quot; placeholder=&quot;输入消息...&quot; /&gt;        &lt;button onclick=&quot;sendMessage()&quot;&gt;发送&lt;/button&gt;    &lt;/div&gt;    &lt;div class=&quot;status&quot; id=&quot;status&quot;&gt;连接状态：正常&lt;/div&gt;       // &lt;iframe   //      src=&quot;http://47.237.81.149/chatbot/9h9nyQcblGTesiGJ&quot;    //     style=&quot;width: 100%; height: 100%; min-height: 700px&quot;   //      frameborder=&quot;0&quot;  //       allow=&quot;microphone&quot;&gt;   // &lt;/iframe&gt;    &lt;script&gt;        const ws = new WebSocket(&#x27;ws://&#x27; + window.location.host + &#x27;/ws&#x27;);        const chatContainer = document.getElementById(&#x27;chatContainer&#x27;);        let isBotResponding = false;        // WebSocket 事件处理        ws.onopen = () =&gt; updateStatus(&#x27;已连接&#x27;);        ws.onclose = () =&gt; updateStatus(&#x27;连接已断开&#x27;);        ws.onerror = () =&gt; updateStatus(&#x27;连接错误&#x27;);        ws.onmessage = (event) =&gt; &#123;            const data = JSON.parse(event.data);            handleResponse(data);        &#125;;        function handleResponse(data) &#123;            switch(data.type) &#123;                case &#x27;user_message&#x27;:                    appendMessage(data.content, &#x27;user&#x27;);                    break;                case &#x27;assistant_start&#x27;:                    isBotResponding = true;                    appendMessage(&#x27;&#x27;, &#x27;bot&#x27;);                    break;                case &#x27;assistant_chunk&#x27;:                    appendChunk(data.content);                    break;                case &#x27;assistant_end&#x27;:                    isBotResponding = false;                    break;                case &#x27;error&#x27;:                    appendMessage(`错误：$&#123;data.content&#125;`, &#x27;error&#x27;);                    break;            &#125;        &#125;        function appendMessage(content, role) &#123;            const div = document.createElement(&#x27;div&#x27;);            div.className = `message $&#123;role&#125;-message`;            div.textContent = content;            chatContainer.appendChild(div);            scrollToBottom();        &#125;        function appendChunk(content) &#123;            const messages = document.getElementsByClassName(&#x27;bot-message&#x27;);            const lastMsg = messages[messages.length - 1];            lastMsg.textContent += content;            scrollToBottom();        &#125;        function scrollToBottom() &#123;            chatContainer.scrollTop = chatContainer.scrollHeight;        &#125;        function updateStatus(text) &#123;            document.getElementById(&#x27;status&#x27;).textContent = `状态：$&#123;text&#125;`;        &#125;        function sendMessage() &#123;            const input = document.getElementById(&#x27;userInput&#x27;);            const message = input.value.trim();            if (message &amp;&amp; !isBotResponding) &#123;                ws.send(message);                input.value = &#x27;&#x27;;            &#125;        &#125;        // 支持回车发送        document.getElementById(&#x27;userInput&#x27;).addEventListener(&#x27;keypress&#x27;, (e) =&gt; &#123;            if (e.key === &#x27;Enter&#x27;) sendMessage();        &#125;);    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot;@app.get(&quot;/&quot;)async def get():    return HTMLResponse(HTML_TEMPLATE)@app.websocket(&quot;/ws&quot;)async def websocket_endpoint(websocket: WebSocket):    await websocket.accept()    try:        while True:            # 接收用户消息            user_message = await websocket.receive_text()            # 更新对话历史            conversation_history.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message&#125;)            # 发送用户消息到前端            await websocket.send_json(&#123;                &quot;type&quot;: &quot;user_message&quot;,                &quot;content&quot;: user_message            &#125;)            # 准备流式请求            await websocket.send_json(&#123;&quot;type&quot;: &quot;assistant_start&quot;&#125;)            # 构造请求数据            request_data = &#123;                &quot;model&quot;: &quot;deepseek-r1:latest&quot;,                &quot;messages&quot;: conversation_history,                &quot;stream&quot;: True            &#125;            # 流式获取响应            full_response = []            with requests.post(                    &quot;http://1.1.1.1:11434/api/chat&quot;,#大模型接口地址                    json=request_data,                    stream=True            ) as response:                response.raise_for_status()                for line in response.iter_lines():                    if line:                        chunk = json.loads(line.decode(&#x27;utf-8&#x27;))                        if &#x27;message&#x27; in chunk:                            content = chunk[&#x27;message&#x27;][&#x27;content&#x27;]                            full_response.append(content)                            await websocket.send_json(&#123;                                &quot;type&quot;: &quot;assistant_chunk&quot;,                                &quot;content&quot;: content                            &#125;)            # 保存完整响应            conversation_history.append(&#123;                &quot;role&quot;: &quot;assistant&quot;,                &quot;content&quot;: &quot;&quot;.join(full_response)            &#125;)            await websocket.send_json(&#123;&quot;type&quot;: &quot;assistant_end&quot;&#125;)    except Exception as e:        await websocket.send_json(&#123;            &quot;type&quot;: &quot;error&quot;,            &quot;content&quot;: f&quot;系统错误: &#123;str(e)&#125;&quot;        &#125;)    finally:        await websocket.close()if __name__ == &quot;__main__&quot;:    import uvicorn    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)","tags":["websocket"]},{"title":"使用maven打包","url":"/2025/05/12/%E4%BD%BF%E7%94%A8maven%E6%89%93%E5%8C%85/","content":"使用springboot&lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.5.9&lt;/version&gt;        &lt;relativePath/&gt;    &lt;/parent&gt;    &lt;groupId&gt;org.ecs&lt;/groupId&gt;    &lt;artifactId&gt;springboot01&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n其他&lt;groupId&gt;org.example&lt;/groupId&gt;    &lt;artifactId&gt;CpuLoad&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;3.1.0&lt;/version&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;manifest&gt;                            &lt;!-- 指定入口函数 --&gt;                             \t\t\t    &lt;mainClass&gt;org.example.CpuLoad&lt;/mainClass&gt;                            &lt;!-- 是否添加依赖的jar路径配置 --&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;!-- 依赖的jar包存放未知，和生成的jar放在同一级目录下 --&gt;                            &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;                        &lt;/manifest&gt;                    &lt;/archive&gt;                    &lt;!-- 不打包com.yh.excludes下面的所有类 --&gt;                    &lt;excludes&gt;com/xx/excludes/*&lt;/excludes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n","tags":["maven"]},{"title":"数据库","url":"/2025/07/24/%E6%95%B0%E6%8D%AE%E5%BA%93/","content":"数据库mysql索引失效情况\n回表概念1.聚集索引的B+树，性能最优，叶子节点存储的数据是整行的所有字段数据(主键索引)2.非聚集索引的B+树，非聚集索引列可能是一列，也可能是多列（联合索引），  叶子节点存储的数据是非聚集索引列（1列或多列）的数据和聚集索引列用户user表4列（id, userCode, userName, userSex）id是主键（聚集索引）；userCode 是非聚集索引，此时会创建2个索引的B+树聚集索引的B+树，叶子节点保存了4列（id, userCode, userName, userSex）的数据非聚集索引的B+树，叶子节点保存了2列（id, userCode）的数据不回表走主键索引不回表，因为挂载的是整列数据select * from user where id = 1 走非聚集索引不回表，因为叶子结点挂载了非聚集索引和聚集索引的值select id,userCode from user where userCode = 1 回表因为查询的列除了主键id和非聚集索引userCode还有userName, userSex，这两个叶子节点没有存数据，会通过主键索引id回表来查询userName, userSex的值，因为主键索引id挂载的整列的值select id,userCode，userSex from user where userCode = 1select id,userCode，userName from user where userCode = 1select * from user where userCode = 1\n常用sql元数据#指定数据库的详细信息SELECT   TABLE_SCHEMA AS &#x27;数据库&#x27;,  TABLE_NAME AS &#x27;表名&#x27;,  TABLE_ROWS AS `行数`,  ROUND( (DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) AS &#x27;总大小(MB)&#x27;,  ROUND(DATA_LENGTH / 1024 / 1024, 2) AS &#x27;数据大小(MB)&#x27;,  ROUND(INDEX_LENGTH / 1024 / 1024, 2) AS &#x27;索引大小(MB)&#x27;,  TABLE_ROWS AS &#x27;数据行数（估算值）&#x27;FROM information_schema.TABLESWHERE TABLE_SCHEMA = &#x27;y_back&#x27;  -- 替换为你的数据库名ORDER BY (DATA_LENGTH + INDEX_LENGTH) DESC;  -- 按总大小排序#数据库表的行数SELECT   TABLE_NAME AS &#x27;表名&#x27;,  TABLE_ROWS AS &#x27;估算行数&#x27;,  (SELECT COUNT(*) FROM y_back.t_work) AS &#x27;精确行数&#x27;  -- 替换为实际表名FROM information_schema.TABLESWHERE TABLE_SCHEMA = &#x27;y_back&#x27;;#allSELECT\ttable_schema AS &#x27;数据库&#x27;,\tsum( table_rows ) AS &#x27;记录数&#x27;,\tsum(\tTRUNCATE ( data_length / 1024 / 1024, 2 )) AS &#x27;数据容量(MB)&#x27;,\tsum(\tTRUNCATE ( index_length / 1024 / 1024, 2 )) AS &#x27;索引容量(MB)&#x27; FROM\tinformation_schema.TABLES GROUP BY\ttable_schema ORDER BY\tsum( data_length ) DESC,\tsum( index_length ) DESC;#过滤元数据库SELECT  table_schema AS &#x27;数据库&#x27;,  SUM(table_rows) AS &#x27;记录数&#x27;,  TRUNCATE(SUM(data_length) / 1024 / 1024, 2) AS &#x27;数据容量(MB)&#x27;,  -- 先求和再转换单位  TRUNCATE(SUM(index_length) / 1024 / 1024, 2) AS &#x27;索引容量(MB)&#x27;FROM  information_schema.TABLESWHERE  table_schema NOT IN (    &#x27;information_schema&#x27;,     &#x27;mysql&#x27;,     &#x27;performance_schema&#x27;,     &#x27;sys&#x27;  )GROUP BY  table_schemaORDER BY  SUM(data_length) DESC,  SUM(index_length) DESC;ANALYZE TABLE - 更新统计信息OPTIMIZE TABLE - 表优化重组俗称清理碎片#造数据CREATE TABLE `t_work_db01` (  `id` bigint NOT NULL AUTO_INCREMENT,  `name` varchar(256) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci DEFAULT NULL,  `age` int DEFAULT NULL,  `sex` char(1) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci DEFAULT NULL,  `money` float DEFAULT NULL COMMENT &#x27;金额&#x27;,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=100001 DEFAULT CHARSET=utf8mb3 ROW_FORMAT=DYNAMICDELIMITER $$CREATE PROCEDURE InsertDummyData()BEGIN    DECLARE i INT DEFAULT 0;    WHILE i &lt; 100000 DO        INSERT INTO t_work (NAME, age, sex, money)        VALUES (            -- 随机生成用户名（示例：User_XXXX）            CONCAT(&#x27;User_&#x27;, SUBSTRING(MD5(RAND()) FROM 1 FOR 8)),            -- 随机年龄 18~65 岁            FLOOR(18 + RAND() * 48),            -- 随机性别（M/F）            IF(RAND() &lt; 0.5, &#x27;M&#x27;, &#x27;F&#x27;),            -- 随机金额 1000~10000（保留两位小数）            ROUND(1000 + RAND() * 9000, 2)        );        SET i = i + 1;    END WHILE;END$$DELIMITER ;-- 执行存储过程CALL InsertDummyData();DROP PROCEDURE IF EXISTS InsertDummyData;  -- 强制删除（如果存在）\nmysql读写分离github ProxySqlMaxScale\nmysql分表分库mycat\npgsqlPostgreSQL psql 常用命令\n概念PUBLIC 是 PostgreSQL 数据库中一个特殊的角色组，在元数据表（pg_roles）中都查不到该角色，数据库中所创建的角色都可以理解为是 PUBLIC 角色组成员。而且对 PUBLIC 权限的继承完全不受 NOINHERIT 的控制，一旦创建了一个拥有 login 权限的角色，它会立即继承 PUBLIC 角色组拥有的权限，此时如果想通过 revoke（比如 revoke connect on database）来回收的话不会成功，只能从 PUBLIC 组回收相关权限（比如 revoke connect on database from PUBLIC）REVOKE CONNECT ON DATABASE test FROM PUBLIC;--这样普通用户就无法自由切换数据库，默认数据库下面有一个public的schemeMySQL 的 datadir ≈ PostgreSQL 的默认表空间 pg_defaultPostgreSQL 的 pg_default 表空间对应默认数据目录（由参数 data_directory 配置），类似于 MySQL 的 datadir。PostgreSQL 的数据库 ≈ MySQL 的实例（但更轻量）。PostgreSQL 的模式 ≈ MySQL 的数据库\n\n基本使用命令docker run -id --name=pgsql -v postgre-data:/var/lib/postgresql/data -p 54222:5432 -e POSTGRES_PASSWORD=123456 -e LANG=C.UTF-8 bitnami/postgresqldocker exec -it -uroot pgsql bashpsql -U postgres -W -ncat .psql_history psql -h host -p port -d dbname -U  user -W使用反斜线作为命令前缀.  postgres=# \\db# 输出的信息如下：       List of tablespaces    Name    |  Owner   | Location ------------+----------+---------- pg_default | postgres |  pg_global  | postgres | (2 rows)退出    \\q 列出所有的数据库      \\l 列出所有的数据库的大小      \\l+ 更改当前连接的数据库       \\c 列出当前数据库的连接信息    \\connect 列出当前数据库和连接的详细信息 \\conninfo 查看当前数据库里面的表和拥有者和表大小         \\dt+ 展示所有用户           \\dg ​模式 \\dn 查看所有表名的列表             \\d 获取表结构                   \\da 展示所有用户               \\du 查看t_sms表的结构      \\d t_sms  展示数据库里面的所有的表         \\dt 列出所有的数据库的详细信息（包括数据库大小和字符格式）         \\l+ 显示用户访问权限。                            \\z或\\dp 显示所有可设置的访问权限                     \\h GRAN 显示用户的对所有数据库表的详细访问权限     \\dp或者\\z 确认当前连接的用户为超级用户postgres，且该用户后创建角色和数据库的权限等     #select current_user; 在超级用户连接postgres后，设置不允许普通用户a连接数据库         #alter role a nologin; ​ 使用普通用户a连接数据库正常                   #\\c highgo a快速查看当前所有用户：\\du查看详细用户信息：select * from pg_user;查看详细角色信息：select * from pg_roles;查看当前登录用户：select user;一般建议先创建用户然后使用这个用户去创建数据库模式，因为数据库那个用户创建的默认Owner就是这个用户创建用户：CREATE USER $user_name PASSWORD &#x27;$password&#x27;;创建角色：CREATE ROLE $role_name; 修改用户与角色：ALTER USER[ROLE] $user_name         e.g.        //修改用户名：ALTER USER U2 RENAME TO U22;        //修改用户的密码：ALTER USER U22 PASSWORD&#x27;U22;        //修改用户的权限：ALTER USER u22 CREATEROLE;        //修改数据库 testdb中的参数重设为默认值：ALTER USER u22 IN DATABASE testdb RESET all1;        //修改角色的名字：ALTER ROLE dev RENAME TO dev1;        //修改角色的权限：ALTER ROLE dev1 SUPERUSER;        //修改角色的权限：ALTER ROLE dev1 LOGIN; 删除用户与角色：DROP USER[ROLE] [IF EXISTS] $user_name 授权用户某个角色:GRANT $role_name TO $user_name;    (授权后set role $role_name启用生效） create user test with password &#x27;rong &#x27;;CREATE DATABASE testdb OWNER test;GRANT ALL PRIVILEGES ON DATABASE testdb TO test;alter user qh with password &#x27;123&#x27;;\\password qh;  //需要输入两次密码（推荐）\n\n\n\nmanggodb详细使用教程\ndocker run -itd --name mongo -v /docker_volume/mongodb/data:/data/db -p 27017:27017 mongo:4.4 --auth–auth：需要密码才能访问容器服务；mongodb安装好后第一次进入是不需要密码的，也没有任何用户，通过shell命令可直接进入use admin 使用admin数据库并进行验证，如果不验证，是做不了任何操作的db.auth(&quot;root&quot;,&quot;123456&quot;)  返回1表示成功 验证之后还是做不了操作，因为root只有用户管理权限，下面创建用户，用户都跟着库走use mydb db.createUser(&#123;user: &quot;admin&quot;,pwd: &quot;123456&quot;,roles: [&#123; role: &quot;readWrite&quot;, db: &quot;mydb&quot; &#125;]&#125;) 通过admin用户增删改查docker exec -it mongo mongo admindb.createUser(&#123; user:&#x27;root&#x27;,pwd:&#x27;123456&#x27;,roles:[ &#123; role:&#x27;userAdminAnyDatabase&#x27;, db: &#x27;admin&#x27;&#125;,&#x27;readWriteAnyDatabase&#x27;]&#125;);【role:‘userAdminAnyDatabase’】：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限【db: ‘admin’】：可操作的数据库【‘readWriteAnyDatabase’】：赋予用户读写权限mongoDB 没有无敌用户root，只有能管理用户的用户 userAdminAnyDatabase SQL 术语/概念\tMongoDB 术语/概念   解释/说明database\t    database\t       数据库table\t        collection\t       数据库表/集合row\t            document\t       数据记录行/文档column\t        field\t           数据字段/域index\t        index\t           索引table joins\t \t表连接,            MongoDB不支持primary key\t    primary key\t       主键,MongoDB自动将_id字段设置为主键\nsqlserverdocker run -d \\  --name sqlserver --user=root \\  -e &quot;ACCEPT_EULA=Y&quot; \\  -e &quot;SA_PASSWORD=Testing@123&quot;  -p 1433:1433  -v /data/sqlserver:/var/opt/mssql \\  --cap-add SYS_PTRACE mcr.microsoft.com/mssql/server:2019-latest  /opt/mssql-tools18/bin/sqlcmd -S localhost -U SA -P &quot;Testing@123&quot; -C  -- 数据库级  SELECT name, type_desc FROM sys.database_principals WHERE type IN (&#x27;S&#x27;, &#x27;U&#x27;, &#x27;G&#x27;);  select * from master.dbo.SysDatabases  --服务器级  SELECT name, type_desc FROM sys.server_principals WHERE type IN (&#x27;S&#x27;, &#x27;U&#x27;, &#x27;G&#x27;);  go  SELECT DB_NAME() AS [CurrentDatabase];  USE master; SELECT name FROM sys.schemas  USE master; SELECT name FROM sys.tables  SELECT name, USER_NAME(principal_id) FROM sys.schemas;CREATE TABLE Users (    UserID INT PRIMARY KEY IDENTITY(1,1),     UserName NVARCHAR(50) NOT NULL,   Email NVARCHAR(100) NOT NULL, RegistrationDate DATETIME DEFAULT GETDATE(), IsActive BIT DEFAULT 1);INSERT INTO Users (UserName, Email) VALUES     (&#x27;王五&#x27;, &#x27;wangwu@example.com&#x27;),    (&#x27;赵六&#x27;, &#x27;zhaoliu@example.com&#x27;),    (&#x27;孙七&#x27;, &#x27;sunqi@example.com&#x27;);--cdcuse y_testEXEC sys.sp_cdc_enable_db;go SELECT name AS [y_test],    is_cdc_enabled AS [CDCEnabled]FROM   sys.databases WHERE     name = DB_NAME(); \n","categories":["db"]},{"title":"部署本地大模型","url":"/2025/05/12/%E9%83%A8%E7%BD%B2%E6%9C%AC%E5%9C%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/","content":"模型框架\n\n企业级服务，SGLang 是不二之选：凭借卓越的性能，其吞吐量和结构化输出能力堪称行业翘楚，为企业级应用筑牢根基。https://docs.sglang.ai/start/install.htmlhttps://github.com/sgl-project/sglang\n在线高并发场景，VLLM 独占鳌头：凭借动态批处理和先进的内存管理技术，确保服务在高并发压力下依然稳定高效，保障业务流畅运行。https://docs.vllm.com.cn/en/latest/getting_started/installation/gpu.htmlhttps://github.com/vllm-project/vllm\n个人开发领域，Ollama 崭露头角：简单易用，跨平台支持搭配丰富的模型库，让创意灵感瞬间触手可及，助力个人开发者快速实现想法。https://github.com/ollama/ollama?tab=readme-ov-file\n\n\nLLM webui\n\nDify：适合企业开发复杂 AI 应用，如智能客服、合同处理系统等，支持多模型协作和业务流程自动化。https://dify.ai/zhhttps://github.com/langgenius/dify/blob/main/README_CN.md\nOpen-WebUI：适合个人开发者快速测试本地模型（如 Ollama 部署的 Llama3），或作为 ChatGPT 替代品进行日常交互。https://docs.openwebui.com/\nChatbox：面向非技术用户，提供无需代码的对话界面，支持快速体验多模型（如 GPT、Claude）的聊天能力。https://chatboxai.app/zhhttps://github.com/chatboxai/chatbox\n\n\n部署\n由于vllm和sglang需要资源较多，我们这里采用ollama + openwebui + deepseek\n前提条件服务器已经配置了驱动和cuda nvidia-smi（驱动命令）nvcc（cuda命令）\nhttps://www.nvidia.cn/drivers/lookup/ 显卡下载run脚本运行\nhttps://developer.nvidia.com/cuda-toolkit-archive cuda下载\n\n安装ollama#https://github.com/ollama/ollama/tree/main/docs#OLLAMA_MODELS 模型下载位置默认/usr/share/ollama/.ollama/models#OLLAMA_HOST 监控地址默认127.0.0.1curl -fsSL https://ollama.com/install.sh | shsed -i &#x27;/^Environment=&quot;PATH=/a Environment=&quot;OLLAMA_HOST=0.0.0.0&quot;&#x27; /etc/systemd/system/ollama.servicesystemctl daemon-reloadsystemctl restart ollama.serviceollama run deepseek-r1\n安装docker和nvidia-container-toolkit#添加Docker软件包源#添加Docker软件包源sudo wget -O /etc/yum.repos.d/docker-ce.repo http://mirrors.cloud.aliyuncs.com/docker-ce/linux/centos/docker-ce.reposudo sed -i &#x27;s|https://mirrors.aliyun.com|http://mirrors.cloud.aliyuncs.com|g&#x27; /etc/yum.repos.d/docker-ce.repo#安装Docker社区版本，容器运行时containerd.io，以及Docker构建和Compose插件sudo yum -y install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin#启动Dockersudo systemctl start docker#设置Docker守护进程在系统启动时自动启动sudo systemctl enable docker#配置生产存储库curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \\  sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo#安装 NVIDIA Container Toolkit 软件包sudo yum install -y nvidia-container-toolkit#重启dockersudo systemctl restart docker\n安装webui#可以通过-e OLLAMA_BASE_URL 配置ollama地址,进入web界面也可以配置,镜像差不多9G,在国外需要配置加速源docker run -d -p 3000:8080 --gpus all -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:cuda\n\n额外\ndify功能比Open-WebUI更强大，支持agent和工作流和很多插件，如果不想只单独通过webui来交互建议使用difycurl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composegit clone https://github.com/langgenius/dify.gitcd difycd dockercp .env.example .envdocker compose up -d\n\n","tags":["llm"]}]