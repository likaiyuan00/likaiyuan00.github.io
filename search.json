[{"title":"alertmanager","url":"/2025/04/27/alertmanager/","content":"安装curl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composeversion: &#x27;3&#x27;services:  alertmanager:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/alertmanager:v0.28.1    ports:      - &quot;9093:9093&quot;      - &quot;9094:9094&quot;    volumes:      - ./config:/etc/alertmanager      - alertmanager_data:/alertmanager    command:      - &#x27;--config.file=/etc/alertmanager/alertmanager.yml&#x27;      - &#x27;--storage.path=/alertmanager&#x27;      - &#x27;--cluster.advertise-address=alertmanager:9094&#x27;    networks:      - monitoring-netvolumes:  alertmanager_data:networks:  monitoring-net:    driver: bridge\n配置文件解读global: # 即为全局设置,在Alertmanager配置文件中,只要全局设置配置了的选项,全部为公共设置,可以让其他设置继承,作为默认值,可以子参数中覆盖其设置。  resolve_timeout: 1m # 用于设置处理超时时间,也是生命警报状态为解决的时间,这个时间会直接影响到警报恢复的通知时间,需要自行结合实际生产场景来设置主机的恢复时间,默认是5分钟。  # 整合邮件  smtp_smarthost: &#x27;smtp.qq.com:465&#x27; # 邮箱smtp服务器  smtp_from: &#x27;1451578387@qq.com&#x27; # 发件用的邮箱地址  smtp_auth_username: &#x27;1451578387@qq.com&#x27; # 发件人账号  smtp_auth_password: &#x27;dkuuifhdskaduasdsb&#x27; # 发件人邮箱密码  smtp_require_tls: false # 不进行tls验证route: # 路由分组  group_by: [&#x27;alertname&#x27;] # 报警分组  group_wait: 10s # 组内等待时间,同一分组内收到第一个告警等待多久开始发送,目标是为了同组消息同时发送,不占用告警信息,默认30s。  group_interval: 10s # 当组内已经发送过一个告警,组内若有新增告警需要等待的时间,默认为5m,这条要确定组内信息是影响同一业务才能设置,若分组不合理,可能导致告警延迟,造成影响。  repeat_interval: 1h # 告警已经发送,且无新增告警,若重复告警需要间隔多久,默认4h,属于重复告警,时间间隔应根据告警的严重程度来设置。  receiver: &#x27;webhook&#x27; # 告警的接收者,需要和 receivers[n].name 的值一致。  # 上面所有的属性都由所有子路由继承,并且可以在每个子路由上进行覆盖。  # 当报警信息中标签匹配到team:node时会使用email发送报警,否则使用webhook。 templates:- &#x27;/etc/alertmanager/config/*.tmpl&#x27;# route根路由,该模块用于该根路由下的节点及子路由routes的定义,子树节点如果不对相关配置进行配置,则默认会从父路由树继承该配置选项。每一条告警都要进入route,即要求配置选项group_by的值能够匹配到每一条告警的至少一个labelkey(即通过POST请求向altermanager服务接口所发送告警的labels项所携带的&lt;labelname&gt;),告警进入到route后,将会根据子路由routes节点中的配置项match_re或者match来确定能进入该子路由节点的告警(由在match_re或者match下配置的labelkey:labelvalue是否为告警labels的子集决定,是的话则会进入该子路由节点,否则不能接收进入该子路由节点)。route:  # 例如所有labelkey:labelvalue含cluster=A及altertname=LatencyHigh的labelkey的告警都会被归入单一组中  group_by: [&#x27;job&#x27;, &#x27;altername&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;,&#x27;severity&#x27;]  # 若一组新的告警产生,则会等group_wait后再发送通知,该功能主要用于当告警在很短时间内接连产生时,在group_wait内合并为单一的告警后再发送  group_wait: 30s  # 再次告警时间间隔  group_interval: 5m  # 如果一条告警通知已成功发送,且在间隔repeat_interval后,该告警仍然未被设置为resolved,则会再次发送该告警通知  repeat_interval: 12h  # 默认告警通知接收者,凡未被匹配进入各子路由节点的告警均被发送到此接收者  receiver: &#x27;wechat&#x27;  # 上述route的配置会被传递给子路由节点,子路由节点进行重新配置才会被覆盖  # 子路由树  routes:  # 该配置选项使用正则表达式来匹配告警的labels,以确定能否进入该子路由树  # match_re和match均用于匹配labelkey为service,labelvalue分别为指定值的告警,被匹配到的告警会将通知发送到对应的receiver  - match_re:      service: ^(foo1|foo2|baz)$    receiver: &#x27;wechat&#x27;    # 在带有service标签的告警同时有severity标签时,他可以有自己的子路由,同时具有severity != critical的告警则被发送给接收者team-ops-mails,对severity == critical的告警则被发送到对应的接收者即team-ops-pager    routes:    - match:        severity: critical      receiver: &#x27;wechat&#x27;  # 比如关于数据库服务的告警,如果子路由没有匹配到相应的owner标签,则都默认由team-DB-pager接收  - match:      service: database    receiver: &#x27;wechat&#x27;  # 我们也可以先根据标签service:database将数据库服务告警过滤出来,然后进一步将所有同时带labelkey为database  - match:      severity: critical    receiver: &#x27;wechat&#x27;# 抑制规则,当出现critical(关键的)告警时忽略warning。# 下面的这段配置是指如果出现标签为severity=critical的告警,则抑制severity=warning的告警inhibit_rules:- source_match:    severity: &#x27;critical&#x27;  target_match:    severity: &#x27;warning&#x27;  # 如果警报名称相同,则应用抑制。  # alertname、cluster和service对应的标签值需要相等  equal: [&#x27;alertname&#x27;, &#x27;cluster&#x27;, &#x27;service&#x27;]# 收件人配置receivers:- name: &#x27;team-ops-mails&#x27;  email_configs:  - to: &#x27;dukuan@xxx.com&#x27;- name: &#x27;team-X-pager&#x27;  email_configs:  - to: &#x27;team-X+alerts-critical@example.org&#x27;  pagerduty_configs:  - service_key: &lt;team-X-key&gt;- name: &#x27;team-Y-mails&#x27;  email_configs:  - to: &#x27;team-Y+alerts@example.org&#x27;- name: &#x27;webhook&#x27;  webhook_configs:  - url: http://127.0.0.1:8060/dingtalk/webhook1/send    send_resolved: true\n分组和路由\n\n路由match（精确匹配）match_re（正则表达式匹配）每一个告警都会从配置文件中顶级的route进入路由树，需要注意的是顶级的route必须匹配所有告警(即不能有任何的匹配设置match和match_re)，每一个路由都可以定义自己的接受人以及匹配规则。默认情况下，告警进入到顶级route后会遍历所有的子节点，直到找到最深的匹配route，并将告警发送到该route定义的receiver中。但如果route中设置continue的值为false，那么告警在匹配到第一个子节点之后就直接停止。如果continue为true，报警则会继续进行后续子节点的匹配。如果当前告警匹配不到任何的子节点，那该告警将会基于当前路由节点的接收器配置方式进行处理\n分组告警通知进行分组，将多条告警合合并为一个通知。这里我们可以使用group_by来定义分组规则。基于告警中包含的标签，如果满足group_by中定义标签名称，那么这些告警将会合并为一个通知发送给接收器。有的时候为了能够一次性收集和发送更多的相关信息时，可以通过group_wait参数设置等待时间，如果在等待时间内当前group接收到了新的告警，这些告警将会合并为一个通知向receiver发送\n\n\nroute:  group_by: [&#x27;alertname&#x27;,&#x27;team&#x27;]   #在这里添加team匹配的标签  group_wait: 5s  group_interval: 5s  repeat_interval: 5m  # 默认发给&quot;sre_system&quot;组用户  receiver: &#x27;sre_system&#x27;  continue: false  # 配置子路由  routes:    - receiver: &#x27;sre_dba&#x27;      match_re:        job: test      # 建议将continue的值设置为true，表示当前的条件是否匹配，都将继续向下匹配规则      # 这样做的目的是将消息发给最后的系统组(sre_system)      continue: true==================================================================#rule.yml- name: grafana  rules:  - alert: node           #这个相当于alertname的值,与之前匹配的相同    expr: up&#123;job=&quot;grafana&quot;&#125; == 0    for: 10s                      labels:                         severity: 1       job: test  # 对应上面的 match_re      team: grafana        #这里标签设置不同的一会用    annotations:                    summary: &quot;&#123;&#123; \\$labels.instance &#125;&#125; 已停止运行超过 15s&quot;      description: hello world alertname 等于 node 如果相同报警会一起发送team 等于 grafana \n抑制规则inhibit_rules:  - source_match:      severity: &#x27;告警&#x27;    target_match:      severity: &#x27;提示&#x27;    #equal: [&#x27;type&#x27;,&#x27;test&#x27;] 要求 type 和 test签均相同     equal: [&#x27;type&#x27;]type的值必须一样当匹配到 告警 时就会抑制提示的告警通知并检查他们是否来自于同个ssl（即ssl标签的值相同抑制才会生效）当子路由匹配到不同的 severity 时就会将消息发往不同的 receiver，当子路由无法匹配到时，消息会默认发往根路由的 receiver，因此，无论是否匹配到子路由规则，消息都会发往根路由的 receiver对应报警规则配置为groups:- name: node-alerts  rules:  - alert: HighNodeCPU    expr: (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) * 100 &gt; 80    for: 5m    labels:      severity: &quot;告警&quot;      type: ssl    annotations:      summary: &quot;高节点CPU使用率 (&#123;&#123; $labels.instance &#125;&#125;)&quot;      description: &quot;节点 &#123;&#123; $labels.instance &#125;&#125; CPU 使用率超过 80% 已持续 5 分钟&quot;- name: cluster-alerts  rules:  - alert: ClusterWideCPUProblem    expr: |      sum( (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) * 100 &gt; 80 )      /      count( (1 - avg(rate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by (instance)) )      * 100 &gt; 50    for: 10m    labels:      severity: &quot;提示&quot;      type: ssl    annotations:      summary: &quot;集群级CPU问题&quot;      description: &quot;超过 50% 的节点持续高CPU使用率达 10 分钟&quot;\n\nalertmanager集成三方告警\n原生alertmanager只有邮件和webhook告警；Alertmanager 的原生 Webhook 告警是一种通过 HTTP POST 请求将告警信息发送到自定义接口（Webhook 接收端）的机制；所以要对接需要开发者自行开发，这里推荐两个现成的工具来对接\n\nPrometheusAlert使用\nPrometheus Alert 是开源的运维告警中心消息转发系统，支持主流的监控系统 Prometheus，日志系统 Graylog 和数据可视化系统 Grafana 发出的预警消息。通知渠道支持钉钉、微信、华为云短信、腾讯云短信、腾讯云电话、阿里云短信、阿里云电话等等\n\nwget https://github.com/feiyu563/PrometheusAlert/releases/download/v4.8.1/linux.zipchmod +x PrometheusAlert启动 nohup ./PrometheusAlert &amp; 后台运行#alertmanager.yml配置集成PrometheusAlert；格式可以登录PrometheusAlert查看receivers:- name: &#x27;web.hook.prometheusalert&#x27;  webhook_configs:  - url: &#x27;http://192.168.197.142:8080/prometheusalert?type=wx&amp;tpl=prometheus-wx&amp;wxurl=https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=53fdb356-4446-42e5-b8bd-f7da63bcfe76&#x27;\n\nprometheus-webhook-dingtalk使用\nPrometheus 的Alertmanager自身不支持钉钉报警，需要通过插件的方式来达到报警条件\n\n安装wget https://github.com/timonwong/prometheus-webhook-dingtalk/releases/download/v2.1.0/prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gztar zxf prometheus-webhook-dingtalk-2.1.0.linux-amd64.tar.gz mv prometheus-webhook-dingtalk-2.1.0.linux-amd64 /usr/local/prometheus-webhook-dingtalkcat &gt; /usr/lib/systemd/system/webhook-dingtalk.service &lt;&lt; EOF[Unit]Description=prometheus-webhook-dingtalkDocumentation=https://github.com/timonwong/prometheus-webhook-dingtalkAfter=network.target[Service]User=rootGroup=rootExecStart=/usr/local/prometheus-webhook-dingtalk/prometheus-webhook-dingtalk  --config.file=/usr/local/prometheus-webhook-dingtalk/config.ymlExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failure[Install]WantedBy=multi-user.targetEOF#集成模版/usr/local/prometheus-webhook-dingtalk/config.ymltemplates:    - /usr/local/prometheus/webhook-dingtalk/template.tmpltargets:  webhook1:    url: https://oapi.dingtalk.com/robot/send?access_token=9ac4354ab7c8#alertmanager配置发送给dingtalk插件receivers:  - name: &#x27;email&#x27;    email_configs:      - to: &#x27;xxxxx@163.com&#x27; #指定发送给谁  - name: &#x27;webhook1&#x27;    webhook_configs:      - send_resolved: false        url: http://localhost:8060/dingtalk/webhook1/send\n\n报警内容模版vim /usr/local/prometheus/webhook-dingtalk/template.tmpl&#123;&#123; define &quot;__subject&quot; &#125;&#125;[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;]&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;__alert_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;---&#123;&#123; if .Labels.owner &#125;&#125;@&#123;&#123; .Labels.owner &#125;&#125;&#123;&#123; end &#125;&#125; **告警主题**: &#123;&#123; .Annotations.summary &#125;&#125;**告警类型**: &#123;&#123; .Labels.alertname &#125;&#125; **告警级别**: &#123;&#123; .Labels.severity &#125;&#125;  **告警主机**: &#123;&#123; .Labels.instance &#125;&#125;  **告警信息**: &#123;&#123; index .Annotations &quot;description&quot; &#125;&#125; **告警时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; &#123;&#123; define &quot;__resolved_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;---&#123;&#123; if .Labels.owner &#125;&#125;@&#123;&#123; .Labels.owner &#125;&#125;&#123;&#123; end &#125;&#125;**告警主题**: &#123;&#123; .Annotations.summary &#125;&#125;**告警类型**: &#123;&#123; .Labels.alertname &#125;&#125;  **告警级别**: &#123;&#123; .Labels.severity &#125;&#125; **告警主机**: &#123;&#123; .Labels.instance &#125;&#125; **告警信息**: &#123;&#123; index .Annotations &quot;description&quot; &#125;&#125; **告警时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125; **恢复时间**: &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.EndsAt) &quot;Asia/Shanghai&quot; &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;default.title&quot; &#125;&#125;&#123;&#123; template &quot;__subject&quot; . &#125;&#125;&#123;&#123; end &#125;&#125; &#123;&#123; define &quot;default.content&quot; &#125;&#125;&#123;&#123; if gt (len .Alerts.Firing) 0 &#125;&#125;**====侦测到&#123;&#123; .Alerts.Firing | len  &#125;&#125;个故障====**&#123;&#123; template &quot;__alert_list&quot; .Alerts.Firing &#125;&#125;---&#123;&#123; end &#125;&#125; &#123;&#123; if gt (len .Alerts.Resolved) 0 &#125;&#125;**====恢复&#123;&#123; .Alerts.Resolved | len  &#125;&#125;个故障====**&#123;&#123; template &quot;__resolved_list&quot; .Alerts.Resolved &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;  &#123;&#123; define &quot;ding.link.title&quot; &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; define &quot;ding.link.content&quot; &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;\n报警规则示例mkdir /usr/local/prometheus/prometheus/rulevim /usr/local/prometheus/prometheus/rule/node_exporter.ymlgroups:- name: 服务器资源监控  rules:  - alert: 内存使用率过高    expr: 100 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 &gt; 80    for: 3m     labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123; $labels.instance &#125;&#125; 内存使用率过高, 请尽快处理！&quot;      description: &quot;&#123;&#123; $labels.instance &#125;&#125;内存使用率超过80%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;            - alert: 服务器宕机    expr: up == 0    for: 1s    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 服务器宕机, 请尽快处理!&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 服务器延时超过3分钟,当前状态&#123;&#123; $value &#125;&#125;. &quot;   - alert: CPU高负荷    expr: 100 - (avg by (instance,job)(irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) * 100) &gt; 90    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; CPU使用率过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; CPU使用大于90%,当前使用率&#123;&#123; $value &#125;&#125;%. &quot;        - alert: 磁盘IO性能    expr: avg(irate(node_disk_io_time_seconds_total[1m])) by(instance,job)* 100 &gt; 90    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入磁盘IO使用率过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入磁盘IO大于90%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;    - alert: 网络流入    expr: ((sum(rate (node_network_receive_bytes_total&#123;device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*&#x27;&#125;[5m])) by (instance,job)) / 100) &gt; 102400    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入网络带宽过高，请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流入网络带宽持续5分钟高于100M. RX带宽使用量&#123;&#123;$value&#125;&#125;.&quot;   - alert: 网络流出    expr: ((sum(rate (node_network_transmit_bytes_total&#123;device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*&#x27;&#125;[5m])) by (instance,job)) / 100) &gt; 102400    for: 5m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; 流出网络带宽过高,请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 流出网络带宽持续5分钟高于100M. RX带宽使用量&#123;$value&#125;&#125;.&quot;    - alert: TCP连接数    expr: node_netstat_Tcp_CurrEstab &gt; 10000    for: 2m    labels:      severity: 严重告警    annotations:      summary: &quot; TCP_ESTABLISHED过高！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; TCP_ESTABLISHED大于100%,当前使用率&#123;&#123; $value &#125;&#125;%.&quot;   - alert: 磁盘容量    expr: 100-(node_filesystem_free_bytes&#123;fstype=~&quot;ext4|xfs&quot;&#125;/node_filesystem_size_bytes &#123;fstype=~&quot;ext4|xfs&quot;&#125;*100) &gt; 90    for: 1m    labels:      severity: 严重告警    annotations:      summary: &quot;&#123;&#123;$labels.mountpoint&#125;&#125; 磁盘分区使用率过高，请尽快处理！&quot;      description: &quot;&#123;&#123;$labels.instance&#125;&#125; 磁盘分区使用大于90%，当前使用率&#123;&#123; $value &#125;&#125;%.&quot;\n","categories":["prometheus"]},{"title":"elfk部署使用","url":"/2025/04/18/elfk/","content":"\nfilebeat不建议容器启动，适合放到每个节点采集日志统一发给logstash；如果全部输出到elasticsearch会导致负载比较高；不建议每个节点用logstash采集因为比较重，filebeat比较轻量级\n\n安装elfkcurl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composeyum install -y https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpmcat &gt;&gt; ./elk.yml &lt;&lt; EOFversion: &#x27;3.8&#x27;services:  elasticsearch:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/elasticsearch:7.14.0    container_name: elasticsearch    environment:      - discovery.type=single-node  # 单节点模式      - ES_JAVA_OPTS=-Xms512m -Xmx512m  # JVM 堆内存限制      - ELASTIC_PASSWORD=Ytest@123  # 设置 Elasticsearch 密码    volumes:      - ./elasticsearch/data:/usr/share/elasticsearch/data  # 数据持久化#      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml  # 自定义配置（可选）    ports:      - &quot;9200:9200&quot;  # REST API      - &quot;9300:9300&quot;  # 集群通信    networks:      - elk  logstash:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/logstash:7.14.0    container_name: logstash    volumes:      - ./logstash/config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf  # 自定义 Logstash 管道配置      - ./logstash/logs:/usr/share/logstash/logs  # 日志持久化    environment:      - LS_JAVA_OPTS=-Xms512m -Xmx512m  # JVM 堆内存限制    ports:      - &quot;5044:5044&quot;  # Beats 输入端口（如 Filebeat）      - &quot;5000:5000/tcp&quot;  # TCP 输入      - &quot;5000:5000/udp&quot;  # UDP 输入    depends_on:      - elasticsearch    networks:      - elk  kibana:    image: registry.cn-hangzhou.aliyuncs.com/lky-deploy/kibana:7.14.0    container_name: kibana    environment:      - I18N_LOCALE=zh-CN      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200  # 指向 Elasticsearch 服务      - ELASTICSEARCH_USERNAME=elastic  # 默认用户名      - ELASTICSEARCH_PASSWORD=Ytest@123  # 与 Elasticsearch 密码一致    ports:      - &quot;5601:5601&quot;  # Kibana Web 界面    depends_on:      - elasticsearch    networks:      - elknetworks:  elk:    driver: bridgeEOFmkdir ./logstash/config -pcat &gt;&gt; ./logstash/config/logstash.conf &lt;&lt; EOF# ./logstash/config/logstash.confinput &#123;  tcp &#123;    port =&gt; 5000  # 监听 TCP 日志  &#125;  beats &#123;    port =&gt; 5044  # 接收 Filebeat 输入  &#125;&#125;filter &#123;  grok &#123;    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;  # 解析 Apache 日志  &#125;  date &#123;    match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]  # 时间解析  &#125;&#125;output &#123;  elasticsearch &#123;    hosts =&gt; [&quot;elasticsearch:9200&quot;]    user =&gt; &quot;elastic&quot;    password =&gt; &quot;Ytest@123&quot;    index =&gt; &quot;logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引  &#125;&#125;EOFchmod 777 elasticsearch/data\nfilebeat根据不同tag写入不同的logstash后续分割和输出建立索引好区分\nfilebeat.inputs: # filebeat input输入- type: log    # 标准输入  enabled: true  # 启用标准输入  paths:    - /var/log/*  tags: [&quot;system&quot;]  #  fields:  #    type: &quot;system_log&quot;- type: filestream  paths:    - &quot;/var/log/nginx/*.log&quot;  tags: [&quot;nginx&quot;]   # 标记为 nginx 日志#output.console:# enabled: true               # 启用控制台输出  #  pretty: true                # 美化 JSON 格式  # codec.json:  #   pretty: true  # escape_html: false        # 不转义 HTML 符号（保持原始格式） # 输出到 Logstash - 用于生产数据处理output.logstash:  enabled: true               # 启用 Logstash 输出  #  when:  #    equals:  #      fields.type: &quot;system_log&quot;  hosts: [&quot;127.0.0.1:5044&quot;]  # Logstash 的地址和端口（支持多个主机负载均衡）  when.contains:      tags: &quot;system&quot;  # 匹配 tags 包含 &quot;system&quot;  hosts: [&quot;127.0.0.1:5045&quot;]  enabled: true  when.contains:    tags: &quot;nginx&quot;  # 匹配 tags 包含 &quot;nginx&quot;\nlogstash根据不同type进行过滤和输出索引\nLogstash Reference [7.10] | Elasticinput &#123;  tcp &#123;    port =&gt; 5000  # 监听 TCP 日志  &#125;  beats &#123;    port =&gt; 5044  # 接收 Filebeat 输入    type =&gt; &quot;system&quot;  &#125;  beats &#123;    port =&gt; 5045  # 接收 Filebeat 输入    type =&gt; &quot;nginx&quot;  &#125;&#125;   filter &#123;  date &#123;    match =&gt; [ &quot;timestamp&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot; ]  # 时间解析  &#125;   if[type] == &quot;nginx&quot; &#123;    grok &#123;      match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;HTTPD_COMMONLOG&#125;&quot; &#125;  # 解析 nginx 日志,如果不区分；system类型是解析不了的，会直接报错      remove_field =&gt; [&quot;@version&quot;]     &#125;  &#125;  #对于system类型可以再写个if来单独过滤  if[type] == &quot;system&quot; &#123;    grok &#123;      match =&gt;  &#123;&quot;message&quot; =&gt; &quot;%&#123;IPV4:ip&#125;&quot;&#125;        remove_field =&gt; [&quot;@version&quot;]     &#125;    mutate &#123;  #这里过滤器乱写的，需要根据自身的业务配置        remove_field =&gt; [&quot;timestamp&quot;]        gsub =&gt; [&quot;message&quot;,&quot;\\s&quot;,&quot;| &quot;]        split =&gt; [&quot;message&quot;,&quot;|&quot;]        replace =&gt; &#123; &quot;timenew&quot; =&gt;  &quot;%&#123;+yyyy-MM-dd&#125;&quot; &#125;        add_field =&gt; &#123;         &quot;year&quot; =&gt; &quot;%&#123;+yyyy&#125;&quot;         &quot;month&quot; =&gt; &quot;%&#123;+MM&#125;&quot;         &quot;day&quot; =&gt; &quot;%&#123;+dd&#125;&quot;         &quot;status&quot; =&gt; &quot;%&#123;[message][1]&#125;&quot;         &quot;code&quot; =&gt; &quot;%&#123;[message][2]&#125;&quot;        &#125;    &#125;  &#125;   &#125;#必须通过type指定不同输出创建不同的index =&gt;,否则index的字段不一样，当第一个index结构确定后，第二个输入无法输出到第一个index，因为字段不一样output &#123;  if &quot;system&quot; in [tags] &#123;    elasticsearch &#123;      hosts =&gt; [&quot;elasticsearch:9200&quot;]      user =&gt; &quot;elastic&quot;      password =&gt; &quot;Ytest@123&quot;      index =&gt; &quot;filebeat-system-logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引    &#125;  &#125;    if &quot;nginx&quot; in [tags] &#123;    elasticsearch &#123;      hosts =&gt; [&quot;elasticsearch:9200&quot;]      user =&gt; &quot;elastic&quot;      password =&gt; &quot;Ytest@123&quot;      index =&gt; &quot;filebeat-nginx-logs-%&#123;+YYYY.MM.dd&#125;&quot;  # 按日期创建索引    &#125;  &#125;  &#125;\nelasticsearch\n常用语法\n\n&#x2F;_cat &#x2F;_cat&#x2F;master?help&#x2F;_cat&#x2F;indices?v  显示title&#x2F;_cat&#x2F;indiceslogs-2025.03.24 为索引名称&#x2F;logs-2025.03.24&#x2F;_search 查看文档&#x2F;logs-2025.03.24&#x2F; 查看索引结构&#x2F;logs-2025.03.24&#x2F;_doc&#x2F;_search?q&#x3D;message:test\n\n\n","categories":["中间件"]},{"title":"iptables防止ddos(cc)","url":"/2025/04/21/iptables%E9%98%B2%E6%AD%A2ddos-cc/","content":"\n基本上发行版都是自带的，轻量级，不需要额外下载Fail2Ban也可以但是需要额外下载\n\n如何配置使用iptables -I INPUT -p tcp --dport 80 -m state --state NEW -m recent --set参数    作用-I INPUT    将规则插入到 INPUT 链的最前面-p tcp --dport 80    匹配目标端口为 80 的 TCP 流量-m state --state NEW    仅匹配 新建连接（如 TCP 的 SYN 包）-m recent --set    将来源 IP 记录到 recent 模块的默认列表（/proc/net/xt_recent/DEFAULT）iptables -I INPUT -p tcp --dport 80 -m state --state NEW -m recent --update --seconds 60 --hitcount 100 -j DROP参数    作用-m recent --update --seconds 60 --hitcount 100    检查 IP 在 60 秒内是否发起超过 100 次新连接-j DROP    若超限，直接丢弃数据包\n\n效果图，到指定次数自动丢弃数据包，端口不通，到达指定时间自动恢复\n经过测试 –hitcount 大于20 会报错\n解决办法echo options xt_recent ip_pkt_list_tot=200 &gt; /etc/modprobe.d/xt.confmodprobe -r xt_recent &amp;&amp; modprobe xt_recent 重新加载查看 lsmod |grep xt  ；cat /sys/module/xt_recent/parameters/ip_pkt_list_tot 对应 xt.conf\n额外补充若其他规则也使用 recent 默认列表，可能导致误判，可以通过–name 指定名称分类\niptables -I INPUT -p tcp –dport 80 -m state –state NEW -m recent –set –name HTTP_CC\niptables -I INPUT -p tcp –dport 80 -m state –state NEW -m recent –update –seconds 60 –hitcount 200 –name HTTP_CC -j DROP\n则 &#x2F;proc&#x2F;net&#x2F;xt_recent&#x2F;HTTP_CC 叫 HTTP_CC\n","categories":["linux"]},{"title":"miniconda3","url":"/2025/04/21/miniconda3/","content":"\nconda是一个包和环境管理工具，用于创建、管理和切换Python的虚拟环境\n\n安装mkdir -p ~/miniconda3wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.shbash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3rm ~/miniconda3/miniconda.shsource ~/miniconda3/bin/activate\n使用1. conda --version #查看conda版本，验证是否安装2. conda update conda #更新至最新版本，也会更新其它相关包3. conda update --all #更新所有包4. conda update package_name #更新指定的包5. conda create -n env_name package_name #创建名为env_name的新环境，并在该环境下安装名为package_name 的包，可以指定新环境的版本号，例如：conda create -n python2 python=python2.7 numpy pandas，创建了python2环境，python版本为2.7，同时还安装了numpy pandas包6. source activate env_name #切换至env_name环境7. source deactivate #退出环境8. conda info -e #显示所有已经创建的环境9. conda create --name new_env_name --clone old_env_name #复制old_env_name为new_env_name10. conda remove --name env_name –all #删除环境11. conda list #查看所有已经安装的包12. conda install package_name #在当前环境中安装包13. conda install --name env_name package_name #在指定环境中安装包14. conda remove -- name env_name package #删除指定环境中的包15. conda remove package #删除当前环境中的包16. conda env remove -n env_name #采用第10条的方法删除环境失败时，可采用这种方法\n\n\n\n两个环境，一个有request一个没有，隔离作用\n镜像源# 查看镜像源conda config --show-sources# 添加镜像源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main# 从镜像源中安装包时显示来源conda config --set show_channel_urls yes# 删除镜像源conda config --remove channels https://XXX# 删除配置的镜像源，使用默认镜像源conda config --remove-key channels\n\n打包运行环境pip install conda-packconda pack -n my_env_name -o out_name.tar.gztar -zxvf 2.7.tar.gz -C 2.7conda info -esource activate my_env_name\n\n","categories":["python"]},{"title":"openvpn","url":"/2025/04/21/openvpn/","content":"安装git clone https://github.com/likaiyuan00/openvpn-install.gitcd openvpn-install &amp;&amp; bash openvpn-install.sh#systemctl start openvpn@client.service 启动的账号密码  auth-user-pass 控制客户端密码验证echo &quot;test test@123&quot; &gt;  /etc/openvpn/userfile.sh\n\n配置文件字段解读server端在#openvpn服务端的监听地址local 0.0.0.0#openvpn服务端的监听端口（默认1194）port 1115#使用的协议，tcp/udpproto tcp#使用三层路由ip隧道（tun），还是二层以太网隧道（tap），一般使用tundev tun#ca证书、服务端证书、服务端秘钥和秘钥交换文件ca /etc/openvpn/server/ca.crtcert /etc/openvpn/server/server.crtkey /etc/openvpn/server/server.keydh /etc/openvpn/server/dh.pem#vpn服务端为自己和客户端分配的ip地址池。#服务端自己获取网段的第一个地址（此处是10.8.0.1），后为客户端分配其他的可用地址。以后客户端就可以和10.8.0.1进行通信。注意：以下网段地址不要和已有网段冲突或重复server 10.8.0.0  255.255.255.0#使用一个文件记录已分配虚拟ip的客户端和虚拟ip的对应关系。以后openvpn重启时，将可以按照此文件继续为对应的客户端分配此前相同的ip（自动续借ip）ifconfig-pool-persist ipp.txt#使用tap模式的时候考虑此选项server-bridge XXXXXX#vpn服务端向客户端推送vpn服务端内网网段的路由配置，以便让客户端能够找到服务端的内网。多条路由写多个push指令push &quot;route 10.0.10.0  255.255.255.0&quot;push &quot;route 192.168.10.0 255.255.255.0&quot;  #允许客户端访问的内网网段#让vpn客户端之间可以通信。默认情况客户端只能服务端进行通信#默认此项是注释的，客户端之间不能相互通信client-to-client#允许多个客户端使用同一个vpn账号连接服务端#默认是注释的，不支持多个客户端登录一个账号duplicate-cn#每10秒ping一次，120秒后没收到ping就说明对方挂了keepalive 10 120#加强认证方式，防攻击。如果配置文件中启用此项（默认是启用的），需要执行openvpn --genkey --secret ta.key，并把ta.key放到/etc/openvpn/server/目录，服务端第二个参数为0；同时客户端也要有此文件，且client.conf中此指令的第二个参数需要为1tls-auth /etc/openvpn/server/ta.key 0#选择一个密码。如果在服务器上使用了cipher选项，那么也必须在这里指定它。注意，v2.4客户端/服务端将在tls模式下自动协商AES-256-GCMcipher AES-256-CBC#openvpn 2.4版本的vpn才能设置此选项。表示服务端启用lz4的压缩功能 ，传输数据给客户端时会压缩数据包。Push后在客户端也配置启用lz4的压缩功能，向服务端发数据时也会压缩。如果是2.4版本以下的老版本，则使用用comp-lzo指令compress lz4-v2push &quot;compress lz4-v2&quot;#启用lzo数据压缩格式，此指令用于低于2.4版本的老版本，且如果服务端配置了该指令，客户端也必须要配置comp-lzo#并发客户端的连接数max-clients 1000#通过ping得知超时时，当重启vpn后将使用同一个秘钥文件以及保持tun连接状态persist-keypersist-tun#在文件中输出当前的连接信息，每分钟截断并重写一次该文件status openvpn-status.log#log指令表示每次启动vpn时覆盖式记录到指定日志文件中#log-append则表示每次启动vpn时追加式的记录到指定日志中#但两者只能选其一，或者不选时记录到rsyslog中log  /var/log/openvpn.loglog-append  /var/log/openvpn.log#日志记录的详细级别verb 3#当服务器重新启动时，通知客户端，以便它可以自动重新连接。仅在UDP协议是可用explicit-exit-notify 1#沉默的重复信息。最多20条相同消息类别的连续消息将输出到日志mute 20\nclient#标识这是个客户端client#使用的协议，tcp/udp，服务端是什么客户端就是什么proto tcp#使用三层路由ip隧道（tun），还是二层以太网隧道（tap），服务端是什么客户端就是什么dev tun#服务端的地址和端口remote 10.0.0.190 1194#一直尝试解析OpenVPN服务器的主机名resolv-retry infinite#大多数客户机不需要绑定到特定的本地端口号nobind#初始化后的降级特权(仅非windows)user nobodygroup nobody#尝试在重新启动时保留某些状态persist-keypersist-tun#ca证书、客户端证书、客户端密钥#如果它们和client.conf或client.ovpn在同一个目录下则可以不写绝对路径，否则需要写绝对路径调用ca ca.crtcert client.crtkey client.key#通过检查certicate是否具有正确的密钥使用设置来验证服务器证书。remote-cert-tls server#加强认证方式，防攻击。服务端有配置，则客户端必须有tls-auth ta.key 1#选择一个密码。如果在服务器上使用了cipher选项，那么您也必须在这里指定它。注意，v2.4客户端/服务器将在TLS模式下自动协商AES-256-GCM。cipher AES-256-CBC# 服务端用的什么，客户端就用的什么#表示客户端启用lz4的压缩功能，传输数据给客户端时会压缩数据包comp-lzo# 日志级别verb 3#沉默的重复信息。最多20条相同消息类别的连续消息将输出到日志mute 20\n\n如何直连openvpn服务端其他局域网服务器\n客户端（10.8.0.10） ping (服务端)172.16.1.7 正常 ping (服务端其他内网机器)172.16.1.8失败\n\n\n第一种方法 配置路由route add -net 10.8.0.0 netmask 255.255.255.0 gw 172.16.1.710.8.0.0  客户端IP172.16.1.7 openvpn 服务端IP\n\n\n\n\n\n\n\n第二种方法使用snat转发 iptables -t nat -A POSTROUTING -d 10.8.0.0&#x2F;24 -o eth0 -j MASQUERADEiptables -A FORWARD -s 10.8.0.0 -j ACCEPT\n\n\n\n额外服务端route 192.168.0.0 255.255.0.0   指令作用是在服务端加一条路由，网关是客户端ip\n服务端只能ping通客户端的tun0的ip，内网ip不行，即使加了路由也不行\n客户端push “route 192.168.10.0 255.255.255.0”作用是在客户端多加一条路由。网关是服务端的tun0IP（也就是server 指令配置分配的地址池）\n","categories":["linux"]},{"title":"prometheus","url":"/2025/04/18/prometheus/","content":"https://github.com/likaiyuan00/k8s-prometheus.git\nk8s-prometheus部署kubernetes_sd_configs配置文件只采集了\n\n1 prometheus*  prometheus-server2 container*   kubelet 的10250端口  &#x2F;metrics&#x2F;cadvisor3 node*    node_exporter4 apiserver*  apiserver 6443 端口 &#x2F;metrics5 kube*  kube-state-metrics组件 8080端口 &#x2F;metrics6 coredns*  kubernetes-pods 自动发现 pod需要配置 prometheus.io&#x2F;scrape: “true” 不然抓取不到 默认flaseprometheus.io&#x2F;path: “&#x2F;metrics”   # 指标路径（默认 &#x2F;metrics 可不写）7 kubelet*  apiserver代理端点 &#x2F;api&#x2F;v1&#x2F;nodes&#x2F;&lt;node-name&gt;&#x2F;proxy&#x2F;metrics其他有需要的可以自行配置\n\n导入镜像，执行yml文件即可\nprometheus效果图\ngrafana效果图\nkubelet 组件 kubelet 三个指标 &#x2F;metrics&#x2F;probes（探针） &#x2F;metrics&#x2F;cadvisor（pod） &#x2F;metrics（node）\n对应apiserver的 &#x2F;api&#x2F;v1&#x2F;nodes&#x2F;${node-name}&#x2F;proxy&#x2F;${url};一般为了减少apiserver的负载不建议使用这种方式 **\n直接访问会报401没有权限\n需要先获取token，上面文件执行完会有一个prometheus用户\npod内token路径为 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token\n通过token再去访问发现就正常了\n/metricscurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metricscurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics\n\n对应kubelet*开头\n/metrics/probes（探针）curl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metrics/probescurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics/probes\n\n/metrics/cadvisor（pod）curl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:6443/api/v1/nodes/master/proxy/metrics/cadvisorcurl -k -sS  -H &quot;Authorization: Bearer $TOKEN&quot;  https://127.0.0.1:10250/metrics/cadvisor\n\n对应container*开头，容器指标\nnode_exporter端口暴露到节点了就不需要token了\nnode*开头，节点指标\nkube-state-metrics集群应用状态监控比较重要的一个需要单独安装使用containerPort: 8080 暴露到节点了不需要token\nkube*开头\napiserver主要是监控apiserver的qps,查询成功率失败率等信息\napiserver*开头\nkubernetes-pods 自动发现如果元数据内设置true，该pod才可以被抓取，默认false\n以coredns为例\n以coredns*开头\n这个自动发现还可以配置自身业务的监控，只有保证开启抓取，和符合prometheus抓取规范就可以，如果开启了prometheus.io&#x2F;scrape 但是pod并没有提供数据指标的能力就会直接报错，如图404\n比如现在我想加一个grafana的数据，只需要添加对应元数据就可以了\nprometheus就自动发现了pod的ip\ngrafana*开头\n","categories":["prometheus"],"tags":["prometheus"]},{"title":"screen","url":"/2025/04/27/screen/","content":"多终端管理神器ctrl +a + d 退出终端exit 退出加销毁终端\n常用参数$&gt; screen [-AmRvx -ls -wipe][-d &lt;作业名称&gt;][-h &lt;行数&gt;][-r &lt;作业名称&gt;][-s ][-S &lt;作业名称&gt;] -A 　将所有的视窗都调整为目前终端机的大小。-d   &lt;作业名称&gt; 　将指定的screen作业离线。-h   &lt;行数&gt; 　指定视窗的缓冲区行数。-m 　即使目前已在作业中的screen作业，仍强制建立新的screen作业。-r   &lt;作业名称&gt; 　恢复离线的screen作业。-R 　先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。-s 　指定建立新视窗时，所要执行的shell。-S   &lt;作业名称&gt; 　指定screen作业的名称。-v 　显示版本信息。-x 　恢复之前离线的screen作业。-ls或--list 　显示目前所有的screen作业。-wipe 　检查目前所有的screen作业，并删除已经无法使用的screen作业。screen -S yourname -&gt; 新建一个叫yourname的sessionscreen -ls         -&gt; 列出当前所有的sessionscreen -r yourname -&gt; 回到yourname这个sessionscreen -d yourname -&gt; 远程detach某个sessionscreen -d -r yourname -&gt; 结束当前session并回到yourname这个session\n常用快捷键C-a ? -&gt; 显示所有键绑定信息C-a c -&gt; 创建一个新的运行shell的窗口并切换到该窗口C-a n -&gt; Next，切换到下一个 window C-a p -&gt; Previous，切换到前一个 window C-a 0..9 -&gt; 切换到第 0..9 个 windowCtrl+a [Space] -&gt; 由视窗0循序切换到视窗9C-a C-a -&gt; 在两个最近使用的 window 间切换 C-a x -&gt; 锁住当前的 window，需用用户密码解锁C-a d -&gt; detach，暂时离开当前session，将目前的 screen session (可能含有多个 windows) 丢到后台执行，并会回到还没进 screen 时的状态，此时在 screen session 里，每个 window 内运行的 process (无论是前台/后台)都在继续执行，即使 logout 也不影响。 C-a z -&gt; 把当前session放到后台执行，用 shell 的 fg 命令则可回去。C-a w -&gt; 显示所有窗口列表C-a t -&gt; time，显示当前时间，和系统的 load C-a k -&gt; kill window，强行关闭当前的 windowC-a [ -&gt; 进入 copy mode，在 copy mode 下可以回滚、搜索、复制就像用使用 vi 一样    C-b Backward，PageUp     C-f Forward，PageDown     H(大写) High，将光标移至左上角     L Low，将光标移至左下角     0 移到行首     $ 行末     w forward one word，以字为单位往前移     b backward one word，以字为单位往后移     Space 第一次按为标记区起点，第二次按为终点     Esc 结束 copy mode C-a ] -&gt; paste，把刚刚在 copy mode 选定的内容贴上\n","categories":["linux"]},{"title":"websocket","url":"/2025/05/28/websocket/","content":"异步因为websocket会使用到异步操作先了解一下异步\nimport asyncioimport timeasync def task(name, duration):    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 开始&quot;)    await asyncio.sleep(duration)  # 模拟并发等待    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 完成&quot;)def task_(name, duration):    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 开始&quot;)    time.sleep(duration)  # 模拟耗时操作    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 任务 &#123;name&#125; 完成&quot;)async def main():    start_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 异步任务开始&quot;)    await asyncio.gather(        task(&quot;A&quot;, 2),        task(&quot;B&quot;, 3),        task(&quot;C&quot;, 1)    )    end_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 异步任务总耗时: &#123;end_time - start_time:.2f&#125; 秒&quot;)def main_():    start_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 同步任务开始&quot;)    task_(&quot;A&quot;, 2)    task_(&quot;B&quot;, 3)    task_(&quot;C&quot;, 1)    end_time = time.time()    print(f&quot;[&#123;time.strftime(&#x27;%H:%M:%S&#x27;)&#125;] 同步任务总耗时: &#123;end_time - start_time:.2f&#125; 秒&quot;)if __name__ == &quot;__main__&quot;:    print(&quot;======================异步==========================&quot;)    asyncio.run(main())    print(&quot;======================同步==========================&quot;)    main_()#结果可以看出异步不需要等待会直接执行下一步操作，任务完成可以使用await来回调处理完成结果======================异步==========================[14:45:43] 异步任务开始[14:45:43] 任务 A 开始[14:45:43] 任务 B 开始[14:45:43] 任务 C 开始[14:45:44] 任务 C 完成[14:45:45] 任务 A 完成[14:45:46] 任务 B 完成[14:45:46] 异步任务总耗时: 3.00 秒======================同步==========================[14:45:46] 同步任务开始[14:45:46] 任务 A 开始[14:45:48] 任务 A 完成[14:45:48] 任务 B 开始[14:45:51] 任务 B 完成[14:45:51] 任务 C 开始[14:45:52] 任务 C 完成[14:45:52] 同步任务总耗时: 6.00 秒\nwebsocket服务端import asyncioimport websockets#https://websockets.readthedocs.io/en/stable/# 处理客户端连接async def handle_client(websocket):    async for message in websocket:        print(f&quot;收到客户端消息: &#123;message&#125;&quot;)        reply = f&quot;机器人回复：你说的是 &#x27;&#123;message&#125;&#x27; 对吗？&quot;        await websocket.send(reply)# async def main_logic(websocket, path):#    # await check_permit(websocket)##     await handle_client(websocket)# 启动服务器async def main():    async with websockets.serve(handle_client, &quot;localhost&quot;, 8765):        print(&quot;WebSocket 服务器已启动，端口 8765&quot;)        await asyncio.Future()  # 永久运行asyncio.run(main())\n\n\n\n客户端import asyncioimport websocketsasync def client():    async with websockets.connect(&quot;ws://localhost:8765&quot;) as websocket:        while True:            message = input(&quot;请输入消息（输入 q 退出）: &quot;)            if message == &#x27;q&#x27;:                break            await websocket.send(message)            response = await websocket.recv()            print(f&quot;收到回复: &#123;response&#125;&quot;)asyncio.run(client())#效果，相当于打开了一个通道双方都可以发消息WebSocket 服务器已启动，端口 8765请输入消息（输入 q 退出）: hello websockets收到回复: 机器人回复：你说的是 &#x27;hello websockets&#x27; 对吗？请输入消息（输入 q 退出）: \n额外fastapi框架使用websocketfrom fastapi import FastAPI, WebSocket, WebSocketDisconnectfrom fastapi.responses import HTMLResponsefrom fastapi.middleware.cors import CORSMiddlewareimport jsonapp = FastAPI()# 配置CORS跨域app.add_middleware(    CORSMiddleware,    allow_origins=[&quot;*&quot;],    allow_credentials=True,    allow_methods=[&quot;*&quot;],    allow_headers=[&quot;*&quot;],)# HTML页面（修改了前端WebSocket实现）HTML_TEMPLATE = &#x27;&#x27;&#x27;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;FastAPI 聊天&lt;/title&gt;    &lt;style&gt;        body &#123; max-width: 800px; margin: 20px auto; padding: 20px; &#125;        #output &#123;             height: 300px;             border: 1px solid #ccc;             overflow-y: auto;             padding: 10px;             margin-bottom: 10px;        &#125;        #input &#123;             width: 80%;             padding: 8px;            margin-right: 10px;        &#125;        button &#123;            padding: 8px 16px;            background: #007bff;            color: white;            border: none;            border-radius: 4px;            cursor: pointer;        &#125;        button:hover &#123;            opacity: 0.8;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;output&quot;&gt;&lt;/div&gt;    &lt;input type=&quot;text&quot; id=&quot;input&quot; placeholder=&quot;输入消息...&quot;&gt;    &lt;button onclick=&quot;sendMessage()&quot;&gt;发送&lt;/button&gt;    &lt;script&gt;        // 初始化WebSocket连接        const socket = new WebSocket(`ws://$&#123;window.location.host&#125;/ws`);        // 连接成功回调        socket.onopen = () =&gt; &#123;            addMessage(&#x27;系统&#x27;, &#x27;已连接到服务器&#x27;);        &#125;;        // 接收消息处理        socket.onmessage = (event) =&gt; &#123;            const data = JSON.parse(event.data);            addMessage(&#x27;机器人&#x27;, data.message);        &#125;;        // 错误处理        socket.onerror = (error) =&gt; &#123;            addMessage(&#x27;系统&#x27;, `连接错误: $&#123;error.message&#125;`);        &#125;;        // 关闭连接处理        socket.onclose = () =&gt; &#123;            addMessage(&#x27;系统&#x27;, &#x27;连接已断开&#x27;);        &#125;;        // 发送消息        function sendMessage() &#123;            const input = document.getElementById(&#x27;input&#x27;);            const message = input.value.trim();            if (message) &#123;                socket.send(JSON.stringify(&#123;                    type: &quot;user_message&quot;,                    content: message                &#125;));                addMessage(&#x27;我&#x27;, message);                input.value = &#x27;&#x27;;            &#125;        &#125;        // 添加消息到界面        function addMessage(sender, content) &#123;            const output = document.getElementById(&#x27;output&#x27;);            const div = document.createElement(&#x27;div&#x27;);            div.innerHTML = `&lt;strong&gt;$&#123;sender&#125;:&lt;/strong&gt; $&#123;content&#125;`;            output.appendChild(div);            // 自动滚动到底部            output.scrollTop = output.scrollHeight;        &#125;    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&#x27;&#x27;&#x27;@app.get(&quot;/&quot;)async def index():    return HTMLResponse(HTML_TEMPLATE)# WebSocket端点@app.websocket(&quot;/ws&quot;)async def websocket_endpoint(websocket: WebSocket):    await websocket.accept()    try:        while True:            # 接收客户端消息            data = await websocket.receive_text()            message_data = json.loads(data)            # 处理客户端消息            if message_data[&#x27;type&#x27;] == &#x27;user_message&#x27;:                print(f&quot;收到客户端消息: &#123;message_data[&#x27;content&#x27;]&#125;&quot;)                # 构造回复消息                reply = &#123;                    &quot;type&quot;: &quot;server_response&quot;,                    &quot;message&quot;: f&quot;机器人回复：你说的是 &#x27;&#123;message_data[&#x27;content&#x27;]&#125;&#x27; 对吗？&quot;                &#125;                # 发送回复                await websocket.send_json(reply)    except WebSocketDisconnect:        print(&quot;客户端断开连接&quot;)    except Exception as e:        print(f&quot;发生错误: &#123;str(e)&#125;&quot;)if __name__ == &quot;__main__&quot;:    import uvicorn    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8001)\nflask使用websocketimport eventleteventlet.monkey_patch()  # 关键：启用异步支持from flask import Flask, render_template_string#pip install flask-socketio eventletfrom flask_socketio import SocketIO, emitapp = Flask(__name__)app.config[&#x27;SECRET_KEY&#x27;] = &#x27;secret!&#x27;socketio = SocketIO(app, cors_allowed_origins=&quot;*&quot;)  # 允许跨域@app.route(&#x27;/&#x27;)def index():    return render_template_string(&#x27;&#x27;&#x27;    &lt;!DOCTYPE html&gt;    &lt;html&gt;    &lt;head&gt;        &lt;title&gt;Socket.IO 聊天&lt;/title&gt;        &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.7.2/socket.io.js&quot;&gt;&lt;/script&gt;        &lt;style&gt;            /* 保持原有样式不变 */            body &#123; max-width: 800px; margin: 20px auto; padding: 20px; &#125;            #output &#123; height: 300px; border: 1px solid #ccc; overflow-y: auto; padding: 10px; &#125;        &lt;/style&gt;    &lt;/head&gt;    &lt;body&gt;        &lt;div id=&quot;output&quot;&gt;&lt;/div&gt;        &lt;input id=&quot;input&quot; placeholder=&quot;输入消息&quot;&gt;        &lt;button onclick=&quot;send()&quot;&gt;发送&lt;/button&gt;        &lt;script&gt;            const socket = io();  // 自动连接当前域名            // 连接成功回调            socket.on(&#x27;connect&#x27;, () =&gt; &#123;                addMessage(&#x27;系统&#x27;, &#x27;已连接到服务器&#x27;);            &#125;);            // 接收服务器消息            socket.on(&#x27;server_response&#x27;, (data) =&gt; &#123;                addMessage(&#x27;机器人&#x27;, data.message);            &#125;);            // 发送消息            function send() &#123;                const input = document.getElementById(&#x27;input&#x27;);                const message = input.value.trim();                if (message) &#123;                    socket.emit(&#x27;client_message&#x27;, message);                    addMessage(&#x27;我&#x27;, message);                    input.value = &#x27;&#x27;;                &#125;            &#125;            // 添加消息到界面            function addMessage(sender, content) &#123;                const div = document.createElement(&#x27;div&#x27;);                div.innerHTML = `&lt;strong&gt;$&#123;sender&#125;:&lt;/strong&gt; $&#123;content&#125;`;                document.getElementById(&#x27;output&#x27;).appendChild(div);                // 自动滚动到底部                const output = document.getElementById(&#x27;output&#x27;);                output.scrollTop = output.scrollHeight;            &#125;        &lt;/script&gt;    &lt;/body&gt;    &lt;/html&gt;    &#x27;&#x27;&#x27;)# Socket.IO 事件处理@socketio.on(&#x27;client_message&#x27;)def handle_message(message):    print(f&#x27;收到客户端消息: &#123;message&#125;&#x27;)    # 构造回复消息    reply = f&quot;机器人回复：你说的是 &#x27;&#123;message&#125;&#x27; 对吗？&quot;    # 发送消息给客户端    emit(&#x27;server_response&#x27;, &#123;&#x27;message&#x27;: reply&#125;)if __name__ == &#x27;__main__&#x27;:    socketio.run(app, host=&#x27;0.0.0.0&#x27;, port=8000, debug=True)\n大模型使用websocket聊天# main.pyfrom fastapi import FastAPI, WebSocketfrom fastapi.responses import HTMLResponseimport requestsimport jsonapp = FastAPI()# 存储对话历史 (生产环境建议使用数据库)conversation_history = []# 集成前端页面与后端逻辑HTML_TEMPLATE = &quot;&quot;&quot;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;AI 对话助手&lt;/title&gt;    &lt;style&gt;        body &#123;            max-width: 800px;            margin: 0 auto;            padding: 20px;            font-family: Arial, sans-serif;        &#125;        #chatContainer &#123;            height: 60vh;            border: 1px solid #ddd;            border-radius: 8px;            overflow-y: auto;            padding: 15px;            margin-bottom: 15px;            background: #f9f9f9;        &#125;        .message &#123;            margin: 10px 0;            padding: 12px;            border-radius: 15px;            max-width: 80%;            word-wrap: break-word;        &#125;        .user-message &#123;            background: #e3f2fd;            margin-left: auto;            border-bottom-right-radius: 5px;        &#125;        .bot-message &#123;            background: #fff;            border: 1px solid #eee;            margin-right: auto;            border-bottom-left-radius: 5px;        &#125;        #inputContainer &#123;            display: flex;            gap: 10px;        &#125;        #userInput &#123;            flex: 1;            padding: 12px;            border: 1px solid #ddd;            border-radius: 25px;            outline: none;        &#125;        button &#123;            padding: 12px 25px;            background: #007bff;            color: white;            border: none;            border-radius: 25px;            cursor: pointer;            transition: background 0.3s;        &#125;        button:hover &#123;            background: #0056b3;        &#125;        .status &#123;            color: #666;            text-align: center;            padding: 10px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;AI 对话助手&lt;/h1&gt;    &lt;div id=&quot;chatContainer&quot;&gt;&lt;/div&gt;    &lt;div id=&quot;inputContainer&quot;&gt;        &lt;input type=&quot;text&quot; id=&quot;userInput&quot; placeholder=&quot;输入消息...&quot; /&gt;        &lt;button onclick=&quot;sendMessage()&quot;&gt;发送&lt;/button&gt;    &lt;/div&gt;    &lt;div class=&quot;status&quot; id=&quot;status&quot;&gt;连接状态：正常&lt;/div&gt;       // &lt;iframe   //      src=&quot;http://47.237.81.149/chatbot/9h9nyQcblGTesiGJ&quot;    //     style=&quot;width: 100%; height: 100%; min-height: 700px&quot;   //      frameborder=&quot;0&quot;  //       allow=&quot;microphone&quot;&gt;   // &lt;/iframe&gt;    &lt;script&gt;        const ws = new WebSocket(&#x27;ws://&#x27; + window.location.host + &#x27;/ws&#x27;);        const chatContainer = document.getElementById(&#x27;chatContainer&#x27;);        let isBotResponding = false;        // WebSocket 事件处理        ws.onopen = () =&gt; updateStatus(&#x27;已连接&#x27;);        ws.onclose = () =&gt; updateStatus(&#x27;连接已断开&#x27;);        ws.onerror = () =&gt; updateStatus(&#x27;连接错误&#x27;);        ws.onmessage = (event) =&gt; &#123;            const data = JSON.parse(event.data);            handleResponse(data);        &#125;;        function handleResponse(data) &#123;            switch(data.type) &#123;                case &#x27;user_message&#x27;:                    appendMessage(data.content, &#x27;user&#x27;);                    break;                case &#x27;assistant_start&#x27;:                    isBotResponding = true;                    appendMessage(&#x27;&#x27;, &#x27;bot&#x27;);                    break;                case &#x27;assistant_chunk&#x27;:                    appendChunk(data.content);                    break;                case &#x27;assistant_end&#x27;:                    isBotResponding = false;                    break;                case &#x27;error&#x27;:                    appendMessage(`错误：$&#123;data.content&#125;`, &#x27;error&#x27;);                    break;            &#125;        &#125;        function appendMessage(content, role) &#123;            const div = document.createElement(&#x27;div&#x27;);            div.className = `message $&#123;role&#125;-message`;            div.textContent = content;            chatContainer.appendChild(div);            scrollToBottom();        &#125;        function appendChunk(content) &#123;            const messages = document.getElementsByClassName(&#x27;bot-message&#x27;);            const lastMsg = messages[messages.length - 1];            lastMsg.textContent += content;            scrollToBottom();        &#125;        function scrollToBottom() &#123;            chatContainer.scrollTop = chatContainer.scrollHeight;        &#125;        function updateStatus(text) &#123;            document.getElementById(&#x27;status&#x27;).textContent = `状态：$&#123;text&#125;`;        &#125;        function sendMessage() &#123;            const input = document.getElementById(&#x27;userInput&#x27;);            const message = input.value.trim();            if (message &amp;&amp; !isBotResponding) &#123;                ws.send(message);                input.value = &#x27;&#x27;;            &#125;        &#125;        // 支持回车发送        document.getElementById(&#x27;userInput&#x27;).addEventListener(&#x27;keypress&#x27;, (e) =&gt; &#123;            if (e.key === &#x27;Enter&#x27;) sendMessage();        &#125;);    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot;@app.get(&quot;/&quot;)async def get():    return HTMLResponse(HTML_TEMPLATE)@app.websocket(&quot;/ws&quot;)async def websocket_endpoint(websocket: WebSocket):    await websocket.accept()    try:        while True:            # 接收用户消息            user_message = await websocket.receive_text()            # 更新对话历史            conversation_history.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_message&#125;)            # 发送用户消息到前端            await websocket.send_json(&#123;                &quot;type&quot;: &quot;user_message&quot;,                &quot;content&quot;: user_message            &#125;)            # 准备流式请求            await websocket.send_json(&#123;&quot;type&quot;: &quot;assistant_start&quot;&#125;)            # 构造请求数据            request_data = &#123;                &quot;model&quot;: &quot;deepseek-r1:latest&quot;,                &quot;messages&quot;: conversation_history,                &quot;stream&quot;: True            &#125;            # 流式获取响应            full_response = []            with requests.post(                    &quot;http://1.1.1.1:11434/api/chat&quot;,#大模型接口地址                    json=request_data,                    stream=True            ) as response:                response.raise_for_status()                for line in response.iter_lines():                    if line:                        chunk = json.loads(line.decode(&#x27;utf-8&#x27;))                        if &#x27;message&#x27; in chunk:                            content = chunk[&#x27;message&#x27;][&#x27;content&#x27;]                            full_response.append(content)                            await websocket.send_json(&#123;                                &quot;type&quot;: &quot;assistant_chunk&quot;,                                &quot;content&quot;: content                            &#125;)            # 保存完整响应            conversation_history.append(&#123;                &quot;role&quot;: &quot;assistant&quot;,                &quot;content&quot;: &quot;&quot;.join(full_response)            &#125;)            await websocket.send_json(&#123;&quot;type&quot;: &quot;assistant_end&quot;&#125;)    except Exception as e:        await websocket.send_json(&#123;            &quot;type&quot;: &quot;error&quot;,            &quot;content&quot;: f&quot;系统错误: &#123;str(e)&#125;&quot;        &#125;)    finally:        await websocket.close()if __name__ == &quot;__main__&quot;:    import uvicorn    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)","tags":["websocket"]},{"title":"使用kubekey快速安装k8s","url":"/2025/04/27/%E4%BD%BF%E7%94%A8kubekey%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85k8s/","content":"官方地址https://github.com/kubesphere/kubekey\n安装\ncurl -sfL https://get-kk.kubesphere.io | sh -\n\n单节点测试使用kk create cluster#默认 v1.23.17--with-kubernetes v1.24.1 #默认docker--container-manager containerd#如果不使用--with-kubesphere默认不安装；默认版本为 v3.4.1--with-kubesphere\n多节点kk create config -f deploy.yml#-f 指定配置文件开始安装kk create cluster -f deploy.yml#deploy.yml;其他节点的ip用户名密码的修改成实际的apiVersion: kubekey.kubesphere.io/v1alpha2kind: Clustermetadata:  name: samplespec:  hosts:  - &#123;name: node1, address: 172.16.0.2, internalAddress: 172.16.0.2, user: ubuntu, password: &quot;Qcloud@123&quot;&#125;  - &#123;name: node2, address: 172.16.0.3, internalAddress: 172.16.0.3, user: ubuntu, password: &quot;Qcloud@123&quot;&#125;  roleGroups:    etcd:    - node1    control-plane:     - node1    worker:    - node1    - node2  controlPlaneEndpoint:    ## Internal loadbalancer for apiservers     # internalLoadbalancer: haproxy    domain: lb.kubesphere.local    address: &quot;&quot;    port: 6443  kubernetes:    version: v1.23.17    clusterName: cluster.local    autoRenewCerts: true    containerManager: docker  etcd:    type: kubekey  network:    plugin: calico    kubePodsCIDR: 10.233.64.0/18    kubeServiceCIDR: 10.233.0.0/18    ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni    multusCNI:      enabled: false  registry:    privateRegistry: &quot;&quot;    namespaceOverride: &quot;&quot;    registryMirrors: []    insecureRegistries: []  addons: []----------------------------------------------------#默认不安装kubesphere需要指定--with-kubespherekk create config --with-kubesphere -f deploy-with.yml\n新增删除#新增节点接入集群kk add nodes -f  deploy.yml#删除节点kk delete node &lt;nodeName&gt; -f deploy.yml#删除集群kk delete cluster [-f deploy.yml]\n\n升级集群使用指定版本升级集群。kk upgrade [--with-kubernetes version] [--with-kubesphere version] 仅支持升级 Kubernetes。仅支持升级 KubeSphere。支持升级 Kubernetes 和 KubeSphere。多节点使用指定的配置文件升级集群。kk upgrade [--with-kubernetes version] [--with-kubesphere version] [(-f | --filename) path]如果指定了--with-kubernetes或--with-kubesphere，配置文件也将被更新。用于-f指定为集群创建而生成的配置文件。\n\n更新集群证书\n#默认一年kk  certs renew\n\n","categories":["k8s"]},{"title":"使用maven打包","url":"/2025/05/12/%E4%BD%BF%E7%94%A8maven%E6%89%93%E5%8C%85/","content":"使用springboot&lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.5.9&lt;/version&gt;        &lt;relativePath/&gt;    &lt;/parent&gt;    &lt;groupId&gt;org.ecs&lt;/groupId&gt;    &lt;artifactId&gt;springboot01&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n其他&lt;groupId&gt;org.example&lt;/groupId&gt;    &lt;artifactId&gt;CpuLoad&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                &lt;version&gt;3.1.0&lt;/version&gt;                &lt;configuration&gt;                    &lt;archive&gt;                        &lt;manifest&gt;                            &lt;!-- 指定入口函数 --&gt;                             \t\t\t    &lt;mainClass&gt;org.example.CpuLoad&lt;/mainClass&gt;                            &lt;!-- 是否添加依赖的jar路径配置 --&gt;                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;                            &lt;!-- 依赖的jar包存放未知，和生成的jar放在同一级目录下 --&gt;                            &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;                        &lt;/manifest&gt;                    &lt;/archive&gt;                    &lt;!-- 不打包com.yh.excludes下面的所有类 --&gt;                    &lt;excludes&gt;com/xx/excludes/*&lt;/excludes&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n","tags":["maven"]},{"title":"部署本地大模型","url":"/2025/05/12/%E9%83%A8%E7%BD%B2%E6%9C%AC%E5%9C%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/","content":"模型框架\n\n企业级服务，SGLang 是不二之选：凭借卓越的性能，其吞吐量和结构化输出能力堪称行业翘楚，为企业级应用筑牢根基。https://docs.sglang.ai/start/install.htmlhttps://github.com/sgl-project/sglang\n在线高并发场景，VLLM 独占鳌头：凭借动态批处理和先进的内存管理技术，确保服务在高并发压力下依然稳定高效，保障业务流畅运行。https://docs.vllm.com.cn/en/latest/getting_started/installation/gpu.htmlhttps://github.com/vllm-project/vllm\n个人开发领域，Ollama 崭露头角：简单易用，跨平台支持搭配丰富的模型库，让创意灵感瞬间触手可及，助力个人开发者快速实现想法。https://github.com/ollama/ollama?tab=readme-ov-file\n\n\nLLM webui\n\nDify：适合企业开发复杂 AI 应用，如智能客服、合同处理系统等，支持多模型协作和业务流程自动化。https://dify.ai/zhhttps://github.com/langgenius/dify/blob/main/README_CN.md\nOpen-WebUI：适合个人开发者快速测试本地模型（如 Ollama 部署的 Llama3），或作为 ChatGPT 替代品进行日常交互。https://docs.openwebui.com/\nChatbox：面向非技术用户，提供无需代码的对话界面，支持快速体验多模型（如 GPT、Claude）的聊天能力。https://chatboxai.app/zhhttps://github.com/chatboxai/chatbox\n\n\n部署\n由于vllm和sglang需要资源较多，我们这里采用ollama + openwebui + deepseek\n前提条件服务器已经配置了驱动和cuda nvidia-smi（驱动命令）nvcc（cuda命令）\nhttps://www.nvidia.cn/drivers/lookup/ 显卡下载run脚本运行\nhttps://developer.nvidia.com/cuda-toolkit-archive cuda下载\n\n安装ollama#https://github.com/ollama/ollama/tree/main/docs#OLLAMA_MODELS 模型下载位置默认/usr/share/ollama/.ollama/models#OLLAMA_HOST 监控地址默认127.0.0.1curl -fsSL https://ollama.com/install.sh | shsed -i &#x27;/^Environment=&quot;PATH=/a Environment=&quot;OLLAMA_HOST=0.0.0.0&quot;&#x27; /etc/systemd/system/ollama.servicesystemctl daemon-reloadsystemctl restart ollama.serviceollama run deepseek-r1\n安装docker和nvidia-container-toolkit#添加Docker软件包源#添加Docker软件包源sudo wget -O /etc/yum.repos.d/docker-ce.repo http://mirrors.cloud.aliyuncs.com/docker-ce/linux/centos/docker-ce.reposudo sed -i &#x27;s|https://mirrors.aliyun.com|http://mirrors.cloud.aliyuncs.com|g&#x27; /etc/yum.repos.d/docker-ce.repo#安装Docker社区版本，容器运行时containerd.io，以及Docker构建和Compose插件sudo yum -y install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin#启动Dockersudo systemctl start docker#设置Docker守护进程在系统启动时自动启动sudo systemctl enable docker#配置生产存储库curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | \\  sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo#安装 NVIDIA Container Toolkit 软件包sudo yum install -y nvidia-container-toolkit#重启dockersudo systemctl restart docker\n安装webui#可以通过-e OLLAMA_BASE_URL 配置ollama地址,进入web界面也可以配置,镜像差不多9G,在国外需要配置加速源docker run -d -p 3000:8080 --gpus all -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:cuda\n\n额外\ndify功能比Open-WebUI更强大，支持agent和工作流和很多插件，如果不想只单独通过webui来交互建议使用difycurl -SL https://github.com/docker/compose/releases/download/v2.30.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose#将可执行权限赋予安装目标路径中的独立二进制文件sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-composegit clone https://github.com/langgenius/dify.gitcd difycd dockercp .env.example .envdocker compose up -d\n\n","tags":["llm"]}]